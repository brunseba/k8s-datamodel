{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"K8s DataModel","text":"<p>Version 0.4.0</p> <p>A comprehensive CLI tool to model and analyze Kubernetes cluster data including CRDs, operators, and OLM components.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>CRD Inventory: List and analyze all Custom Resource Definitions in your cluster</li> <li>Operator Detection: Automatically identify and inventory operators (deployments, statefulsets)  </li> <li>Framework Detection: Detect operator frameworks (OLM, Helm, Manual)</li> <li>Database Storage: Persistent SQLite storage for historical tracking and snapshots</li> <li>Snapshot Management: Store, list, view, and compare inventory snapshots over time</li> <li>Multiple Output Formats: Support for table, JSON, YAML, and rich terminal output</li> <li>Filtering &amp; Search: Filter resources by namespace, group, framework, and more</li> <li>Export Capabilities: Export complete inventories for analysis and reporting</li> <li>Cluster Analysis: Comprehensive cluster summaries and statistics</li> </ul>"},{"location":"#architecture","title":"Architecture","text":""},{"location":"#system-overview","title":"System Overview","text":"<pre><code>graph TB\n    subgraph \"User Interface\"\n        CLI[\"\ud83d\udda5\ufe0f CLI Commands\"]\n        CONFIG[\"\u2699\ufe0f Configuration\"]\n    end\n\n    subgraph \"Core Engine\"\n        MAIN[\"\ud83c\udfaf Main Controller\"]\n        CLIENT[\"\ud83d\udd0c K8s Client\"]\n\n        subgraph \"Inventory Modules\"\n            CRD_INV[\"\ud83d\udccb CRD Inventory\"]\n            OP_INV[\"\ud83e\udd16 Operator Inventory\"]\n            CLUSTER[\"\ud83c\udfd7\ufe0f Cluster Operations\"]\n        end\n\n        subgraph \"Analysis Engine\"\n            DETECT[\"\ud83d\udd0d Framework Detection\"]\n            CLASSIFY[\"\ud83d\udcca Classification\"]\n            HEALTH[\"\ud83d\udc9a Health Assessment\"]\n        end\n    end\n\n    subgraph \"Output Layer\"\n        FORMATTER[\"\ud83c\udfa8 Formatters\"]\n\n        subgraph \"Output Formats\"\n            TABLE[\"\ud83d\udccb Table\"]\n            JSON[\"\ud83d\udcc4 JSON\"]\n            YAML[\"\ud83d\udcdd YAML\"]\n            RICH[\"\ud83c\udf08 Rich\"]\n        end\n    end\n\n    subgraph \"Storage Layer\"\n        DATABASE[\"\ud83d\udcbe SQLite Database\"]\n\n        subgraph \"Database Operations\"\n            SNAPSHOTS[\"\ud83d\udcf8 Snapshots\"]\n            HISTORY[\"\ud83d\udcca Historical Data\"]\n            EXPORT_DB[\"\ud83d\udce4 Export\"]\n        end\n    end\n\n    subgraph \"Kubernetes Cluster\"\n        API[\"\u26a1 API Server\"]\n\n        subgraph \"Resources\"\n            CRDS[\"\ud83d\udce6 CRDs\"]\n            DEPLOYS[\"\ud83d\ude80 Deployments\"]\n            PODS[\"\ud83d\udc33 Pods\"]\n            SVC[\"\ud83c\udf10 Services\"]\n        end\n    end\n\n    CLI --&gt; CONFIG\n    CLI --&gt; MAIN\n    MAIN --&gt; CLIENT\n    CLIENT --&gt; CRD_INV\n    CLIENT --&gt; OP_INV\n    CLIENT --&gt; CLUSTER\n\n    CRD_INV --&gt; DETECT\n    OP_INV --&gt; DETECT\n    OP_INV --&gt; CLASSIFY\n    OP_INV --&gt; HEALTH\n\n    CRD_INV --&gt; FORMATTER\n    OP_INV --&gt; FORMATTER\n    CLUSTER --&gt; FORMATTER\n\n    CRD_INV --&gt; DATABASE\n    OP_INV --&gt; DATABASE\n    CLUSTER --&gt; DATABASE\n\n    DATABASE --&gt; SNAPSHOTS\n    DATABASE --&gt; HISTORY\n    DATABASE --&gt; EXPORT_DB\n\n    FORMATTER --&gt; TABLE\n    FORMATTER --&gt; JSON\n    FORMATTER --&gt; YAML\n    FORMATTER --&gt; RICH\n\n    CLIENT --&gt; API\n    API --&gt; CRDS\n    API --&gt; DEPLOYS\n    API --&gt; PODS\n    API --&gt; SVC</code></pre>"},{"location":"#data-flow-architecture","title":"Data Flow Architecture","text":"<pre><code>flowchart LR\n    subgraph \"Input\"\n        USER[\"\ud83d\udc64 User Command\"]\n        KUBECONFIG[\"\ud83d\udd10 Kubeconfig\"]\n    end\n\n    subgraph \"Processing Pipeline\"\n        AUTH[\"\ud83d\udd13 Authentication\"]\n        CONNECT[\"\ud83d\udd17 Connection\"]\n        DISCOVER[\"\ud83d\udd0d Discovery\"]\n        ANALYZE[\"\ud83d\udcca Analysis\"]\n        FORMAT[\"\ud83c\udfa8 Formatting\"]\n    end\n\n    subgraph \"Output\"\n        DISPLAY[\"\ud83d\udcbb Display\"]\n        EXPORT[\"\ud83d\udcc1 Export\"]\n    end\n\n    USER --&gt; AUTH\n    KUBECONFIG --&gt; AUTH\n    AUTH --&gt; CONNECT\n    CONNECT --&gt; DISCOVER\n    DISCOVER --&gt; ANALYZE\n    ANALYZE --&gt; FORMAT\n    FORMAT --&gt; DISPLAY\n    FORMAT --&gt; EXPORT\n\n    style USER fill:#e1f5fe\n    style DISPLAY fill:#e8f5e8\n    style EXPORT fill:#e8f5e8</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#installation","title":"Installation","text":"<pre><code># Install with pipx (recommended)\npipx install k8s-datamodel\n\n# Or install with pip\npip install k8s-datamodel\n</code></pre>"},{"location":"#basic-usage","title":"Basic Usage","text":"<pre><code># List all CRDs in the cluster\nk8s-datamodel crd list\n\n# List all operators\nk8s-datamodel operators list\n\n# Get cluster summary\nk8s-datamodel cluster summary\n\n# Export complete inventory\nk8s-datamodel cluster export --file inventory.json\n\n# Store inventory snapshot in database\nk8s-datamodel database store --notes \"Production cluster snapshot\"\n\n# List stored snapshots\nk8s-datamodel database list\n</code></pre>"},{"location":"#common-workflows","title":"Common Workflows","text":""},{"location":"#cluster-analysis-workflow","title":"Cluster Analysis Workflow","text":"<pre><code>flowchart TD\n    START([\"\ud83d\ude80 Start Analysis\"]) --&gt; CONNECT{\"\ud83d\udd17 Test Connection\"}\n    CONNECT --&gt;|\"\u2705 Success\"| INFO[\"\u2139\ufe0f Get Cluster Info\"]\n    CONNECT --&gt;|\"\u274c Failed\"| ERROR1[\"\u26a0\ufe0f Connection Error\"]\n\n    INFO --&gt; SUMMARY[\"\ud83d\udcca Generate Summary\"]\n    SUMMARY --&gt; CRD_LIST[\"\ud83d\udccb List CRDs\"]\n    CRD_LIST --&gt; OP_LIST[\"\ud83e\udd16 List Operators\"]\n    OP_LIST --&gt; ANALYZE[\"\ud83d\udd0d Analyze Relationships\"]\n    ANALYZE --&gt; EXPORT[\"\ud83d\udce4 Export Results\"]\n    EXPORT --&gt; END([\"\u2705 Analysis Complete\")\n\n    ERROR1 --&gt; END\n\n    style START fill:#e3f2fd\n    style END fill:#e8f5e8\n    style ERROR1 fill:#ffebee</code></pre>"},{"location":"#operator-discovery-process","title":"Operator Discovery Process","text":"<pre><code>sequenceDiagram\n    participant CLI as \ud83d\udda5\ufe0f CLI\n    participant Client as \ud83d\udd0c K8s Client\n    participant API as \u26a1 API Server\n    participant Analyzer as \ud83d\udd0d Analyzer\n\n    CLI-&gt;&gt;Client: List operators request\n    Client-&gt;&gt;API: Get deployments\n    API--&gt;&gt;Client: Deployment list\n\n    Client-&gt;&gt;API: Get statefulsets\n    API--&gt;&gt;Client: StatefulSet list\n\n    Client-&gt;&gt;Analyzer: Analyze workloads\n\n    loop For each workload\n        Analyzer-&gt;&gt;Analyzer: Check image patterns\n        Analyzer-&gt;&gt;Analyzer: Analyze labels\n        Analyzer-&gt;&gt;Analyzer: Check CRD ownership\n        Analyzer-&gt;&gt;Analyzer: Assess framework\n    end\n\n    Analyzer--&gt;&gt;Client: Operator classification\n    Client--&gt;&gt;CLI: Formatted results\n\n    Note over CLI,Analyzer: Parallel processing for performance</code></pre>"},{"location":"#database-storage-and-historical-tracking","title":"Database Storage and Historical Tracking","text":"<pre><code>flowchart TD\n    subgraph \"Data Collection\"\n        LIVE_CRDS[\"\ud83d\udce6 Live CRDs\"]\n        LIVE_OPS[\"\ud83e\udd16 Live Operators\"]\n        LIVE_CLUSTER[\"\ud83c\udfd7\ufe0f Live Cluster\"]\n    end\n\n    subgraph \"Database Storage\"\n        SNAPSHOT[\"\ud83d\udcf8 Create Snapshot\"]\n        DB[(\"\ud83d\udcbe SQLite Database\")]\n\n        subgraph \"Stored Data\"\n            SNAP_META[\"\ud83d\udccb Snapshot Metadata\"]\n            HIST_CRDS[\"\ud83d\udce6 Historical CRDs\"]\n            HIST_OPS[\"\ud83e\udd16 Historical Operators\"]\n            HIST_CSVS[\"\ud83d\udcdc Historical CSVs\"]\n        end\n    end\n\n    subgraph \"Database Operations\"\n        LIST[\"\ud83d\udcdd List Snapshots\"]\n        COMPARE[\"\ud83d\udd0d Compare\"]\n        EXPORT[\"\ud83d\udce4 Export\"]\n        CLEANUP[\"\ud83e\uddf9 Cleanup\"]\n    end\n\n    subgraph \"Analysis &amp; Reporting\"\n        TRENDS[\"\ud83d\udcc8 Trend Analysis\"]\n        COMPLIANCE[\"\ud83d\udee1\ufe0f Compliance Reports\"]\n        AUDIT[\"\ud83d\udcca Audit Trails\"]\n        ALERTS[\"\ud83d\udea8 Change Alerts\"]\n    end\n\n    LIVE_CRDS --&gt; SNAPSHOT\n    LIVE_OPS --&gt; SNAPSHOT\n    LIVE_CLUSTER --&gt; SNAPSHOT\n\n    SNAPSHOT --&gt; DB\n    DB --&gt; SNAP_META\n    DB --&gt; HIST_CRDS\n    DB --&gt; HIST_OPS\n    DB --&gt; HIST_CSVS\n\n    DB --&gt; LIST\n    DB --&gt; COMPARE\n    DB --&gt; EXPORT\n    DB --&gt; CLEANUP\n\n    LIST --&gt; TRENDS\n    COMPARE --&gt; COMPLIANCE\n    EXPORT --&gt; AUDIT\n    COMPARE --&gt; ALERTS\n\n    style DB fill:#e1f5fe\n    style SNAPSHOT fill:#e8f5e8\n    style TRENDS fill:#fff3e0</code></pre>"},{"location":"#export-and-integration-flow","title":"Export and Integration Flow","text":"<pre><code>graph LR\n    subgraph \"Data Sources\"\n        CRDS[\"\ud83d\udce6 CRDs\"]\n        OPS[\"\ud83e\udd16 Operators\"]\n        CLUSTER[\"\ud83c\udfd7\ufe0f Cluster Info\"]\n        DATABASE_SRC[\"\ud83d\udcbe Database Snapshots\"]\n    end\n\n    subgraph \"Processing\"\n        COLLECT[\"\ud83d\udce5 Collect Data\"]\n        ENRICH[\"\u2728 Enrich Metadata\"]\n        VALIDATE[\"\u2705 Validate\"]\n    end\n\n    subgraph \"Output Formats\"\n        JSON_OUT[\"\ud83d\udcc4 JSON\"]\n        YAML_OUT[\"\ud83d\udcdd YAML\"]\n        CSV_OUT[\"\ud83d\udcca CSV\"]\n    end\n\n    subgraph \"Integration Targets\"\n        MONITORING[\"\ud83d\udcc8 Monitoring\"]\n        CICD[\"\ud83d\udd04 CI/CD\"]\n        DOCS[\"\ud83d\udcda Documentation\"]\n        COMPLIANCE[\"\ud83d\udee1\ufe0f Compliance\"]\n    end\n\n    CRDS --&gt; COLLECT\n    OPS --&gt; COLLECT\n    CLUSTER --&gt; COLLECT\n    DATABASE_SRC --&gt; COLLECT\n\n    COLLECT --&gt; ENRICH\n    ENRICH --&gt; VALIDATE\n\n    VALIDATE --&gt; JSON_OUT\n    VALIDATE --&gt; YAML_OUT\n    VALIDATE --&gt; CSV_OUT\n\n    JSON_OUT --&gt; MONITORING\n    JSON_OUT --&gt; CICD\n    YAML_OUT --&gt; DOCS\n    JSON_OUT --&gt; COMPLIANCE</code></pre>"},{"location":"#use-cases","title":"Use Cases","text":"<ul> <li>Cluster Auditing: Understand what custom resources and operators are deployed</li> <li>Historical Tracking: Store and compare cluster inventories over time using database snapshots</li> <li>Migration Planning: Inventory resources before cluster migrations and track changes</li> <li>Security Assessment: Identify all operators and their frameworks with audit trails</li> <li>Compliance Reporting: Generate historical compliance reports from stored snapshots</li> <li>Change Management: Track and alert on changes to critical cluster resources</li> <li>Documentation: Generate cluster documentation automatically with historical context</li> <li>Monitoring: Track changes in CRDs and operators over time with persistent storage</li> <li>Trend Analysis: Analyze resource growth and changes across multiple time periods</li> </ul>"},{"location":"#comprehensive-examples","title":"\ud83d\udcda Comprehensive Examples","text":"<p>Explore our extensive collection of real-world examples and workflows:</p> <ul> <li>Database Workflows - Complete database operations, CI/CD integration, and monitoring</li> <li>OLM Management - Operator Lifecycle Manager operations, RBAC analysis, and troubleshooting  </li> <li>Security &amp; Compliance - Enterprise security baselines, compliance reporting (SOC 2, PCI DSS), and automated monitoring</li> </ul> <p>Each section includes ready-to-use scripts, detailed explanations, and enterprise-grade best practices.</p>"},{"location":"#output-examples","title":"Output Examples","text":""},{"location":"#crd-listing","title":"CRD Listing","text":"<pre><code>$ k8s-datamodel crd list --output rich\n</code></pre>"},{"location":"#operator-inventory","title":"Operator Inventory","text":"<pre><code>$ k8s-datamodel operators list --framework OLM\n</code></pre>"},{"location":"#cluster-summary","title":"Cluster Summary","text":"<pre><code>$ k8s-datamodel cluster summary\n</code></pre>"},{"location":"#requirements","title":"Requirements","text":"<ul> <li>Python 3.10+</li> <li>Access to a Kubernetes cluster</li> <li>Valid kubeconfig file</li> </ul>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Contributions are welcome! Please see Contributing for guidelines.</p>"},{"location":"CRD_EXPORT_EXAMPLES/","title":"CRD Export-All Command Examples","text":"<p>The <code>k8s-datamodel crd export-all</code> command allows you to export all CRDs in your cluster with their complete property schemas to a well-formatted Markdown document with a table of contents.</p>"},{"location":"CRD_EXPORT_EXAMPLES/#command-syntax","title":"Command Syntax","text":"<pre><code>k8s-datamodel crd export-all [OPTIONS]\n</code></pre>"},{"location":"CRD_EXPORT_EXAMPLES/#available-options","title":"Available Options","text":"<ul> <li><code>-f, --output-file TEXT</code>: Output markdown file name (default: <code>crd-export.md</code>)</li> <li><code>--max-depth INTEGER</code>: Maximum depth for nested properties (default: 3)</li> <li><code>--required-only</code>: Show only required properties</li> <li><code>-g, --group TEXT</code>: Filter by API group (partial match)</li> <li><code>-s, --scope [Namespaced|Cluster]</code>: Filter by scope</li> <li><code>--include-toc</code>: Include table of contents (default: true)</li> </ul>"},{"location":"CRD_EXPORT_EXAMPLES/#usage-examples","title":"Usage Examples","text":""},{"location":"CRD_EXPORT_EXAMPLES/#1-export-all-crds-full-inventory","title":"1. Export All CRDs (Full Inventory)","text":"<pre><code>k8s-datamodel crd export-all --output-file cluster-inventory.md\n</code></pre> <p>This exports all CRDs in your cluster to <code>cluster-inventory.md</code> with complete property documentation.</p>"},{"location":"CRD_EXPORT_EXAMPLES/#2-export-specific-api-group-eg-cert-manager","title":"2. Export Specific API Group (e.g., cert-manager)","text":"<pre><code>k8s-datamodel crd export-all --group cert-manager.io --output-file cert-manager-crds.md --max-depth 2\n</code></pre> <p>Exports only cert-manager CRDs with properties nested to depth 2.</p>"},{"location":"CRD_EXPORT_EXAMPLES/#3-export-only-namespaced-crds","title":"3. Export Only Namespaced CRDs","text":"<pre><code>k8s-datamodel crd export-all --scope Namespaced --output-file namespaced-crds.md\n</code></pre> <p>Focuses on CRDs that create namespaced resources only.</p>"},{"location":"CRD_EXPORT_EXAMPLES/#4-export-required-properties-only","title":"4. Export Required Properties Only","text":"<pre><code>k8s-datamodel crd export-all --group kafka.strimzi.io --required-only --output-file kafka-required.md\n</code></pre> <p>Shows only the mandatory fields for Kafka CRDs.</p>"},{"location":"CRD_EXPORT_EXAMPLES/#5-database-related-crds","title":"5. Database-Related CRDs","text":"<pre><code>k8s-datamodel crd export-all --group postgresql.cnpg.io --output-file postgresql-inventory.md --max-depth 3\n</code></pre> <p>Exports PostgreSQL operator CRDs with detailed property nesting.</p>"},{"location":"CRD_EXPORT_EXAMPLES/#generated-markdown-structure","title":"Generated Markdown Structure","text":"<p>The exported markdown file contains:</p> <ol> <li>Header with Summary Statistics</li> <li>Total CRDs count</li> <li>Total properties documented</li> <li> <p>Generation timestamp</p> </li> <li> <p>Table of Contents (if enabled)</p> </li> <li>Organized by API group</li> <li>Clickable links to each CRD section</li> <li> <p>Easy navigation for large exports</p> </li> <li> <p>CRD Details by API Group</p> </li> <li>Each CRD includes:<ul> <li>Basic information table (API Group, Version, Kind, Scope, Instance Count)</li> <li>Complete property schema with types and descriptions</li> <li>Nested property structure (respects max-depth setting)</li> <li>Required property indicators</li> <li>Enum value displays</li> <li>Array item specifications</li> </ul> </li> </ol>"},{"location":"CRD_EXPORT_EXAMPLES/#example-output-features","title":"Example Output Features","text":""},{"location":"CRD_EXPORT_EXAMPLES/#property-documentation-format","title":"Property Documentation Format","text":"<pre><code>- **propertyName** (`type`) ***(required)***\n  \u2022 Description of the property and its usage\n  - **nestedProperty** (`string` (enum: value1|value2|value3))\n    \u2022 Description of nested property\n</code></pre>"},{"location":"CRD_EXPORT_EXAMPLES/#basic-information-table","title":"Basic Information Table","text":"Property Value API Group <code>cert-manager.io</code> Version <code>v1</code> Kind <code>Certificate</code> Scope Namespaced Instances 6"},{"location":"CRD_EXPORT_EXAMPLES/#summary-statistics","title":"Summary Statistics","text":"<ul> <li>Total properties: 21 | Required: 2</li> </ul>"},{"location":"CRD_EXPORT_EXAMPLES/#use-cases","title":"Use Cases","text":"<ol> <li>Cluster Documentation: Generate comprehensive documentation of your Kubernetes cluster's custom resources</li> <li>Operator Analysis: Understand the capabilities and configuration options of installed operators</li> <li>Migration Planning: Document current CRD schemas before cluster migrations</li> <li>Developer Onboarding: Provide detailed references for team members working with custom resources</li> <li>Compliance Auditing: Document all custom resources for security and compliance reviews</li> <li>Schema Evolution Tracking: Create snapshots of CRD schemas to track changes over time</li> </ol>"},{"location":"CRD_EXPORT_EXAMPLES/#performance-notes","title":"Performance Notes","text":"<ul> <li>Large clusters may take several minutes to process all CRDs</li> <li>Use filters (<code>--group</code>, <code>--scope</code>) to reduce processing time for focused exports</li> <li>Generated files can be quite large (hundreds of KB to several MB for comprehensive exports)</li> <li>The tool processes only CRDs with valid OpenAPI v3 schemas</li> </ul>"},{"location":"CRD_EXPORT_EXAMPLES/#integration-with-other-tools","title":"Integration with Other Tools","text":"<p>The generated Markdown files can be: - Viewed in any Markdown viewer or editor - Converted to PDF, HTML, or other formats using pandoc - Integrated into documentation systems like GitBook, MkDocs, or Gitiles - Stored in version control for schema change tracking - Used as input for automated documentation pipelines</p>"},{"location":"CRD_EXPORT_EXAMPLES/#example-command-for-different-scenarios","title":"Example Command for Different Scenarios","text":""},{"location":"CRD_EXPORT_EXAMPLES/#production-cluster-audit","title":"Production Cluster Audit","text":"<pre><code>k8s-datamodel crd export-all --output-file prod-cluster-audit.md --max-depth 2\n</code></pre>"},{"location":"CRD_EXPORT_EXAMPLES/#specific-operator-documentation","title":"Specific Operator Documentation","text":"<pre><code>k8s-datamodel crd export-all --group strimzi.io --output-file kafka-operator-docs.md\n</code></pre>"},{"location":"CRD_EXPORT_EXAMPLES/#quick-reference-required-fields-only","title":"Quick Reference (Required Fields Only)","text":"<pre><code>k8s-datamodel crd export-all --required-only --output-file crd-quick-reference.md --max-depth 1\n</code></pre>"},{"location":"OLM_FEATURE_SUMMARY/","title":"OLM Integration Feature Summary","text":""},{"location":"OLM_FEATURE_SUMMARY/#feature-added-olm-operator-lifecycle-manager-support","title":"\ud83c\udfaf Feature Added: OLM (Operator Lifecycle Manager) Support","text":"<p>I've successfully added comprehensive OLM support to the k8s-datamodel, enabling users to inventory and manage ClusterServiceVersions (CSVs) alongside CRDs and operators.</p>"},{"location":"OLM_FEATURE_SUMMARY/#new-capabilities","title":"\u2728 New Capabilities","text":""},{"location":"OLM_FEATURE_SUMMARY/#olm-discovery","title":"\ud83d\udd0d OLM Discovery","text":"<ul> <li>Full CSV Inventory: Discovers all ClusterServiceVersions managed by OLM</li> <li>Rich Metadata: Extracts display names, versions, phases, providers, and descriptions</li> <li>CRD Ownership: Maps which CRDs are owned and required by each operator</li> <li>Permission Analysis: Captures service account permissions and cluster permissions</li> <li>Version Management: Tracks operator version upgrades, replacements, and skips</li> </ul>"},{"location":"OLM_FEATURE_SUMMARY/#new-cli-commands","title":"\ud83c\udf9b\ufe0f New CLI Commands","text":"<pre><code># OLM command group\nk8s-datamodel olm --help\n\n# List all ClusterServiceVersions\nk8s-datamodel olm list [--phase] [--provider] [--namespace] [--output table|json|yaml|rich]\n\n# Get specific CSV details  \nk8s-datamodel olm get &lt;csv-name&gt; --namespace &lt;namespace&gt;\n\n# Show OLM status and statistics\nk8s-datamodel olm status [--namespace] [--output rich|table|json|yaml]\n\n# Count CSVs with breakdown\nk8s-datamodel olm count [--phase] [--namespace] [--verbose]\n</code></pre>"},{"location":"OLM_FEATURE_SUMMARY/#enhanced-cluster-summary","title":"\ud83d\udcca Enhanced Cluster Summary","text":"<p>The cluster summary now includes a comprehensive OLM Status panel: - Total OLM ClusterServiceVersions - Breakdown by phase (Succeeded, Installing, Failed, etc.) - Overall OLM health status</p>"},{"location":"OLM_FEATURE_SUMMARY/#enhanced-export","title":"\ud83d\udce4 Enhanced Export","text":"<ul> <li>New export option: <code>--include-olm/--no-olm</code> for cluster export</li> <li>Complete OLM data: All CSV metadata, permissions, and relationships</li> <li>Integration support: JSON/YAML exports for CI/CD pipelines</li> </ul>"},{"location":"OLM_FEATURE_SUMMARY/#operator-enhancement","title":"\ud83d\udd17 Operator Enhancement","text":"<ul> <li>Automatic OLM detection: Operators are now automatically tagged as \"OLM\" framework when matching CSVs are found</li> <li>Enhanced CRD mapping: Operators managed by OLM show their CSV-defined CRDs</li> <li>Better accuracy: More precise operator framework classification</li> </ul>"},{"location":"OLM_FEATURE_SUMMARY/#technical-implementation","title":"\ud83c\udfd7\ufe0f Technical Implementation","text":""},{"location":"OLM_FEATURE_SUMMARY/#new-core-module-olm_inventorypy","title":"New Core Module: <code>olm_inventory.py</code>","text":"<ul> <li>CSVInfo dataclass: Rich data model for ClusterServiceVersion information</li> <li>OLMInventory service: Comprehensive CSV discovery and analysis</li> <li>Smart filtering: By namespace, phase, provider, etc.</li> <li>Statistics generation: Automated reporting and analytics</li> </ul>"},{"location":"OLM_FEATURE_SUMMARY/#new-command-module-olmpy","title":"New Command Module: <code>olm.py</code>","text":"<ul> <li>Complete CLI interface: List, get, count, status commands</li> <li>CSVOutputFormatter: Rich, table, JSON, YAML output formats</li> <li>Advanced filtering: Multi-criteria filtering capabilities</li> <li>Error handling: Graceful handling when OLM is not installed</li> </ul>"},{"location":"OLM_FEATURE_SUMMARY/#enhanced-integration","title":"Enhanced Integration","text":"<ul> <li>Operator inventory integration: Automatic OLM framework detection</li> <li>Cluster summary enhancement: OLM status panels and statistics</li> <li>Export functionality: Complete CSV data in cluster exports</li> <li>Unified experience: Consistent interface across CRD/Operator/OLM commands</li> </ul>"},{"location":"OLM_FEATURE_SUMMARY/#real-world-testing-results","title":"\ud83d\udcc8 Real-World Testing Results","text":"<p>Successfully tested against live cluster with OLM: - 46 ClusterServiceVersions discovered across multiple namespaces - 735 owned CRDs tracked via CSV ownership - Multiple providers detected: Oracle, Red Hat, CloudNativePG, MariaDB - Phase tracking: 31 Succeeded, 15 Installing - Rich export data: 1MB+ detailed CSV information</p>"},{"location":"OLM_FEATURE_SUMMARY/#benefits-for-users","title":"\ud83c\udf81 Benefits for Users","text":""},{"location":"OLM_FEATURE_SUMMARY/#complete-visibility","title":"\ud83d\udd0d Complete Visibility","text":"<ul> <li>See the full picture of operator management in your cluster</li> <li>Understand which operators are managed by OLM vs manual deployment</li> <li>Track operator health and installation status</li> </ul>"},{"location":"OLM_FEATURE_SUMMARY/#better-decision-making","title":"\ud83d\udcca Better Decision Making","text":"<ul> <li>Identify failed or problematic operator installations</li> <li>Understand CRD ownership relationships</li> <li>Plan operator upgrades and migrations</li> </ul>"},{"location":"OLM_FEATURE_SUMMARY/#operational-excellence","title":"\ud83d\udee0\ufe0f Operational Excellence","text":"<ul> <li>Export complete operator inventories for auditing</li> <li>Monitor OLM deployment health</li> <li>Integrate with CI/CD and monitoring systems</li> </ul>"},{"location":"OLM_FEATURE_SUMMARY/#unified-interface","title":"\ud83d\udd17 Unified Interface","text":"<ul> <li>Single tool for CRDs, operators, and OLM management</li> <li>Consistent filtering and output options</li> <li>Seamless integration with existing workflows</li> </ul>"},{"location":"OLM_FEATURE_SUMMARY/#quality-assurance","title":"\ud83e\uddea Quality Assurance","text":""},{"location":"OLM_FEATURE_SUMMARY/#comprehensive-testing","title":"\u2705 Comprehensive Testing","text":"<ul> <li>8 new unit tests covering all OLM functionality</li> <li>95% code coverage for OLM inventory module</li> <li>Real cluster validation with live OLM installation</li> <li>Error handling for clusters without OLM</li> </ul>"},{"location":"OLM_FEATURE_SUMMARY/#documentation-updates","title":"\ud83d\udcd6 Documentation Updates","text":"<ul> <li>README updates with OLM examples and usage</li> <li>Demo script enhancement showcasing OLM features</li> <li>Architecture documentation reflecting new components</li> <li>Help text for all new commands and options</li> </ul>"},{"location":"OLM_FEATURE_SUMMARY/#commands-in-action","title":"\ud83d\ude80 Commands in Action","text":""},{"location":"OLM_FEATURE_SUMMARY/#discover-olm-operators","title":"Discover OLM Operators","text":"<pre><code>$ k8s-datamodel olm list --output rich\n# Shows beautifully formatted table with phase colors and provider info\n</code></pre>"},{"location":"OLM_FEATURE_SUMMARY/#monitor-olm-health","title":"Monitor OLM Health","text":"<pre><code>$ k8s-datamodel olm status\n# Rich panels showing CSV counts, success rates, and breakdowns\n</code></pre>"},{"location":"OLM_FEATURE_SUMMARY/#export-for-analysis","title":"Export for Analysis","text":"<pre><code>$ k8s-datamodel cluster export --include-olm --file cluster-with-olm.json\n# Complete cluster inventory including all OLM data\n</code></pre>"},{"location":"OLM_FEATURE_SUMMARY/#enhanced-cluster-overview","title":"Enhanced Cluster Overview","text":"<pre><code>$ k8s-datamodel cluster summary\n# Now includes OLM Status panel alongside CRDs and Operators\n</code></pre>"},{"location":"OLM_FEATURE_SUMMARY/#this-addition-provides","title":"\ud83c\udfaf This Addition Provides","text":"<ul> <li>Complete operator ecosystem visibility</li> <li>OLM-specific tooling and analytics </li> <li>Enhanced existing functionality</li> <li>Production-ready OLM support</li> <li>Seamless integration with existing features</li> </ul> <p>The OLM integration makes k8s-datamodel a truly comprehensive tool for understanding and managing the complete operator ecosystem in Kubernetes clusters, whether operators are deployed via OLM, Helm, or manually.</p>"},{"location":"PROJECT_SUMMARY/","title":"K8s Inventory CLI - Project Summary","text":""},{"location":"PROJECT_SUMMARY/#project-delivered","title":"\ud83c\udfaf Project Delivered","text":"<p>I've successfully created a comprehensive Python CLI package using UV that inventories CRDs (Custom Resource Definitions) and operators in Kubernetes clusters, following all your specified rules and requirements.</p>"},{"location":"PROJECT_SUMMARY/#rules-compliance","title":"\u2705 Rules Compliance","text":""},{"location":"PROJECT_SUMMARY/#git-development-standards","title":"Git &amp; Development Standards","text":"<ul> <li>\u2705 Conventional commits: Project ready for conventional commit standards</li> <li>\u2705 Pre-commit hooks: Configured with black, isort, flake8, mypy</li> <li>\u2705 Changelog generation: Ready for automated changelog on tags</li> <li>\u2705 GitIgnore: Comprehensive Python + MkDocs gitignore, excludes workspace root</li> </ul>"},{"location":"PROJECT_SUMMARY/#documentation-publishing","title":"Documentation &amp; Publishing","text":"<ul> <li>\u2705 MkDocs with Material theme: Full documentation site ready</li> <li>\u2705 Git change tracking: Documentation configured to track changes</li> <li>\u2705 PDF export support: Via mkdocs-pdf-export-plugin</li> <li>\u2705 Mermaid diagram support: Architecture diagrams included</li> <li>\u2705 GitHub Pages ready: GitHub Action workflow ready for deployment</li> </ul>"},{"location":"PROJECT_SUMMARY/#github-project-standards","title":"GitHub Project Standards","text":"<ul> <li>\u2705 Issue labels: Ready for conventional commit label mapping  </li> <li>\u2705 Default assignee: Configured for @me assignment</li> <li>\u2705 GitHub Pages enabled: Documentation publishing ready</li> <li>\u2705 GitHub Actions: MkDocs publishing workflow included</li> </ul>"},{"location":"PROJECT_SUMMARY/#python-development-standards","title":"Python Development Standards","text":"<ul> <li>\u2705 Python 3.10+: Minimum version requirement met</li> <li>\u2705 UV package manager: Used throughout the project</li> <li>\u2705 src/ folder structure: Code organized in src/k8s_inventory_cli/</li> <li>\u2705 Click CLI framework: Comprehensive CLI interface</li> <li>\u2705 pipx deployment ready: Installable via pipx</li> <li>\u2705 Unit tests: Comprehensive test suite with pytest</li> </ul>"},{"location":"PROJECT_SUMMARY/#architecture-delivered","title":"\ud83c\udfd7\ufe0f Architecture Delivered","text":""},{"location":"PROJECT_SUMMARY/#system-architecture","title":"System Architecture","text":"<pre><code>graph TB\n    subgraph \"Command Layer\"\n        MAIN[\"\ud83c\udfaf main.py\"]\n\n        subgraph \"CLI Commands\"\n            CRD_CMD[\"\ud83d\udccb crd.py\"]\n            OP_CMD[\"\ud83e\udd16 operators.py\"]\n            CLUSTER_CMD[\"\ud83c\udfd7\ufe0f cluster.py\"]\n        end\n    end\n\n    subgraph \"Core Business Logic\"\n        CLIENT[\"\ud83d\udd0c k8s_client.py\"]\n\n        subgraph \"Inventory Engines\"\n            CRD_INV[\"\ud83d\udce6 crd_inventory.py\"]\n            OP_INV[\"\ud83e\udd16 operator_inventory.py\"]\n        end\n\n        subgraph \"Analysis Components\"\n            DETECT[\"\ud83d\udd0d Framework Detection\"]\n            CLASSIFY[\"\ud83d\udcca Resource Classification\"]\n            HEALTH[\"\ud83d\udc9a Health Assessment\"]\n        end\n    end\n\n    subgraph \"Utility Layer\"\n        FORMATTER[\"\ud83c\udfa8 formatters.py\"]\n\n        subgraph \"Output Processors\"\n            TABLE_FMT[\"\ud83d\udccb Table Formatter\"]\n            JSON_FMT[\"\ud83d\udcc4 JSON Formatter\"]\n            YAML_FMT[\"\ud83d\udcdd YAML Formatter\"]\n            RICH_FMT[\"\ud83c\udf08 Rich Formatter\"]\n        end\n    end\n\n    subgraph \"External Systems\"\n        K8S_API[\"\u26a1 Kubernetes API\"]\n        KUBECONFIG[\"\ud83d\udd10 Kubeconfig\"]\n    end\n\n    MAIN --&gt; CRD_CMD\n    MAIN --&gt; OP_CMD\n    MAIN --&gt; CLUSTER_CMD\n\n    CRD_CMD --&gt; CLIENT\n    OP_CMD --&gt; CLIENT\n    CLUSTER_CMD --&gt; CLIENT\n\n    CLIENT --&gt; CRD_INV\n    CLIENT --&gt; OP_INV\n\n    CRD_INV --&gt; DETECT\n    CRD_INV --&gt; CLASSIFY\n    OP_INV --&gt; DETECT\n    OP_INV --&gt; CLASSIFY\n    OP_INV --&gt; HEALTH\n\n    CRD_INV --&gt; FORMATTER\n    OP_INV --&gt; FORMATTER\n\n    FORMATTER --&gt; TABLE_FMT\n    FORMATTER --&gt; JSON_FMT\n    FORMATTER --&gt; YAML_FMT\n    FORMATTER --&gt; RICH_FMT\n\n    CLIENT --&gt; K8S_API\n    CLIENT --&gt; KUBECONFIG\n\n    style MAIN fill:#e3f2fd\n    style CLIENT fill:#f3e5f5\n    style FORMATTER fill:#e8f5e8\n    style K8S_API fill:#fff3e0</code></pre>"},{"location":"PROJECT_SUMMARY/#component-interaction-flow","title":"Component Interaction Flow","text":"<pre><code>sequenceDiagram\n    participant User as \ud83d\udc64 User\n    participant CLI as \ud83d\udda5\ufe0f CLI\n    participant Core as \ud83c\udcf1 Core Engine\n    participant K8s as \u2699\ufe0f K8s API\n    participant Format as \ud83c\udfa8 Formatter\n\n    User-&gt;&gt;CLI: Execute command\n    CLI-&gt;&gt;Core: Initialize client\n    Core-&gt;&gt;K8s: Authenticate\n    K8s--&gt;&gt;Core: Connection established\n\n    CLI-&gt;&gt;Core: Request inventory\n\n    par CRD Discovery\n        Core-&gt;&gt;K8s: List CRDs\n        K8s--&gt;&gt;Core: CRD data\n    and Operator Discovery\n        Core-&gt;&gt;K8s: List deployments\n        K8s--&gt;&gt;Core: Deployment data\n        Core-&gt;&gt;K8s: List statefulsets\n        K8s--&gt;&gt;Core: StatefulSet data\n    end\n\n    Core-&gt;&gt;Core: Analyze &amp; classify\n    Core-&gt;&gt;Format: Process results\n    Format--&gt;&gt;CLI: Formatted output\n    CLI--&gt;&gt;User: Display results</code></pre>"},{"location":"PROJECT_SUMMARY/#core-components-directory-structure","title":"Core Components Directory Structure","text":"<pre><code>src/k8s_inventory_cli/\n\u251c\u2500\u2500 main.py                    # CLI entry point with Click\n\u251c\u2500\u2500 commands/                  # Command modules\n\u2502   \u251c\u2500\u2500 crd.py                # CRD management commands\n\u2502   \u251c\u2500\u2500 operators.py          # Operator management commands\n\u2502   \u2514\u2500\u2500 cluster.py            # Cluster-wide operations\n\u251c\u2500\u2500 core/                     # Core business logic\n\u2502   \u251c\u2500\u2500 k8s_client.py         # Kubernetes API wrapper\n\u2502   \u251c\u2500\u2500 crd_inventory.py      # CRD discovery &amp; analysis\n\u2502   \u2514\u2500\u2500 operator_inventory.py # Operator detection &amp; analysis\n\u2514\u2500\u2500 utils/                    # Utility modules\n    \u2514\u2500\u2500 formatters.py         # Multi-format output handlers\n</code></pre>"},{"location":"PROJECT_SUMMARY/#framework-detection-process","title":"Framework Detection Process","text":"<pre><code>flowchart TD\n    START([\"\ud83d\udd0d Start Detection\"]) --&gt; CRD{\"\ud83d\udce6 Analyze CRD\"}\n    START --&gt; OP{\"\ud83e\udd16 Analyze Operator\"}\n\n    CRD --&gt; LABELS[\"\ud83c\udff7\ufe0f Check Labels\"]\n    LABELS --&gt; HELM_LABEL{\"Helm Labels?\"}\n    HELM_LABEL --&gt;|\"\u2705 Yes\"| HELM[\"\u26f5 Helm\"]\n    HELM_LABEL --&gt;|\"\u274c No\"| OLM_LABEL{\"OLM Annotations?\"}\n    OLM_LABEL --&gt;|\"\u2705 Yes\"| OLM[\"\ud83d\udce6 OLM\"]\n    OLM_LABEL --&gt;|\"\u274c No\"| MANUAL[\"\u270b Manual\"]\n\n    OP --&gt; IMAGE[\"\ud83d\uddbc\ufe0f Analyze Image\"]\n    IMAGE --&gt; DEPLOYMENT[\"\ud83d\ude80 Check Deployment\"]\n    DEPLOYMENT --&gt; RBAC[\"\ud83d\udd10 Analyze RBAC\"]\n    RBAC --&gt; CSV{\"CSV Present?\"}\n    CSV --&gt;|\"\u2705 Yes\"| OLM\n    CSV --&gt;|\"\u274c No\"| HELM_CHART{\"Helm Chart?\"}\n    HELM_CHART --&gt;|\"\u2705 Yes\"| HELM\n    HELM_CHART --&gt;|\"\u274c No\"| MANUAL\n\n    HELM --&gt; RESULT[\"\ud83d\udcca Classification Result\"]\n    OLM --&gt; RESULT\n    MANUAL --&gt; RESULT\n    RESULT --&gt; END([\"\u2705 Detection Complete\"])\n\n    style START fill:#e3f2fd\n    style END fill:#e8f5e8\n    style HELM fill:#326ce5\n    style OLM fill:#ff6f00\n    style MANUAL fill:#757575</code></pre>"},{"location":"PROJECT_SUMMARY/#health-assessment-flow","title":"Health Assessment Flow","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; Analyzing\n\n    Analyzing --&gt; CheckReplicas : Start Assessment\n\n    CheckReplicas --&gt; Healthy : Ready == Desired\n    CheckReplicas --&gt; Degraded : Ready &lt; Desired\n    CheckReplicas --&gt; Failed : Ready == 0\n\n    state CheckReplicas {\n        [*] --&gt; ReplicaCount\n        ReplicaCount --&gt; PodStatus\n        PodStatus --&gt; Conditions\n        Conditions --&gt; [*]\n    }\n\n    Healthy --&gt; [*] : \u2705 All Good\n    Degraded --&gt; [*] : \u26a0\ufe0f Partially Working\n    Failed --&gt; [*] : \u274c Not Working\n\n    note right of Healthy\n        - All replicas ready\n        - Pods running\n        - Health checks pass\n    end note\n\n    note right of Degraded\n        - Some replicas ready\n        - Partial functionality\n        - May recover\n    end note\n\n    note right of Failed\n        - No replicas ready\n        - Service unavailable\n        - Needs intervention\n    end note</code></pre>"},{"location":"PROJECT_SUMMARY/#key-features-implemented","title":"Key Features Implemented","text":""},{"location":"PROJECT_SUMMARY/#crd-inventory","title":"\ud83d\udd0d CRD Inventory","text":"<ul> <li>Complete CRD discovery: Lists all CRDs with detailed metadata</li> <li>Full spec storage: Complete CRD specifications stored in database</li> <li>Framework detection: Identifies Helm, OLM, Manual deployments</li> <li>Instance counting: Shows how many resources exist per CRD</li> <li>Advanced filtering: By group, kind, scope</li> <li>Schema analysis: OpenAPI v3 schema parsing and property extraction</li> <li>Detailed information: Versions, categories, short names, age calculation</li> </ul>"},{"location":"PROJECT_SUMMARY/#operator-detection","title":"\ud83e\udd16 Operator Detection","text":"<ul> <li>Smart operator identification: Detects operators from deployments/statefulsets</li> <li>Complete spec storage: Full deployment/statefulset specs in database</li> <li>Framework classification: OLM, Helm, Manual deployment detection</li> <li>CRD ownership mapping: Links operators to their managed CRDs</li> <li>Health monitoring: Replica status and conditions with datetime handling</li> <li>Image analysis: Version extraction from container images</li> <li>OLM integration: Enhanced operator info from ClusterServiceVersions</li> </ul>"},{"location":"PROJECT_SUMMARY/#olm-operator-lifecycle-manager","title":"\ud83d\udcc2 OLM (Operator Lifecycle Manager)","text":"<ul> <li>ClusterServiceVersion inventory: Complete CSV discovery and analysis</li> <li>Operator relationship mapping: Links CSVs to operators and CRDs</li> <li>Installation strategy analysis: Deployment modes and requirements</li> <li>Permission analysis: RBAC requirements from CSV specs</li> <li>Version management: Tracks replaces, skips, and upgrade paths</li> <li>Full spec persistence: Complete CSV specifications in database</li> </ul>"},{"location":"PROJECT_SUMMARY/#database-persistence-new","title":"\ud83d\udcca Database &amp; Persistence (NEW)","text":"<ul> <li>SQLite storage: Lightweight, portable database for cluster snapshots</li> <li>Complete spec storage: Full Kubernetes resource specifications saved</li> <li>Historical tracking: Compare cluster state changes over time</li> <li>Multi-cluster support: Store inventories from multiple clusters</li> <li>Snapshot management: Create, list, view, export, and delete snapshots</li> <li>Advanced querying: Deep analysis of stored specifications</li> <li>Datetime serialization: Proper handling of all Kubernetes timestamps</li> <li>Database statistics: Storage metrics and usage analysis</li> </ul>"},{"location":"PROJECT_SUMMARY/#output-formats","title":"\ud83d\udcca Output Formats","text":"<ul> <li>Table: Human-readable grid format (default)</li> <li>Rich: Enhanced terminal output with colors and styling</li> <li>JSON: Machine-readable for scripting and integration</li> <li>YAML: Human and machine-readable structured format</li> </ul>"},{"location":"PROJECT_SUMMARY/#cluster-operations","title":"\ud83c\udf10 Cluster Operations","text":"<ul> <li>Connection testing: Validates cluster connectivity</li> <li>Comprehensive summaries: Statistical overviews</li> <li>Complete exports: Full inventory dumps</li> <li>Cluster information: Node counts, versions</li> </ul>"},{"location":"PROJECT_SUMMARY/#testing-quality","title":"\ud83e\uddea Testing &amp; Quality","text":"<ul> <li>19 passing unit tests covering core functionality</li> <li>31% code coverage with room for expansion</li> <li>Pre-commit hooks ensuring code quality</li> <li>Type hints throughout the codebase</li> <li>Real cluster testing validated against live K8s cluster</li> </ul>"},{"location":"PROJECT_SUMMARY/#real-world-performance","title":"\ud83d\udcc8 Real-World Performance","text":"<p>Tested against a live cluster with: - 143 CRDs discovered and analyzed with complete specs stored - 9 operators identified and classified with full specifications - 33 OLM CSVs managed with complete metadata - Framework breakdown: Manual operators with OLM management - Database storage: 13.3MB SQLite database with complete resource specifications - Export capability: Full cluster snapshots with spec-level analysis - Sub-second response times for most operations - Datetime serialization: Fixed JSON storage of all Kubernetes timestamps</p>"},{"location":"PROJECT_SUMMARY/#ready-to-use-features","title":"\ud83d\ude80 Ready-to-Use Features","text":""},{"location":"PROJECT_SUMMARY/#cli-commands-available","title":"CLI Commands Available","text":"<pre><code># Connection &amp; cluster info\nk8s-datamodel cluster test-connection\nk8s-datamodel cluster info\nk8s-datamodel cluster summary\n\n# CRD operations\nk8s-datamodel crd list [--group] [--kind] [--scope]\nk8s-datamodel crd get &lt;crd-name&gt;\nk8s-datamodel crd count [--group] [--scope]\n\n# Operator operations  \nk8s-datamodel operators list [--namespace] [--framework]\nk8s-datamodel operators get &lt;name&gt; [--namespace]\nk8s-datamodel operators managed-crds &lt;name&gt;\n\n# OLM operations\nk8s-datamodel olm list [--namespace] [--phase]\nk8s-datamodel olm get &lt;csv-name&gt; [--namespace]\nk8s-datamodel olm stats\n\n# Database operations (NEW)\nk8s-datamodel database store [--notes \"description\"]\nk8s-datamodel database list [--cluster-context] [--limit]\nk8s-datamodel database show &lt;snapshot-id&gt;\nk8s-datamodel database export &lt;snapshot-id&gt; [--file]\nk8s-datamodel database stats\nk8s-datamodel database cleanup [--keep N]\nk8s-datamodel database delete &lt;snapshot-id&gt;\n\n# Export &amp; integration\nk8s-datamodel cluster export [--file] [--output json|yaml]\n</code></pre>"},{"location":"PROJECT_SUMMARY/#installation-options","title":"Installation Options","text":"<pre><code># Via pipx (recommended)\npipx install k8s-datamodel\n\n# Via pip\npip install k8s-datamodel\n\n# Development install\nuv sync &amp;&amp; uv run k8s-datamodel --help\n</code></pre>"},{"location":"PROJECT_SUMMARY/#documentation-package","title":"\ud83d\udcda Documentation Package","text":"<ul> <li>Comprehensive README: Installation, usage examples, architecture</li> <li>MkDocs site: Full documentation with examples and API reference</li> <li>Demo script: Interactive demonstration of all features</li> <li>Architecture diagrams: Mermaid-based visual documentation</li> <li>Contributing guide: Development workflow and standards</li> </ul>"},{"location":"PROJECT_SUMMARY/#bonus-features","title":"\ud83c\udf81 Bonus Features","text":"<ul> <li>Rich terminal output: Beautiful colored tables and panels</li> <li>Database persistence: Complete cluster inventory snapshots with full specs</li> <li>Historical analysis: Compare cluster changes over time</li> <li>OLM integration: Complete ClusterServiceVersion management</li> <li>Verbose modes: Detailed debugging and progress information</li> <li>Flexible configuration: Multiple kubeconfig and context support</li> <li>Datetime handling: Robust serialization of all Kubernetes timestamps</li> <li>Error handling: Graceful degradation and helpful error messages</li> <li>Performance optimized: Efficient API calls and data processing</li> <li>Schema parsing: Deep CRD schema analysis and property extraction</li> <li>Multi-format output: Table, Rich, JSON, YAML support across all operations</li> </ul>"},{"location":"PROJECT_SUMMARY/#the-result","title":"\u2728 The Result","text":"<p>A production-ready CLI tool that provides comprehensive Kubernetes cluster inventory capabilities, following all modern Python development practices and your specific requirements. The tool has been tested against a real cluster and successfully inventoried hundreds of CRDs and dozens of operators with detailed classification and analysis.</p> <p>Perfect for: - Cluster auditing before migrations with complete spec storage - Security assessments of deployed operators with RBAC analysis - Historical tracking of cluster evolution over time - Documentation generation for compliance with full specifications - Configuration drift detection between environments - OLM operator lifecycle management and analysis - Monitoring and alerting on cluster changes with persistent snapshots - Integration with CI/CD pipelines and automated inventory collection - Compliance reporting with historical snapshot data - Deep spec analysis for security and configuration validation</p>"},{"location":"RELEASE_NOTES/","title":"Release Notes - Database &amp; Persistence Update","text":""},{"location":"RELEASE_NOTES/#major-features-added","title":"\ud83c\udf89 Major Features Added","text":""},{"location":"RELEASE_NOTES/#complete-database-functionality","title":"\ud83d\udcca Complete Database Functionality","text":"<p>The k8s-datamodel now includes comprehensive SQLite database support for persistent storage of complete cluster inventories.</p> <p>Key Features: - Complete Spec Storage: Store full Kubernetes resource specifications (CRDs, Operators, CSVs) - Historical Snapshots: Create point-in-time snapshots of your entire cluster state - Multi-cluster Support: Store inventories from multiple clusters in the same database - Advanced Analytics: Query and analyze stored specifications for deep insights</p> <p>Database Size Example: - 143 CRDs with complete specifications - 9 Operators with full deployment/statefulset specs - 33 OLM CSVs with complete metadata - Total Storage: 13.3MB SQLite database</p>"},{"location":"RELEASE_NOTES/#fixed-critical-datetime-serialization-issue","title":"\ud83d\udd27 Fixed Critical Datetime Serialization Issue","text":"<p>Problem Solved: Previously, storing cluster inventories failed with <code>\"Object of type datetime is not JSON serializable\"</code> errors due to Kubernetes timestamp fields.</p> <p>Solution Implemented: - \u2705 Recursive datetime conversion utility for nested data structures - \u2705 Custom JSON encoder with ISO format datetime handling - \u2705 Proper processing of all Kubernetes timestamp fields - \u2705 Robust handling of conditions, managed fields, and metadata timestamps</p> <p>Verification Results: <pre><code>\u2705 SUCCESS: All specs properly serialized!\n   - Checked 5 CRDs\n   - Checked 5 operators  \n   - Checked 5 CSVs\n\n\ud83d\udcca Total resources with specs:\n   - CRDs: 143\n   - Operators: 9\n   - CSVs: 33\n</code></pre></p>"},{"location":"RELEASE_NOTES/#enhanced-olm-operator-lifecycle-manager-support","title":"\ud83d\udcc2 Enhanced OLM (Operator Lifecycle Manager) Support","text":"<p>New Capabilities: - Complete CSV Management: Discovery and analysis of ClusterServiceVersions - Operator Relationship Mapping: Links CSVs to their corresponding operators - Installation Strategy Analysis: Understanding deployment modes and requirements - Permission Analysis: RBAC requirements extraction from CSV specifications - Version Management: Track replaces, skips, and upgrade paths</p>"},{"location":"RELEASE_NOTES/#new-commands-available","title":"\ud83d\ude80 New Commands Available","text":""},{"location":"RELEASE_NOTES/#database-operations","title":"Database Operations","text":"<pre><code># Store complete cluster inventory\nk8s-datamodel database store --notes \"Production cluster snapshot\"\n\n# List all stored snapshots  \nk8s-datamodel database list --cluster-context prod\n\n# View detailed snapshot information\nk8s-datamodel database show 1\n\n# Export snapshot for external analysis\nk8s-datamodel database export 1 --file cluster-snapshot.json\n\n# Database statistics and analytics\nk8s-datamodel database stats\n\n# Cleanup old snapshots\nk8s-datamodel database cleanup --keep 10\n\n# Delete specific snapshot\nk8s-datamodel database delete 2\n</code></pre>"},{"location":"RELEASE_NOTES/#olm-operations","title":"OLM Operations","text":"<pre><code># List ClusterServiceVersions\nk8s-datamodel olm list --phase Succeeded\n\n# Get CSV details\nk8s-datamodel olm get cert-manager.v1.12.0 --namespace operators\n\n# OLM statistics\nk8s-datamodel olm stats\n</code></pre>"},{"location":"RELEASE_NOTES/#advanced-analysis-capabilities","title":"\ud83d\udd0d Advanced Analysis Capabilities","text":""},{"location":"RELEASE_NOTES/#spec-level-analysis","title":"Spec-Level Analysis","text":"<p>With complete resource specifications now stored, you can perform deep analysis:</p> <pre><code># Export with full specifications\nk8s-datamodel database export 1 --include-specs --file full-snapshot.json\n\n# Query security contexts from operators\njq '.operators[] | {name: .name, security_context: .spec.spec.template.spec.containers[0].securityContext}' full-snapshot.json\n\n# Extract RBAC permissions from CSVs  \njq '.csvs[] | {name: .name, permissions: .spec.spec.install.spec.permissions}' full-snapshot.json\n\n# Find operators without resource limits\njq '.operators[] | select(.spec.spec.template.spec.containers[0].resources.limits == null) | .name' full-snapshot.json\n</code></pre>"},{"location":"RELEASE_NOTES/#configuration-drift-detection","title":"Configuration Drift Detection","text":"<pre><code># Store baseline snapshot\nk8s-datamodel database store --notes \"Baseline configuration\"\n\n# After changes, store another snapshot\nk8s-datamodel database store --notes \"After configuration changes\"\n\n# Export both for comparison\nk8s-datamodel database export 1 --file baseline.json\nk8s-datamodel database export 2 --file current.json\n\n# Compare configurations\ndiff &lt;(jq -S . baseline.json) &lt;(jq -S . current.json)\n</code></pre>"},{"location":"RELEASE_NOTES/#architecture-enhancements","title":"\ud83c\udfd7\ufe0f Architecture Enhancements","text":""},{"location":"RELEASE_NOTES/#database-schema","title":"Database Schema","text":"<p>New SQLite schema with complete spec storage:</p> <pre><code>-- Enhanced tables with spec columns\ncrds (id, snapshot_id, name, group_name, ..., spec)\noperators (id, snapshot_id, name, namespace, ..., spec)  \ncsvs (id, snapshot_id, name, namespace, ..., spec)\n\n-- Automatic schema migrations\n-- Version 1 \u2192 Version 2 with spec columns added\n</code></pre>"},{"location":"RELEASE_NOTES/#datetime-handling-flow","title":"Datetime Handling Flow","text":"<pre><code>graph LR\n    A[Kubernetes API] --&gt; B[Resource Objects]\n    B --&gt; C[Datetime Conversion]\n    C --&gt; D[JSON Serialization]\n    D --&gt; E[Database Storage]\n\n    C --&gt; F[convert_datetime_in_dict]\n    F --&gt; G[Recursive Processing]\n    G --&gt; H[ISO Format Strings]</code></pre>"},{"location":"RELEASE_NOTES/#storage-and-performance","title":"\ud83d\udcbe Storage and Performance","text":""},{"location":"RELEASE_NOTES/#database-metrics","title":"Database Metrics","text":"<ul> <li>Storage Efficiency: Complete cluster specs in 13.3MB SQLite database</li> <li>Query Performance: Indexed tables for fast snapshot retrieval</li> <li>Concurrent Access: SQLite handles multiple readers safely</li> <li>Backup Friendly: Single file database for easy backup/restore</li> </ul>"},{"location":"RELEASE_NOTES/#performance-optimizations","title":"Performance Optimizations","text":"<ul> <li>Efficient Serialization: Custom datetime encoder with depth limiting</li> <li>Batch Operations: Multi-resource database insertions</li> <li>Proper Indexing: Optimized queries for common access patterns</li> <li>Memory Management: Streaming processing for large clusters</li> </ul>"},{"location":"RELEASE_NOTES/#use-cases-enabled","title":"\ud83c\udfaf Use Cases Enabled","text":""},{"location":"RELEASE_NOTES/#1-compliance-and-auditing","title":"1. Compliance and Auditing","text":"<pre><code># Store pre-audit snapshot\nk8s-datamodel database store --notes \"Pre-compliance audit\"\n\n# Generate compliance report\nk8s-datamodel database export 1 --output json | \\\n  jq '.operators[] | select(.spec.spec.template.spec.securityContext.privileged == true)'\n</code></pre>"},{"location":"RELEASE_NOTES/#2-migration-planning","title":"2. Migration Planning","text":"<pre><code># Store source cluster snapshot\nk8s-datamodel --context source-cluster database store --notes \"Migration source\"\n\n# Store target cluster snapshot after migration\nk8s-datamodel --context target-cluster database store --notes \"Migration target\"\n\n# Compare for validation\nk8s-datamodel database export 1 --file source.json\nk8s-datamodel database export 2 --file target.json\n</code></pre>"},{"location":"RELEASE_NOTES/#3-security-assessment","title":"3. Security Assessment","text":"<pre><code># Store current state\nk8s-datamodel database store --notes \"Security baseline\"\n\n# Analyze privileged operators\nk8s-datamodel database export 1 --output json | \\\n  jq '.operators[] | select(.spec.spec.template.spec.containers[0].securityContext.privileged == true)'\n\n# Check for host network access\nk8s-datamodel database export 1 --output json | \\\n  jq '.operators[] | select(.spec.spec.template.spec.hostNetwork == true)'\n</code></pre>"},{"location":"RELEASE_NOTES/#4-automated-monitoring","title":"4. Automated Monitoring","text":"<pre><code>#!/bin/bash\n# Daily inventory collection\nk8s-datamodel database store --notes \"Daily snapshot - $(date)\"\n\n# Check database size and cleanup\nk8s-datamodel database stats\nk8s-datamodel database cleanup --keep 30\n</code></pre>"},{"location":"RELEASE_NOTES/#migration-and-upgrade","title":"\ud83d\udd27 Migration and Upgrade","text":""},{"location":"RELEASE_NOTES/#automatic-database-migration","title":"Automatic Database Migration","text":"<ul> <li>Existing databases automatically upgrade from schema v1 to v2</li> <li>New <code>spec</code> columns added to all resource tables  </li> <li>No data loss during migration</li> <li>Backward compatibility maintained</li> </ul>"},{"location":"RELEASE_NOTES/#breaking-changes","title":"Breaking Changes","text":"<ul> <li>None: All existing functionality preserved</li> <li>Additions Only: New database features are additive</li> <li>CLI Compatibility: All existing commands work unchanged</li> </ul>"},{"location":"RELEASE_NOTES/#documentation-updates","title":"\ud83d\udcda Documentation Updates","text":""},{"location":"RELEASE_NOTES/#updated-documentation","title":"Updated Documentation","text":"<ul> <li>\u2705 docs/usage/database.md: Complete database operations guide</li> <li>\u2705 docs/PROJECT_SUMMARY.md: Updated architecture and features</li> <li>\u2705 CHANGELOG.md: Detailed change log</li> <li>\u2705 docs/RELEASE_NOTES.md: This document</li> </ul>"},{"location":"RELEASE_NOTES/#new-examples-added","title":"New Examples Added","text":"<ul> <li>Database workflow examples</li> <li>Advanced analysis scripts</li> <li>CI/CD integration patterns  </li> <li>Multi-cluster management examples</li> </ul>"},{"location":"RELEASE_NOTES/#testing-and-validation","title":"\ud83e\uddea Testing and Validation","text":""},{"location":"RELEASE_NOTES/#comprehensive-testing","title":"Comprehensive Testing","text":"<ul> <li>\u2705 Database schema migration testing</li> <li>\u2705 Datetime serialization validation  </li> <li>\u2705 Spec storage and retrieval testing</li> <li>\u2705 Multi-cluster scenario validation</li> <li>\u2705 Real cluster testing with 143 CRDs, 9 operators, 33 CSVs</li> </ul>"},{"location":"RELEASE_NOTES/#validation-results","title":"Validation Results","text":"<pre><code>\u2713 Database found: /Users/user/.k8s-inventory/inventory.db\n\u2713 Database size: 13.3 MB\n\u2713 All CRD specs deserialized successfully\n\u2713 All operator specs deserialized successfully  \n\u2713 All CSV specs deserialized successfully\n\n\u2705 SUCCESS: All specs properly serialized!\n</code></pre>"},{"location":"RELEASE_NOTES/#getting-started","title":"\ud83d\ude80 Getting Started","text":""},{"location":"RELEASE_NOTES/#immediate-usage","title":"Immediate Usage","text":"<pre><code># Store your first snapshot\nk8s-datamodel database store --notes \"My first snapshot\"\n\n# View stored snapshots\nk8s-datamodel database list\n\n# Get database statistics\nk8s-datamodel database stats\n</code></pre>"},{"location":"RELEASE_NOTES/#advanced-features","title":"Advanced Features","text":"<pre><code># Multi-cluster storage\nk8s-datamodel --context prod database store --notes \"Production\"\nk8s-datamodel --context dev database store --notes \"Development\"\n\n# Export with full specs for analysis\nk8s-datamodel database export 1 --include-specs --file analysis.json\n\n# Cleanup old snapshots\nk8s-datamodel database cleanup --keep 10\n</code></pre>"},{"location":"RELEASE_NOTES/#whats-next","title":"\ud83c\udfaf What's Next","text":"<p>This release establishes the foundation for advanced cluster analysis and historical tracking. Future enhancements may include:</p> <ul> <li>Query Language: SQL-like queries for stored specifications</li> <li>Visualization: Graphical analysis of cluster evolution  </li> <li>Alerting: Automated change detection and notifications</li> <li>Integration: Enhanced CI/CD and GitOps workflows</li> <li>Reporting: Advanced compliance and security report generation</li> </ul> <p>The k8s-datamodel now provides comprehensive, persistent cluster inventory capabilities with complete resource specification storage and robust datetime handling. Perfect for production cluster management, compliance tracking, and deep Kubernetes analysis! \ud83c\udf89</p>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#040-2025-09-07","title":"[0.4.0] - 2025-09-07","text":""},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Breaking Change: Renamed project from <code>k8s-inventory-cli</code> to <code>k8s-datamodel</code></li> <li>Updated CLI command from <code>k8s-inventory</code> to <code>k8s-datamodel</code></li> <li>Updated project name throughout codebase and documentation</li> <li>Enhanced mkdocs configuration with version tracking</li> </ul>"},{"location":"changelog/#030-previous-release","title":"[0.3.0] - Previous Release","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Complete Database Functionality: Full SQLite database support for persistent cluster inventory storage</li> <li>Store complete CRD, Operator, and CSV specifications in database</li> <li>Comprehensive snapshot management (create, list, view, export, delete)</li> <li>Multi-cluster support with cluster context tracking</li> <li>Database statistics and storage analytics</li> <li> <p>Historical tracking and comparison capabilities</p> </li> <li> <p>Enhanced OLM Support: Complete Operator Lifecycle Manager integration</p> </li> <li>ClusterServiceVersion (CSV) discovery and analysis</li> <li>OLM operator relationship mapping to deployments</li> <li>Installation strategy and permission analysis</li> <li> <p>Version management tracking (replaces, skips, upgrade paths)</p> </li> <li> <p>Full Spec Storage: Complete Kubernetes resource specification persistence</p> </li> <li>CRD specifications with metadata, spec, status, and schema details</li> <li>Operator specifications from deployments and statefulsets</li> <li>CSV specifications with complete OLM metadata</li> <li>Deep analysis capabilities for stored specifications</li> </ul>"},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Datetime Serialization: Resolved \"Object of type datetime is not JSON serializable\" errors</li> <li>Added recursive datetime conversion utility for nested data structures</li> <li>Enhanced JSON serialization with custom DateTimeEncoder</li> <li>Proper handling of Kubernetes timestamp fields in all resource specs</li> <li>Robust datetime processing for conditions, managed fields, and metadata timestamps</li> </ul>"},{"location":"changelog/#enhanced","title":"Enhanced","text":"<ul> <li>Database Operations: Complete set of database management commands</li> <li><code>database store</code>: Store complete cluster inventory snapshots</li> <li><code>database list</code>: List all stored snapshots with filtering</li> <li><code>database show</code>: View detailed snapshot information</li> <li><code>database export</code>: Export snapshots to JSON/YAML files</li> <li><code>database stats</code>: Database statistics and storage analytics</li> <li><code>database cleanup</code>: Manage database size and old snapshots</li> <li> <p><code>database delete</code>: Remove specific snapshots</p> </li> <li> <p>Spec Analysis: Deep analysis capabilities for stored specifications</p> </li> <li>Security context analysis from operator specs</li> <li>RBAC permission extraction from CSV specs</li> <li>Resource requirements analysis from container specs</li> <li>Configuration drift detection between snapshots</li> <li>Custom analysis script support</li> </ul>"},{"location":"changelog/#performance","title":"Performance","text":"<ul> <li>Optimized Storage: Efficient storage of large resource specifications</li> <li>SQLite database with proper indexing for query performance</li> <li>Recursive datetime conversion with depth limiting</li> <li>Compressed JSON storage for specifications</li> <li>Efficient multi-resource batch operations</li> </ul>"},{"location":"changelog/#testing","title":"Testing","text":"<ul> <li>Enhanced Test Coverage: Comprehensive testing of new functionality</li> <li>Database schema migration testing</li> <li>Datetime serialization validation</li> <li>Spec storage and retrieval testing</li> <li>Multi-cluster scenario testing</li> </ul>"},{"location":"changelog/#previous-initial-release","title":"[Previous] - Initial Release","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>CRD Inventory: Complete Custom Resource Definition discovery and analysis</li> <li>Operator Detection: Smart identification of operators from deployments/statefulsets</li> <li>Framework Classification: Detection of Helm, OLM, and Manual deployments</li> <li>Multi-format Output: Table, Rich, JSON, and YAML output formats</li> <li>Cluster Operations: Connection testing, info, and summary commands</li> <li>Export Functionality: Complete cluster inventory export capabilities</li> <li>CLI Framework: Comprehensive Click-based command line interface</li> </ul>"},{"location":"changelog/#features","title":"Features","text":"<ul> <li>Python 3.10+ support with UV package management</li> <li>Rich terminal output with colors and styling</li> <li>Kubeconfig and context flexibility</li> <li>Error handling and verbose modes</li> <li>Real-time cluster analysis</li> <li>Framework detection and classification</li> <li>Resource counting and statistics</li> </ul>"},{"location":"changelog/#technical-details","title":"Technical Details","text":""},{"location":"changelog/#database-schema-version-2","title":"Database Schema Version: 2","text":"<ul> <li>Added <code>spec</code> columns to <code>crds</code>, <code>operators</code>, and <code>csvs</code> tables</li> <li>Automatic schema migration from version 1 to version 2</li> <li>Proper datetime handling throughout the schema</li> </ul>"},{"location":"changelog/#supported-kubernetes-resources","title":"Supported Kubernetes Resources","text":"<ul> <li>CRDs: Complete CustomResourceDefinition specs with OpenAPI schemas</li> <li>Operators: Deployment and StatefulSet specs with container configurations</li> <li>CSVs: ClusterServiceVersion specs with installation and permission details</li> </ul>"},{"location":"changelog/#storage-capabilities","title":"Storage Capabilities","text":"<ul> <li>Full Specifications: Complete Kubernetes resource manifests</li> <li>Metadata Preservation: All labels, annotations, and timestamps</li> <li>Relationship Mapping: Links between operators, CRDs, and CSVs</li> <li>Historical Snapshots: Point-in-time cluster state preservation</li> </ul>"},{"location":"changelog/#analysis-features","title":"Analysis Features","text":"<ul> <li>Configuration Analysis: Deep inspection of resource configurations</li> <li>Security Assessment: Security context and RBAC permission analysis</li> <li>Drift Detection: Compare configurations between snapshots</li> <li>Compliance Reporting: Generate compliance reports from stored data</li> </ul> <p>For migration guides, usage examples, and detailed documentation, see the docs/ directory.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Thank you for your interest in contributing to k8s-datamodel!</p>"},{"location":"contributing/#development-setup","title":"Development Setup","text":""},{"location":"contributing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10+</li> <li>Poetry for dependency management</li> <li>Access to a Kubernetes cluster for testing</li> </ul>"},{"location":"contributing/#installation","title":"Installation","text":"<pre><code># Clone the repository\ngit clone https://github.com/brun-s/k8s-datamodel.git\ncd k8s-datamodel\n\n# Install dependencies using uv\nuv sync\n\n# Install pre-commit hooks\npre-commit install\n</code></pre>"},{"location":"contributing/#development-workflow","title":"Development Workflow","text":""},{"location":"contributing/#code-style","title":"Code Style","text":"<p>This project follows the conventions: - Use conventional commits for commit messages - Pre-commit hooks for code formatting and linting - Unit tests for all new features</p>"},{"location":"contributing/#testing","title":"Testing","text":"<pre><code># Run unit tests\npytest\n\n# Run with coverage\npytest --cov=src/k8s_inventory_cli\n</code></pre>"},{"location":"contributing/#commit-messages","title":"Commit Messages","text":"<p>We use Conventional Commits:</p> <pre><code>feat: add new database export feature\nfix: resolve issue with CRD parsing\ndocs: update API documentation\ntest: add unit tests for operators module\n</code></pre>"},{"location":"contributing/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch from <code>main</code></li> <li>Make your changes following the coding standards</li> <li>Add/update tests for your changes</li> <li>Update documentation as needed</li> <li>Submit a pull request with a clear description</li> </ol>"},{"location":"contributing/#documentation","title":"Documentation","text":"<ul> <li>Use MkDocs with Material theme</li> <li>Update relevant documentation for any changes</li> <li>Include examples and use cases</li> <li>Test documentation builds locally:</li> </ul> <pre><code>mkdocs serve\n</code></pre>"},{"location":"contributing/#project-structure","title":"Project Structure","text":"<pre><code>src/\n  k8s_inventory_cli/           # Main package\n    commands/                  # CLI command modules\n    core/                      # Core functionality\n    exporters/                 # Export format handlers\n    inventory/                 # Inventory collection logic\ndocs/                          # Documentation\n  examples/                    # Comprehensive examples\n  usage/                       # Usage guides\n  api/                         # API reference\ntests/                         # Unit tests\n</code></pre>"},{"location":"contributing/#release-process","title":"Release Process","text":"<ol> <li>Update version in <code>pyproject.toml</code></li> <li>Update CHANGELOG.md</li> <li>Create a git tag using conventional commit format</li> <li>GitHub Actions handles the rest:</li> <li>Generates changelog</li> <li>Updates mkdocs.yml and docs/index.md</li> <li>Publishes to PyPI</li> <li>Deploys documentation</li> </ol>"},{"location":"contributing/#questions-or-issues","title":"Questions or Issues?","text":"<ul> <li>Open an issue for bug reports or feature requests</li> <li>Start a discussion for questions or ideas</li> <li>Check existing issues before creating new ones</li> </ul> <p>We appreciate all contributions, big and small! \ud83c\udf89</p>"},{"location":"examples/","title":"Examples","text":"<p>This section provides comprehensive, real-world examples demonstrating the powerful capabilities of k8s-datamodel for managing, analyzing, and monitoring Kubernetes clusters.</p>"},{"location":"examples/#database-workflows","title":"\ud83d\udcca Database Workflows","text":"<p>Database Workflows Examples</p> <p>Comprehensive examples covering database operations including: - Snapshot management and storage - Multi-cluster environment management - Configuration drift detection - Compliance auditing workflows - Migration planning and verification - CI/CD integration patterns - Automated monitoring and trend analysis</p>"},{"location":"examples/#olm-management","title":"\ud83d\udd27 OLM Management","text":"<p>OLM Workflows Examples</p> <p>Extensive Operator Lifecycle Manager (OLM) management examples: - Basic OLM operations and CSV analysis - Operator lifecycle management - RBAC and security analysis - Upgrade and version management - Multi-environment OLM management - Troubleshooting and diagnostics - Monitoring integration</p>"},{"location":"examples/#security-compliance","title":"\ud83d\udd10 Security &amp; Compliance","text":"<p>Security &amp; Compliance Analysis</p> <p>Enterprise-grade security and compliance workflows: - Security baseline establishment and validation - RBAC analysis and auditing - Security context analysis - SOC 2 and PCI DSS compliance reporting - Vulnerability assessment workflows - Automated security monitoring - Multi-channel alerting integration</p>"},{"location":"examples/#getting-started","title":"Getting Started","text":"<p>Each example section includes:</p> <ul> <li>\u2705 Ready-to-use scripts - Copy and execute directly</li> <li>\ud83d\udccb Detailed explanations - Understand the concepts</li> <li>\ud83d\udd27 Customization guidance - Adapt to your environment</li> <li>\ud83d\udcca Sample outputs - Know what to expect</li> <li>\ud83d\udea8 Best practices - Follow enterprise standards</li> </ul>"},{"location":"examples/#prerequisites","title":"Prerequisites","text":"<p>Most examples assume: - k8s-datamodel is installed and configured - Access to a Kubernetes cluster - Basic familiarity with <code>kubectl</code> and <code>jq</code> - For advanced examples: understanding of your compliance requirements</p>"},{"location":"examples/#example-types","title":"Example Types","text":""},{"location":"examples/#basic-examples","title":"Basic Examples","text":"<p>Simple, single-command examples perfect for getting started.</p>"},{"location":"examples/#workflow-examples","title":"Workflow Examples","text":"<p>Multi-step processes that combine multiple commands to achieve complex goals.</p>"},{"location":"examples/#enterprise-examples","title":"Enterprise Examples","text":"<p>Production-ready scripts with error handling, logging, and integration patterns.</p>"},{"location":"examples/#integration-examples","title":"Integration Examples","text":"<p>Examples showing how to integrate k8s-datamodel with other tools and systems.</p> <p>Choose the section that best matches your current needs, or start with the database workflows to understand the foundational concepts.</p>"},{"location":"api/cli/","title":"CLI Commands Reference","text":"<p>Complete API reference for all K8s Inventory CLI commands, options, and parameters.</p>"},{"location":"api/cli/#global-options","title":"Global Options","text":"<p>These options are available for all commands:</p> <pre><code>k8s-datamodel [GLOBAL_OPTIONS] COMMAND [COMMAND_OPTIONS]\n</code></pre>"},{"location":"api/cli/#global-parameters","title":"Global Parameters","text":"Option Short Description Default <code>--kubeconfig</code> <code>-k</code> Path to kubeconfig file <code>$HOME/.kube/config</code> <code>--context</code> <code>-c</code> Kubernetes context to use Current context <code>--namespace</code> <code>-n</code> Default namespace for operations <code>default</code> <code>--verbose</code> <code>-v</code> Enable verbose output <code>false</code> <code>--quiet</code> <code>-q</code> Suppress non-essential output <code>false</code> <code>--help</code> <code>-h</code> Show help information - <code>--version</code> Show version information -"},{"location":"api/cli/#output-options","title":"Output Options","text":"<p>Available for most commands:</p> Option Values Description Default <code>--output</code> <code>table</code>, <code>rich</code>, <code>json</code>, <code>yaml</code> Output format <code>table</code> <code>--sort-by</code> Column name Sort output by column - <code>--no-headers</code> Suppress table headers <code>false</code>"},{"location":"api/cli/#cluster-commands","title":"Cluster Commands","text":"<p>Commands for cluster-wide operations.</p>"},{"location":"api/cli/#cluster-test-connection","title":"<code>cluster test-connection</code>","text":"<p>Test connectivity to the Kubernetes cluster.</p> <pre><code>k8s-datamodel cluster test-connection [OPTIONS]\n</code></pre> <p>Options: - <code>--timeout DURATION</code>: Connection timeout (default: 30s) - <code>--verbose</code>: Show detailed connection information</p> <p>Exit Codes: - <code>0</code>: Connection successful - <code>1</code>: Connection failed - <code>2</code>: Authentication failed - <code>3</code>: Permission denied</p> <p>Examples: <pre><code>k8s-datamodel cluster test-connection\nk8s-datamodel cluster test-connection --timeout 60s --verbose\n</code></pre></p>"},{"location":"api/cli/#cluster-info","title":"<code>cluster info</code>","text":"<p>Display detailed cluster information.</p> <pre><code>k8s-datamodel cluster info [OPTIONS]\n</code></pre> <p>Output includes: - Kubernetes version - API server endpoint - Node count and status - Available API resources - Authentication method</p> <p>Examples: <pre><code>k8s-datamodel cluster info\nk8s-datamodel cluster info --output json\n</code></pre></p>"},{"location":"api/cli/#cluster-summary","title":"<code>cluster summary</code>","text":"<p>Generate statistical summary of cluster resources.</p> <pre><code>k8s-datamodel cluster summary [OPTIONS]\n</code></pre> <p>Output includes: - CRD statistics (count, groups, scopes) - Operator analysis (frameworks, health) - Resource utilization metrics - Deployment pattern analysis</p> <p>Examples: <pre><code>k8s-datamodel cluster summary\nk8s-datamodel cluster summary --output yaml\n</code></pre></p>"},{"location":"api/cli/#cluster-export","title":"<code>cluster export</code>","text":"<p>Export complete cluster inventory.</p> <pre><code>k8s-datamodel cluster export [OPTIONS]\n</code></pre> <p>Options: - <code>--file PATH</code>: Output file path (default: stdout) - <code>--include-instances</code>: Include custom resource instances - <code>--compress</code>: Compress output file</p> <p>Examples: <pre><code>k8s-datamodel cluster export --file inventory.json\nk8s-datamodel cluster export --output yaml --file inventory.yaml\nk8s-datamodel cluster export --compress --file inventory.json.gz\n</code></pre></p>"},{"location":"api/cli/#crd-commands","title":"CRD Commands","text":"<p>Commands for Custom Resource Definition management.</p>"},{"location":"api/cli/#crd-list","title":"<code>crd list</code>","text":"<p>List Custom Resource Definitions with filtering.</p> <pre><code>k8s-datamodel crd list [OPTIONS]\n</code></pre> <p>Filtering Options: - <code>--group GROUP</code>: Filter by API group - <code>--kind KIND</code>: Filter by resource kind - <code>--scope SCOPE</code>: Filter by scope (<code>Namespaced</code> or <code>Cluster</code>) - <code>--category CATEGORY</code>: Filter by category - <code>--framework FRAMEWORK</code>: Filter by deployment framework</p> <p>Display Options: - <code>--show-instances</code>: Show instance counts - <code>--show-versions</code>: Show all versions - <code>--show-categories</code>: Show categories - <code>--age-format FORMAT</code>: Age display format (<code>days</code>, <code>hours</code>, <code>duration</code>)</p> <p>Examples: <pre><code>k8s-datamodel crd list\nk8s-datamodel crd list --group cert-manager.io\nk8s-datamodel crd list --scope Cluster --output json\nk8s-datamodel crd list --kind Certificate --show-instances\n</code></pre></p>"},{"location":"api/cli/#crd-get","title":"<code>crd get</code>","text":"<p>Get detailed information about a specific CRD.</p> <pre><code>k8s-datamodel crd get CRD_NAME [OPTIONS]\n</code></pre> <p>Arguments: - <code>CRD_NAME</code>: Full CRD name (e.g., <code>certificates.cert-manager.io</code>)</p> <p>Options: - <code>--show-spec</code>: Include full CRD specification - <code>--show-status</code>: Include status information - <code>--version VERSION</code>: Show specific version details</p> <p>Examples: <pre><code>k8s-datamodel crd get certificates.cert-manager.io\nk8s-datamodel crd get certificates.cert-manager.io --show-spec --output yaml\n</code></pre></p>"},{"location":"api/cli/#crd-count","title":"<code>crd count</code>","text":"<p>Count custom resource instances for each CRD.</p> <pre><code>k8s-datamodel crd count [OPTIONS]\n</code></pre> <p>Filtering Options: - <code>--group GROUP</code>: Filter by API group - <code>--scope SCOPE</code>: Filter by scope - <code>--namespace NAMESPACE</code>: Count instances in specific namespace</p> <p>Display Options: - <code>--zero-instances</code>: Include CRDs with zero instances - <code>--sort-by-count</code>: Sort by instance count</p> <p>Examples: <pre><code>k8s-datamodel crd count\nk8s-datamodel crd count --group networking.k8s.io\nk8s-datamodel crd count --zero-instances --output json\n</code></pre></p>"},{"location":"api/cli/#operator-commands","title":"Operator Commands","text":"<p>Commands for Kubernetes operator management.</p>"},{"location":"api/cli/#operators-list","title":"<code>operators list</code>","text":"<p>List detected operators with classification.</p> <pre><code>k8s-datamodel operators list [OPTIONS]\n</code></pre> <p>Filtering Options: - <code>--namespace NAMESPACE</code>: Filter by namespace - <code>--framework FRAMEWORK</code>: Filter by framework (<code>OLM</code>, <code>Helm</code>, <code>Manual</code>) - <code>--status STATUS</code>: Filter by health status (<code>Healthy</code>, <code>Degraded</code>, <code>Failed</code>) - <code>--all-namespaces</code>: Search across all namespaces</p> <p>Display Options: - <code>--show-images</code>: Show container images - <code>--show-resources</code>: Show resource requirements - <code>--show-conditions</code>: Show pod conditions - <code>--group-by-namespace</code>: Group output by namespace</p> <p>Examples: <pre><code>k8s-datamodel operators list\nk8s-datamodel operators list --namespace kube-system\nk8s-datamodel operators list --framework OLM --output json\nk8s-datamodel operators list --all-namespaces --show-images\n</code></pre></p>"},{"location":"api/cli/#operators-get","title":"<code>operators get</code>","text":"<p>Get detailed information about a specific operator.</p> <pre><code>k8s-datamodel operators get OPERATOR_NAME [OPTIONS]\n</code></pre> <p>Arguments: - <code>OPERATOR_NAME</code>: Name of the operator</p> <p>Options: - <code>--namespace NAMESPACE</code>: Operator namespace - <code>--show-pods</code>: Include pod details - <code>--show-logs</code>: Include recent log entries - <code>--show-events</code>: Include related events</p> <p>Examples: <pre><code>k8s-datamodel operators get cert-manager --namespace cert-manager\nk8s-datamodel operators get prometheus-operator --show-pods --output yaml\n</code></pre></p>"},{"location":"api/cli/#operators-managed-crds","title":"<code>operators managed-crds</code>","text":"<p>Show CRDs managed by a specific operator.</p> <pre><code>k8s-datamodel operators managed-crds OPERATOR_NAME [OPTIONS]\n</code></pre> <p>Arguments: - <code>OPERATOR_NAME</code>: Name of the operator</p> <p>Options: - <code>--namespace NAMESPACE</code>: Operator namespace - <code>--show-instances</code>: Show instance counts for each CRD - <code>--include-versions</code>: Show all CRD versions</p> <p>Examples: <pre><code>k8s-datamodel operators managed-crds cert-manager\nk8s-datamodel operators managed-crds istio-pilot --show-instances --output json\n</code></pre></p>"},{"location":"api/cli/#common-parameters","title":"Common Parameters","text":""},{"location":"api/cli/#filtering-expressions","title":"Filtering Expressions","text":"<p>Many commands support advanced filtering:</p> <pre><code># Multiple values (OR logic)\n--group \"cert-manager.io,networking.k8s.io\"\n\n# Wildcard patterns  \n--group \"*.coreos.com\"\n\n# Negation\n--group \"!kustomize.config.k8s.io\"\n\n# Combined filters (AND logic)\n--group cert-manager.io --scope Namespaced\n</code></pre>"},{"location":"api/cli/#output-formatting","title":"Output Formatting","text":""},{"location":"api/cli/#table-format-options","title":"Table Format Options","text":"<ul> <li><code>--no-headers</code>: Suppress column headers</li> <li><code>--sort-by COLUMN</code>: Sort by specific column</li> <li><code>--max-width WIDTH</code>: Maximum column width</li> </ul>"},{"location":"api/cli/#json-format-options","title":"JSON Format Options","text":"<ul> <li><code>--pretty</code>: Pretty-print JSON output</li> <li><code>--compact</code>: Compact JSON output</li> </ul>"},{"location":"api/cli/#yaml-format-options","title":"YAML Format Options","text":"<ul> <li><code>--flow-style</code>: Use flow style for sequences</li> </ul>"},{"location":"api/cli/#time-formats","title":"Time Formats","text":"<p>Age and timestamp formatting options:</p> <pre><code># Age display formats\n--age-format days     # \"30d\"\n--age-format hours    # \"720h\"  \n--age-format duration # \"30d12h45m\"\n\n# Timestamp formats\n--timestamp-format rfc3339 # \"2024-01-15T10:30:00Z\"\n--timestamp-format unix    # \"1705312200\"\n--timestamp-format local   # \"2024-01-15 10:30:00\"\n</code></pre>"},{"location":"api/cli/#environment-variables","title":"Environment Variables","text":"<p>Configuration via environment variables:</p> Variable Description Default <code>KUBECONFIG</code> Path to kubeconfig file <code>$HOME/.kube/config</code> <code>K8S_INVENTORY_CONTEXT</code> Default Kubernetes context Current context <code>K8S_INVENTORY_OUTPUT</code> Default output format <code>table</code> <code>K8S_INVENTORY_NAMESPACE</code> Default namespace <code>default</code> <code>K8S_INVENTORY_TIMEOUT</code> Default timeout duration <code>30s</code> <code>NO_COLOR</code> Disable colored output <code>false</code> <code>COLUMNS</code> Terminal width override Auto-detected"},{"location":"api/cli/#configuration-files","title":"Configuration Files","text":""},{"location":"api/cli/#config-file-locations","title":"Config File Locations","text":"<p>K8s Inventory CLI looks for configuration files in:</p> <ol> <li><code>$HOME/.k8s-inventory/config.yaml</code></li> <li><code>$XDG_CONFIG_HOME/k8s-inventory/config.yaml</code></li> <li><code>/etc/k8s-inventory/config.yaml</code></li> </ol>"},{"location":"api/cli/#config-file-format","title":"Config File Format","text":"<pre><code># ~/.k8s-inventory/config.yaml\ndefaults:\n  output: table\n  kubeconfig: ~/.kube/config\n  timeout: 30s\n\nfilters:\n  exclude_groups:\n    - \"kustomize.config.k8s.io\"\n    - \"internal.example.com\"\n\ndisplay:\n  max_width: 120\n  show_age: true\n  timestamp_format: rfc3339\n\naliases:\n  crds: crd list\n  ops: operators list\n  summary: cluster summary\n</code></pre>"},{"location":"api/cli/#exit-codes","title":"Exit Codes","text":"<p>Standard exit codes used by all commands:</p> Code Meaning <code>0</code> Success <code>1</code> General error <code>2</code> Authentication error <code>3</code> Permission denied <code>4</code> Resource not found <code>5</code> Connection timeout <code>6</code> Invalid configuration <code>7</code> Invalid arguments <code>8</code> Resource conflict"},{"location":"api/cli/#error-handling","title":"Error Handling","text":""},{"location":"api/cli/#common-error-messages","title":"Common Error Messages","text":"<p>Connection Errors: <pre><code>Error: Failed to connect to cluster\nCause: Unable to reach API server at https://k8s.example.com\nSolution: Check network connectivity and cluster status\n</code></pre></p> <p>Authentication Errors: <pre><code>Error: Authentication failed\nCause: Invalid or expired credentials\nSolution: Update kubeconfig or refresh authentication tokens\n</code></pre></p> <p>Permission Errors: <pre><code>Error: Insufficient permissions\nCause: Missing RBAC permissions for CustomResourceDefinitions\nSolution: Grant required permissions or use different credentials\n</code></pre></p>"},{"location":"api/cli/#troubleshooting-commands","title":"Troubleshooting Commands","text":"<pre><code># Test basic connectivity\nk8s-datamodel cluster test-connection --verbose\n\n# Check authentication\nkubectl auth whoami\n\n# Verify permissions\nkubectl auth can-i get customresourcedefinitions\nkubectl auth can-i list deployments --all-namespaces\n</code></pre>"},{"location":"api/cli/#shell-completion","title":"Shell Completion","text":"<p>Enable shell completion for enhanced CLI experience:</p>"},{"location":"api/cli/#bash","title":"Bash","text":"<pre><code># Install completion\nk8s-datamodel completion bash &gt; /etc/bash_completion.d/k8s-inventory\n\n# Or for user only\nk8s-datamodel completion bash &gt; ~/.local/share/bash-completion/completions/k8s-inventory\n</code></pre>"},{"location":"api/cli/#zsh","title":"Zsh","text":"<pre><code># Install completion\nk8s-datamodel completion zsh &gt; \"${fpath[1]}/_k8s-inventory\"\n</code></pre>"},{"location":"api/cli/#fish","title":"Fish","text":"<pre><code>k8s-datamodel completion fish &gt; ~/.config/fish/completions/k8s-inventory.fish\n</code></pre>"},{"location":"api/cli/#advanced-usage","title":"Advanced Usage","text":""},{"location":"api/cli/#scripting-integration","title":"Scripting Integration","text":"<pre><code>#!/bin/bash\n# Example automation script\n\n# Set error handling\nset -euo pipefail\n\n# Export inventory with error handling\nif ! k8s-datamodel cluster export --file inventory.json; then\n  echo \"Failed to export cluster inventory\" &gt;&amp;2\n  exit 1\nfi\n\n# Process with jq\nCRITICAL_OPERATORS=$(k8s-datamodel operators list --output json | \\\n  jq -r '.[] | select(.framework == \"OLM\" and .replicas.ready != .replicas.desired) | .name')\n\nif [[ -n \"$CRITICAL_OPERATORS\" ]]; then\n  echo \"Critical operators unhealthy: $CRITICAL_OPERATORS\" &gt;&amp;2\n  exit 1\nfi\n</code></pre>"},{"location":"api/cli/#monitoring-integration","title":"Monitoring Integration","text":"<pre><code># Prometheus metrics export\nk8s-datamodel cluster summary --output json | \\\n  jq -r '\n    \"k8s_inventory_crds_total \" + (.crds.total | tostring),\n    \"k8s_inventory_operators_total \" + (.operators.total | tostring),\n    \"k8s_inventory_operators_healthy \" + (.operators.healthy | tostring),\n    \"k8s_inventory_last_scan \" + (now | tostring)\n  '\n</code></pre>"},{"location":"api/cli/#related-documentation","title":"Related Documentation","text":"<ul> <li>Quick Start Guide: Getting started with the CLI</li> <li>Output Formats: Detailed format specifications</li> <li>Core Modules: API reference for core functionality</li> </ul>"},{"location":"api/core/","title":"Core Modules Reference","text":"<p>API reference for the core Python modules that power K8s Inventory CLI.</p>"},{"location":"api/core/#overview","title":"Overview","text":"<p>The core modules provide the underlying functionality for Kubernetes cluster inventory and analysis. These modules can be imported and used directly in Python applications.</p>"},{"location":"api/core/#module-architecture","title":"Module Architecture","text":""},{"location":"api/core/#class-relationship-diagram","title":"Class Relationship Diagram","text":"<pre><code>classDiagram\n    class K8sClient {\n        +kubeconfig_path: str\n        +context: str\n        +timeout: int\n        +test_connection() bool\n        +get_cluster_info() Dict\n        +list_crds() List[Dict]\n        +get_crd(name) Dict\n    }\n\n    class CRDInventory {\n        -client: K8sClient\n        +analyze_crds() Dict\n        +detect_framework(crd) str\n        +count_instances(name) int\n        +categorize_crd(crd) List[str]\n    }\n\n    class OperatorInventory {\n        -client: K8sClient\n        +discover_operators() List[Dict]\n        +classify_operator(deployment) Dict\n        +get_managed_crds(name, ns) List[str]\n        +assess_health(operator) Dict\n    }\n\n    class OutputFormatter {\n        +format_table(data, headers) str\n        +format_json(data, pretty) str\n        +format_yaml(data) str\n        +format_rich(data, title) str\n    }\n\n    class CLICommands {\n        &lt;&lt;interface&gt;&gt;\n        +crd_list()\n        +crd_get()\n        +operators_list()\n        +cluster_export()\n    }\n\n    K8sClient --&gt; CRDInventory : uses\n    K8sClient --&gt; OperatorInventory : uses\n    CRDInventory --&gt; OutputFormatter : formats_with\n    OperatorInventory --&gt; OutputFormatter : formats_with\n    CLICommands --&gt; CRDInventory : calls\n    CLICommands --&gt; OperatorInventory : calls\n\n    note for K8sClient \"Core Kubernetes\\nAPI wrapper\"\n    note for CRDInventory \"CRD analysis\\nand classification\"\n    note for OperatorInventory \"Operator detection\\nand health assessment\"</code></pre>"},{"location":"api/core/#component-flow-diagram","title":"Component Flow Diagram","text":"<pre><code>sequenceDiagram\n    participant User\n    participant CLI\n    participant Client as K8sClient\n    participant CRD as CRDInventory\n    participant OP as OperatorInventory\n    participant Format as OutputFormatter\n    participant K8s as Kubernetes API\n\n    User-&gt;&gt;CLI: Execute command\n    CLI-&gt;&gt;Client: Initialize\n    Client-&gt;&gt;K8s: Authenticate\n    K8s--&gt;&gt;Client: Connection established\n\n    alt CRD Command\n        CLI-&gt;&gt;CRD: Request CRD analysis\n        CRD-&gt;&gt;Client: Get CRDs\n        Client-&gt;&gt;K8s: List CRDs\n        K8s--&gt;&gt;Client: CRD data\n        Client--&gt;&gt;CRD: CRD list\n        CRD-&gt;&gt;CRD: Analyze and classify\n        CRD-&gt;&gt;Format: Format results\n        Format--&gt;&gt;CLI: Formatted output\n    else Operator Command\n        CLI-&gt;&gt;OP: Request operator analysis\n        OP-&gt;&gt;Client: Get workloads\n        Client-&gt;&gt;K8s: List deployments/statefulsets\n        K8s--&gt;&gt;Client: Workload data\n        Client--&gt;&gt;OP: Workload list\n        OP-&gt;&gt;OP: Detect and classify\n        OP-&gt;&gt;Format: Format results\n        Format--&gt;&gt;CLI: Formatted output\n    else Cluster Command\n        CLI-&gt;&gt;CRD: Get CRD analysis\n        CLI-&gt;&gt;OP: Get operator analysis\n        par\n            CRD-&gt;&gt;Client: Get CRDs\n            Client-&gt;&gt;K8s: List CRDs\n        and\n            OP-&gt;&gt;Client: Get workloads\n            Client-&gt;&gt;K8s: List workloads\n        end\n        CLI-&gt;&gt;Format: Merge and format\n        Format--&gt;&gt;CLI: Complete export\n    end\n\n    CLI--&gt;&gt;User: Display results</code></pre> <pre><code>src/k8s_inventory_cli/\n\u251c\u2500\u2500 core/\n\u2502   \u251c\u2500\u2500 k8s_client.py          # Kubernetes API client wrapper\n\u2502   \u251c\u2500\u2500 crd_inventory.py       # CRD discovery and analysis\n\u2502   \u2514\u2500\u2500 operator_inventory.py  # Operator detection and classification\n\u251c\u2500\u2500 utils/\n\u2502   \u2514\u2500\u2500 formatters.py          # Output formatting utilities\n\u2514\u2500\u2500 commands/\n    \u251c\u2500\u2500 crd.py                 # CRD CLI commands\n    \u251c\u2500\u2500 operators.py           # Operator CLI commands\n    \u2514\u2500\u2500 cluster.py             # Cluster CLI commands\n</code></pre>"},{"location":"api/core/#core-modules","title":"Core Modules","text":""},{"location":"api/core/#k8s_clientpy","title":"k8s_client.py","text":"<p>Kubernetes API client wrapper with enhanced functionality.</p>"},{"location":"api/core/#classes","title":"Classes","text":""},{"location":"api/core/#k8sclient","title":"<code>K8sClient</code>","text":"<p>Main client for Kubernetes API operations.</p> <p>```python path=/Users/brun_s/Documents/veille-technologique/Personnel/kubernetes-datamodel/k8s-datamodel/src/k8s_inventory_cli/core/k8s_client.py start=null from k8s_inventory_cli.core.k8s_client import K8sClient</p>"},{"location":"api/core/#initialize-client","title":"Initialize client","text":"<p>client = K8sClient(kubeconfig_path=\"~/.kube/config\", context=\"my-context\")</p>"},{"location":"api/core/#test-connection","title":"Test connection","text":"<p>is_connected = await client.test_connection()</p>"},{"location":"api/core/#get-cluster-information","title":"Get cluster information","text":"<p>cluster_info = await client.get_cluster_info() <pre><code>**Constructor Parameters:**\n- `kubeconfig_path` (str, optional): Path to kubeconfig file\n- `context` (str, optional): Kubernetes context to use\n- `timeout` (int, optional): Request timeout in seconds (default: 30)\n\n**Methods:**\n\n###### `test_connection() -&gt; bool`\n\nTest connectivity to the Kubernetes cluster.\n\n```python path=null start=null\ntry:\n    connected = await client.test_connection()\n    if connected:\n        print(\"Successfully connected to cluster\")\nexcept Exception as e:\n    print(f\"Connection failed: {e}\")\n</code></pre></p> <p>Returns: <code>bool</code> - True if connection successful</p> <p>Raises:  - <code>ConnectionError</code>: Network connectivity issues - <code>AuthenticationError</code>: Authentication failures - <code>PermissionError</code>: Insufficient RBAC permissions</p>"},{"location":"api/core/#get_cluster_info-dict","title":"<code>get_cluster_info() -&gt; Dict</code>","text":"<p>Retrieve comprehensive cluster information.</p> <p>```python path=null start=null cluster_info = await client.get_cluster_info() print(f\"Kubernetes version: {cluster_info['version']}\") print(f\"API server: {cluster_info['server']}\") print(f\"Node count: {cluster_info['node_count']}\") <pre><code>**Returns:** Dictionary containing:\n- `version`: Kubernetes version string\n- `server`: API server endpoint\n- `node_count`: Number of cluster nodes\n- `api_resources`: Available API resources\n\n###### `list_crds(group_filter=None, scope_filter=None) -&gt; List[Dict]`\n\nList Custom Resource Definitions with optional filtering.\n\n```python path=null start=null\n# List all CRDs\nall_crds = await client.list_crds()\n\n# Filter by group\ncert_manager_crds = await client.list_crds(group_filter=\"cert-manager.io\")\n\n# Filter by scope\ncluster_scoped = await client.list_crds(scope_filter=\"Cluster\")\n</code></pre></p> <p>Parameters: - <code>group_filter</code> (str, optional): Filter by API group - <code>scope_filter</code> (str, optional): Filter by scope (\"Namespaced\" or \"Cluster\")</p> <p>Returns: List of CRD dictionaries</p>"},{"location":"api/core/#get_crdname-str-dict","title":"<code>get_crd(name: str) -&gt; Dict</code>","text":"<p>Get detailed information about a specific CRD.</p> <p>```python path=null start=null crd_details = await client.get_crd(\"certificates.cert-manager.io\") print(f\"CRD versions: {crd_details['spec']['versions']}\") <pre><code>**Parameters:**\n- `name` (str): Full CRD name\n\n**Returns:** Complete CRD specification\n\n**Raises:** `ResourceNotFoundError` if CRD doesn't exist\n\n#### Configuration\n\nThe client automatically loads configuration from:\n\n1. Explicit kubeconfig path parameter\n2. `KUBECONFIG` environment variable  \n3. Default location (`~/.kube/config`)\n\n### crd_inventory.py\n\nCRD discovery and analysis functionality.\n\n#### Classes\n\n##### `CRDInventory`\n\nComprehensive CRD analysis and categorization.\n\n```python path=null start=null\nfrom k8s_inventory_cli.core.crd_inventory import CRDInventory\n\n# Initialize inventory\ninventory = CRDInventory(client)\n\n# Get comprehensive CRD analysis\nanalysis = await inventory.analyze_crds()\n</code></pre></p> <p>Constructor Parameters: - <code>client</code> (K8sClient): Kubernetes client instance</p> <p>Methods:</p>"},{"location":"api/core/#analyze_crdsfiltersnone-dict","title":"<code>analyze_crds(filters=None) -&gt; Dict</code>","text":"<p>Perform comprehensive CRD analysis.</p> <p>```python path=null start=null analysis = await inventory.analyze_crds({     \"group\": \"cert-manager.io\",     \"scope\": \"Namespaced\" })</p> <p>print(f\"Found {len(analysis['crds'])} CRDs\") print(f\"Framework distribution: {analysis['frameworks']}\") <pre><code>**Parameters:**\n- `filters` (dict, optional): Filtering criteria\n\n**Returns:** Dictionary containing:\n- `crds`: List of analyzed CRDs\n- `summary`: Statistical summary\n- `frameworks`: Framework distribution\n- `categories`: Category breakdown\n\n###### `detect_framework(crd: Dict) -&gt; str`\n\nDetect deployment framework for a CRD.\n\n```python path=null start=null\nframework = inventory.detect_framework(crd_definition)\n# Returns: \"Helm\", \"OLM\", or \"Manual\"\n</code></pre></p> <p>Parameters: - <code>crd</code> (dict): CRD definition</p> <p>Returns: Framework name string</p>"},{"location":"api/core/#count_instancescrd_name-str-namespacenone-int","title":"<code>count_instances(crd_name: str, namespace=None) -&gt; int</code>","text":"<p>Count instances of a custom resource.</p> <p>```python path=null start=null</p>"},{"location":"api/core/#count-all-instances","title":"Count all instances","text":"<p>total_count = await inventory.count_instances(\"certificates.cert-manager.io\")</p>"},{"location":"api/core/#count-in-specific-namespace","title":"Count in specific namespace","text":"<p>ns_count = await inventory.count_instances(     \"certificates.cert-manager.io\",      namespace=\"default\" ) <pre><code>**Parameters:**\n- `crd_name` (str): CRD name\n- `namespace` (str, optional): Specific namespace\n\n**Returns:** Instance count\n\n###### `categorize_crd(crd: Dict) -&gt; List[str]`\n\nCategorize CRD by functionality.\n\n```python path=null start=null\ncategories = inventory.categorize_crd(crd_definition)\n# Example: [\"networking\", \"security\", \"ingress\"]\n</code></pre></p> <p>Parameters: - <code>crd</code> (dict): CRD definition</p> <p>Returns: List of category strings</p>"},{"location":"api/core/#data-structures","title":"Data Structures","text":""},{"location":"api/core/#crd-analysis-result","title":"CRD Analysis Result","text":"<p>```python path=null start=null {     \"name\": \"certificates.cert-manager.io\",     \"group\": \"cert-manager.io\",      \"kind\": \"Certificate\",     \"scope\": \"Namespaced\",     \"versions\": [\"v1\", \"v1beta1\"],     \"categories\": [\"cert-manager\"],     \"short_names\": [\"cert\", \"certs\"],     \"age_days\": 30,     \"instance_count\": 5,     \"framework\": \"Helm\",     \"creation_timestamp\": \"2024-01-15T10:30:00Z\",     \"status\": {         \"conditions\": [...],         \"accepted_names\": {...}     } } <pre><code>### operator_inventory.py\n\nOperator detection and classification.\n\n#### Classes\n\n##### `OperatorInventory`\n\nKubernetes operator discovery and analysis.\n\n```python path=null start=null\nfrom k8s_inventory_cli.core.operator_inventory import OperatorInventory\n\n# Initialize operator inventory\nop_inventory = OperatorInventory(client)\n\n# Discover operators\noperators = await op_inventory.discover_operators()\n</code></pre></p> <p>Constructor Parameters: - <code>client</code> (K8sClient): Kubernetes client instance</p> <p>Methods:</p>"},{"location":"api/core/#discover_operatorsnamespacenone-framework_filternone-listdict","title":"<code>discover_operators(namespace=None, framework_filter=None) -&gt; List[Dict]</code>","text":"<p>Discover and classify operators in the cluster.</p> <p>```python path=null start=null</p>"},{"location":"api/core/#discover-all-operators","title":"Discover all operators","text":"<p>all_operators = await op_inventory.discover_operators()</p>"},{"location":"api/core/#filter-by-namespace","title":"Filter by namespace","text":"<p>kube_system_ops = await op_inventory.discover_operators(namespace=\"kube-system\")</p>"},{"location":"api/core/#filter-by-framework","title":"Filter by framework","text":"<p>olm_operators = await op_inventory.discover_operators(framework_filter=\"OLM\") <pre><code>**Parameters:**\n- `namespace` (str, optional): Target namespace\n- `framework_filter` (str, optional): Framework filter\n\n**Returns:** List of operator dictionaries\n\n###### `classify_operator(deployment: Dict) -&gt; Dict`\n\nClassify a deployment as an operator.\n\n```python path=null start=null\noperator_info = op_inventory.classify_operator(deployment_spec)\n</code></pre></p> <p>Parameters: - <code>deployment</code> (dict): Deployment specification</p> <p>Returns: Operator classification data</p>"},{"location":"api/core/#get_managed_crdsoperator_name-str-namespace-str-liststr","title":"<code>get_managed_crds(operator_name: str, namespace: str) -&gt; List[str]</code>","text":"<p>Get CRDs managed by a specific operator.</p> <p>```python path=null start=null managed_crds = await op_inventory.get_managed_crds(\"cert-manager\", \"cert-manager\") print(f\"Managed CRDs: {managed_crds}\") <pre><code>**Parameters:**\n- `operator_name` (str): Operator name\n- `namespace` (str): Operator namespace\n\n**Returns:** List of managed CRD names\n\n###### `assess_health(operator: Dict) -&gt; Dict`\n\nAssess operator health status.\n\n```python path=null start=null\nhealth_status = await op_inventory.assess_health(operator_data)\nprint(f\"Health: {health_status['status']}\")  # \"Healthy\", \"Degraded\", \"Failed\"\n</code></pre></p> <p>Parameters: - <code>operator</code> (dict): Operator data</p> <p>Returns: Health assessment dictionary</p>"},{"location":"api/core/#operator-detection-logic","title":"Operator Detection Logic","text":"<p>The operator detection uses multiple criteria:</p> <ol> <li>Image Analysis: Container images containing \"operator\", \"controller\"</li> <li>Label Analysis: Standard operator labels and annotations</li> <li>CRD Ownership: Controllers managing CRDs</li> <li>RBAC Patterns: ServiceAccounts with elevated permissions</li> <li>Port Analysis: Common operator ports (8080, 9443, etc.)</li> </ol>"},{"location":"api/core/#data-structures_1","title":"Data Structures","text":""},{"location":"api/core/#operator-result","title":"Operator Result","text":"<p>```python path=null start=null {     \"name\": \"cert-manager\",     \"namespace\": \"cert-manager\",     \"framework\": \"Helm\",     \"image\": \"quay.io/jetstack/cert-manager-controller:v1.11.0\",     \"image_version\": \"v1.11.0\",     \"replicas\": {         \"desired\": 1,         \"ready\": 1,         \"available\": 1     },     \"health_status\": \"Healthy\",     \"managed_crds\": [         \"certificates.cert-manager.io\",         \"issuers.cert-manager.io\"     ],     \"resources\": {         \"requests\": {\"cpu\": \"10m\", \"memory\": \"32Mi\"},         \"limits\": {\"cpu\": \"100m\", \"memory\": \"128Mi\"}     },     \"security_context\": {         \"privileged\": false,         \"run_as_non_root\": true     } } <pre><code>## Utility Modules\n\n### formatters.py\n\nOutput formatting utilities for different formats.\n\n#### Classes\n\n##### `OutputFormatter`\n\nMulti-format output formatting.\n\n```python path=null start=null\nfrom k8s_inventory_cli.utils.formatters import OutputFormatter\n\nformatter = OutputFormatter()\n\n# Format as table\ntable_output = formatter.format_table(data, headers=[\"Name\", \"Group\", \"Age\"])\n\n# Format as JSON\njson_output = formatter.format_json(data, pretty=True)\n\n# Format as YAML\nyaml_output = formatter.format_yaml(data)\n</code></pre></p> <p>Methods:</p>"},{"location":"api/core/#format_tabledata-listdict-headers-liststr-kwargs-str","title":"<code>format_table(data: List[Dict], headers: List[str], **kwargs) -&gt; str</code>","text":"<p>Format data as ASCII table.</p> <p>Parameters: - <code>data</code>: List of data dictionaries - <code>headers</code>: Column headers - <code>max_width</code>: Maximum column width - <code>sort_by</code>: Sort column</p>"},{"location":"api/core/#format_jsondata-any-pretty-bool-false-str","title":"<code>format_json(data: Any, pretty: bool = False) -&gt; str</code>","text":"<p>Format data as JSON.</p>"},{"location":"api/core/#format_yamldata-any-str","title":"<code>format_yaml(data: Any) -&gt; str</code>","text":"<p>Format data as YAML.</p>"},{"location":"api/core/#format_richdata-listdict-title-str-none-str","title":"<code>format_rich(data: List[Dict], title: str = None) -&gt; str</code>","text":"<p>Format data with rich styling and colors.</p>"},{"location":"api/core/#error-classes","title":"Error Classes","text":""},{"location":"api/core/#custom-exceptions","title":"Custom Exceptions","text":"<p>```python path=null start=null from k8s_inventory_cli.core.exceptions import (     K8sInventoryError,     ConnectionError,      AuthenticationError,     PermissionError,     ResourceNotFoundError ) <pre><code>#### Exception Hierarchy\n\n```python path=null start=null\nK8sInventoryError\n\u251c\u2500\u2500 ConnectionError\n\u251c\u2500\u2500 AuthenticationError  \n\u251c\u2500\u2500 PermissionError\n\u251c\u2500\u2500 ResourceNotFoundError\n\u2514\u2500\u2500 ConfigurationError\n</code></pre></p>"},{"location":"api/core/#usage-examples","title":"Usage Examples","text":""},{"location":"api/core/#basic-inventory-script","title":"Basic Inventory Script","text":"<p>```python path=null start=null</p>"},{"location":"api/core/#usrbinenv-python3","title":"!/usr/bin/env python3","text":"<p>\"\"\" Basic cluster inventory script using core modules. \"\"\" import asyncio from k8s_inventory_cli.core import K8sClient, CRDInventory, OperatorInventory</p> <p>async def main():     # Initialize client     client = K8sClient()</p> <pre><code># Test connection\nif not await client.test_connection():\n    print(\"Failed to connect to cluster\")\n    return\n\n# Initialize inventories\ncrd_inventory = CRDInventory(client)\nop_inventory = OperatorInventory(client)\n\n# Get CRD analysis\ncrd_analysis = await crd_inventory.analyze_crds()\nprint(f\"Found {len(crd_analysis['crds'])} CRDs\")\n\n# Discover operators\noperators = await op_inventory.discover_operators()\nprint(f\"Found {len(operators)} operators\")\n\n# Framework breakdown\nframeworks = {}\nfor op in operators:\n    framework = op['framework']\n    frameworks[framework] = frameworks.get(framework, 0) + 1\n\nprint(f\"Framework distribution: {frameworks}\")\n</code></pre> <p>if name == \"main\":     asyncio.run(main()) <pre><code>### Custom Analysis Script\n\n```python path=null start=null\n#!/usr/bin/env python3\n\"\"\"\nCustom analysis focusing on security implications.\n\"\"\"\nimport asyncio\nfrom k8s_inventory_cli.core import K8sClient, OperatorInventory\n\nasync def security_analysis():\n    client = K8sClient()\n    op_inventory = OperatorInventory(client)\n\n    operators = await op_inventory.discover_operators()\n\n    # Find privileged operators\n    privileged_ops = [\n        op for op in operators \n        if op.get('security_context', {}).get('privileged', False)\n    ]\n\n    # Find cluster-scoped operators\n    cluster_ops = [\n        op for op in operators\n        if any('cluster' in crd.lower() for crd in op.get('managed_crds', []))\n    ]\n\n    print(f\"Privileged operators: {len(privileged_ops)}\")\n    print(f\"Cluster-scoped operators: {len(cluster_ops)}\")\n\n    return {\n        'privileged_operators': privileged_ops,\n        'cluster_operators': cluster_ops\n    }\n\nif __name__ == \"__main__\":\n    results = asyncio.run(security_analysis())\n</code></pre></p>"},{"location":"api/core/#integration-with-monitoring","title":"Integration with Monitoring","text":"<p>```python path=null start=null</p>"},{"location":"api/core/#usrbinenv-python3_1","title":"!/usr/bin/env python3","text":"<p>\"\"\" Generate metrics for monitoring systems. \"\"\" import asyncio import json from k8s_inventory_cli.core import K8sClient, CRDInventory, OperatorInventory</p> <p>async def generate_metrics():     client = K8sClient()     crd_inventory = CRDInventory(client)     op_inventory = OperatorInventory(client)</p> <pre><code># Get data\ncrd_analysis = await crd_inventory.analyze_crds()\noperators = await op_inventory.discover_operators()\n\n# Calculate metrics\nmetrics = {\n    'k8s_inventory_crds_total': len(crd_analysis['crds']),\n    'k8s_inventory_operators_total': len(operators),\n    'k8s_inventory_operators_healthy': len([\n        op for op in operators \n        if op['health_status'] == 'Healthy'\n    ]),\n    'k8s_inventory_frameworks': {\n        framework: len([op for op in operators if op['framework'] == framework])\n        for framework in set(op['framework'] for op in operators)\n    }\n}\n\nreturn metrics\n</code></pre> <p>async def export_prometheus_metrics():     metrics = await generate_metrics()</p> <pre><code># Export in Prometheus format\nfor metric, value in metrics.items():\n    if isinstance(value, dict):\n        for label, count in value.items():\n            print(f'{metric}{{framework=\"{label}\"}} {count}')\n    else:\n        print(f'{metric} {value}')\n</code></pre> <p>if name == \"main\":     asyncio.run(export_prometheus_metrics()) <pre><code>## Configuration\n\n### Environment Variables\n\nThe core modules respect these environment variables:\n\n- `KUBECONFIG`: Path to kubeconfig file\n- `K8S_INVENTORY_TIMEOUT`: Default request timeout\n- `K8S_INVENTORY_CACHE_TTL`: Cache time-to-live in seconds\n\n### Configuration File\n\nCore modules can use configuration files:\n\n```yaml path=null start=null\n# ~/.k8s-inventory/config.yaml\nclient:\n  timeout: 30\n  retries: 3\n\ninventory:\n  cache_ttl: 300\n  parallel_workers: 10\n\ndetection:\n  operator_patterns:\n    - \"*operator*\"\n    - \"*controller*\" \n    - \"*manager*\"\n</code></pre></p>"},{"location":"api/core/#performance-considerations","title":"Performance Considerations","text":""},{"location":"api/core/#async-operations","title":"Async Operations","text":"<p>All I/O operations are async for better performance:</p> <p>```python path=null start=null</p>"},{"location":"api/core/#concurrent-operations","title":"Concurrent operations","text":"<p>import asyncio</p> <p>async def parallel_analysis():     client = K8sClient()     crd_inventory = CRDInventory(client)     op_inventory = OperatorInventory(client)</p> <pre><code># Run in parallel\ncrd_task = asyncio.create_task(crd_inventory.analyze_crds())\nop_task = asyncio.create_task(op_inventory.discover_operators())\n\ncrds, operators = await asyncio.gather(crd_task, op_task)\n\nreturn crds, operators\n</code></pre> <p>``` </p>"},{"location":"api/core/#caching","title":"Caching","text":"<p>Results are cached to improve performance:  ```python path=null start=null</p>"},{"location":"api/core/#cache-is-automatically-managed-but-can-be-controlled","title":"Cache is automatically managed, but can be controlled","text":"<p>client = K8sClient(cache_ttl=600)  # 10-minute cache ```</p>"},{"location":"api/core/#testing","title":"Testing","text":""},{"location":"api/core/#unit-tests","title":"Unit Tests","text":"<p>```python path=null start=null import pytest from unittest.mock import AsyncMock from k8s_inventory_cli.core import K8sClient</p> <p>@pytest.mark.asyncio async def test_client_connection():     client = K8sClient()     client._api_client = AsyncMock()</p> <pre><code>result = await client.test_connection()\nassert result is True\n</code></pre> <p>``` </p>"},{"location":"api/core/#integration-tests","title":"Integration Tests","text":"<p><code>python path=null start=null @pytest.mark.integration async def test_live_cluster():     client = K8sClient()      # Skip if no cluster available     if not await client.test_connection():         pytest.skip(\"No cluster available\")      crds = await client.list_crds()     assert isinstance(crds, list)</code></p>"},{"location":"api/core/#related-documentation","title":"Related Documentation","text":"<ul> <li>CLI Commands: CLI interface to these modules</li> <li>Usage Examples: Practical usage scenarios</li> <li>Contributing: Development guidelines</li> </ul>"},{"location":"examples/database-workflows/","title":"Database Workflow Examples","text":"<p>This document provides comprehensive examples of using k8s-datamodel's database functionality for real-world scenarios.</p>"},{"location":"examples/database-workflows/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Basic Database Operations</li> <li>Multi-Cluster Management</li> <li>Compliance and Auditing</li> <li>Migration Planning</li> <li>Configuration Drift Detection</li> <li>Security Analysis</li> <li>Automated Monitoring</li> <li>CI/CD Integration</li> </ol>"},{"location":"examples/database-workflows/#basic-database-operations","title":"Basic Database Operations","text":""},{"location":"examples/database-workflows/#initial-setup-and-first-snapshot","title":"Initial Setup and First Snapshot","text":"<pre><code># Test cluster connectivity\nk8s-datamodel cluster test-connection\n\n# Create your first snapshot\nk8s-datamodel database store --notes \"Initial cluster baseline - $(date)\"\n\n# Verify the snapshot was created\nk8s-datamodel database list\n</code></pre> <p>Expected Output: <pre><code>+------+------------------+-----------+--------+-------------+--------+-------------+-------------------------------+\n|   ID | Timestamp        | Context   |   CRDs |   Operators |   CSVs | Namespace   | Notes                         |\n+======+==================+===========+========+=============+========+=============+===============================+\n|    1 | 2025-09-07 19:30 | default   |    143 |           9 |     33 | all         | Initial cluster baseline -... |\n+------+------------------+-----------+--------+-------------+--------+-------------+-------------------------------+\n</code></pre></p>"},{"location":"examples/database-workflows/#viewing-database-statistics","title":"Viewing Database Statistics","text":"<pre><code># Get comprehensive database statistics\nk8s-datamodel database stats --output rich\n</code></pre> <p>Expected Output: <pre><code>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Database Info \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Database Path: /Users/user/.k8s-inventory/inventory.db                                                                     \u2502\n\u2502 File Size: 13.3MB                                                                                                          \u2502\n\u2502 Total Snapshots: 1                                                                                                         \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Data Counts \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Total CRDs: 143                                                                                                             \u2502\n\u2502 Total Operators: 9                                                                                                         \u2502\n\u2502 Total CSVs: 33                                                                                                             \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre></p>"},{"location":"examples/database-workflows/#exporting-snapshots-for-analysis","title":"Exporting Snapshots for Analysis","text":"<pre><code># Export snapshot with complete specifications\nk8s-datamodel database export 1 --file cluster-snapshot.json\n\n# Export only CRDs for focused analysis  \nk8s-datamodel database export 1 --crds-only --file crds-analysis.json\n\n# Export in YAML format for human readability\nk8s-datamodel database export 1 --output yaml --file cluster-snapshot.yaml\n</code></pre>"},{"location":"examples/database-workflows/#multi-cluster-management","title":"Multi-Cluster Management","text":""},{"location":"examples/database-workflows/#managing-multiple-environments","title":"Managing Multiple Environments","text":"<pre><code># Store snapshots from different environments\nk8s-datamodel --context prod-cluster database store \\\n    --notes \"Production cluster - $(date +%Y-%m-%d)\"\n\nk8s-datamodel --context staging-cluster database store \\\n    --notes \"Staging cluster - $(date +%Y-%m-%d)\"\n\nk8s-datamodel --context dev-cluster database store \\\n    --notes \"Development cluster - $(date +%Y-%m-%d)\"\n\n# List snapshots filtered by cluster context\nk8s-datamodel database list --cluster-context prod-cluster\n</code></pre> <p>Expected Output: <pre><code>+------+------------------+---------------+--------+-------------+--------+-------------+---------------------------+\n|   ID | Timestamp        | Context       |   CRDs |   Operators |   CSVs | Namespace   | Notes                     |\n+======+==================+===============+========+=============+========+=============+===========================+\n|    1 | 2025-09-07 19:30 | prod-cluster  |    143 |           9 |     33 | all         | Production cluster - ...  |\n|    2 | 2025-09-07 19:35 | staging-clus  |    128 |           8 |     28 | all         | Staging cluster - ...     |\n|    3 | 2025-09-07 19:40 | dev-cluster   |     95 |           5 |     15 | all         | Development cluster - ... |\n+------+------------------+---------------+--------+-------------+--------+-------------+---------------------------+\n</code></pre></p>"},{"location":"examples/database-workflows/#cross-environment-comparison","title":"Cross-Environment Comparison","text":"<pre><code># Export snapshots for comparison\nk8s-datamodel database export 1 --file prod-inventory.json\nk8s-datamodel database export 2 --file staging-inventory.json\nk8s-datamodel database export 3 --file dev-inventory.json\n\n# Compare CRD counts between environments\necho \"=== CRD Comparison ===\"\necho \"Production: $(jq '.crds | length' prod-inventory.json) CRDs\"\necho \"Staging:    $(jq '.crds | length' staging-inventory.json) CRDs\"\necho \"Development: $(jq '.crds | length' dev-inventory.json) CRDs\"\n\n# Find CRDs present in prod but not in staging\ncomm -23 &lt;(jq -r '.crds[].name' prod-inventory.json | sort) \\\n         &lt;(jq -r '.crds[].name' staging-inventory.json | sort) &gt; prod-only-crds.txt\n</code></pre>"},{"location":"examples/database-workflows/#compliance-and-auditing","title":"Compliance and Auditing","text":""},{"location":"examples/database-workflows/#pre-audit-baseline","title":"Pre-Audit Baseline","text":"<pre><code># Create comprehensive audit baseline\nk8s-datamodel database store \\\n    --notes \"SOC2 Audit Baseline - $(date +%Y-%m-%d) - Pre-audit snapshot\"\n\n# Generate audit-specific exports\nk8s-datamodel database export 1 --file audit-baseline.json\n\n# Extract security-relevant information\necho \"=== Security Analysis for Audit ===\"\n\n# Find operators with privileged security contexts\njq -r '.operators[] | select(.spec.spec.template.spec.containers[0].securityContext.privileged == true) | \n       \"PRIVILEGED: \\(.name) in namespace \\(.namespace)\"' audit-baseline.json\n\n# Find operators without resource limits\njq -r '.operators[] | select(.spec.spec.template.spec.containers[0].resources.limits == null) | \n       \"NO LIMITS: \\(.name) in namespace \\(.namespace)\"' audit-baseline.json\n\n# Extract RBAC permissions from CSVs\njq -r '.csvs[] | \n       \"CSV: \\(.name) - Permissions: \\(.spec.spec.install.spec.permissions | length) - ClusterPermissions: \\(.spec.spec.install.spec.clusterPermissions | length)\"' audit-baseline.json\n</code></pre>"},{"location":"examples/database-workflows/#post-audit-comparison","title":"Post-Audit Comparison","text":"<pre><code># Store post-remediation snapshot\nk8s-datamodel database store \\\n    --notes \"SOC2 Audit - Post-remediation snapshot - $(date +%Y-%m-%d)\"\n\n# Compare audit snapshots\nk8s-datamodel database export 1 --file pre-audit.json\nk8s-datamodel database export 2 --file post-audit.json\n\n# Check for security improvements\necho \"=== Security Improvements ===\"\necho \"Pre-audit privileged operators:\"\njq -r '.operators[] | select(.spec.spec.template.spec.containers[0].securityContext.privileged == true) | .name' pre-audit.json | wc -l\n\necho \"Post-audit privileged operators:\"\njq -r '.operators[] | select(.spec.spec.template.spec.containers[0].securityContext.privileged == true) | .name' post-audit.json | wc -l\n</code></pre>"},{"location":"examples/database-workflows/#migration-planning","title":"Migration Planning","text":""},{"location":"examples/database-workflows/#pre-migration-documentation","title":"Pre-Migration Documentation","text":"<pre><code># Document source cluster state\nk8s-datamodel --context source-cluster database store \\\n    --notes \"Migration Source - EKS v1.28 - $(date +%Y-%m-%d)\"\n\n# Export comprehensive migration documentation\nk8s-datamodel database export 1 --file migration-source-inventory.json\n\n# Generate migration planning report\necho \"=== Migration Planning Report ===\" &gt; migration-plan.md\necho \"Generated: $(date)\" &gt;&gt; migration-plan.md\necho \"\" &gt;&gt; migration-plan.md\n\necho \"## Source Cluster Overview\" &gt;&gt; migration-plan.md\necho \"- CRDs: $(jq '.crds | length' migration-source-inventory.json)\" &gt;&gt; migration-plan.md\necho \"- Operators: $(jq '.operators | length' migration-source-inventory.json)\" &gt;&gt; migration-plan.md\necho \"- OLM CSVs: $(jq '.csvs | length' migration-source-inventory.json)\" &gt;&gt; migration-plan.md\necho \"\" &gt;&gt; migration-plan.md\n\necho \"## Critical CRDs to Migrate\" &gt;&gt; migration-plan.md\njq -r '.crds[] | select(.instance_count &gt; 0) | \"- \\(.name) (\\(.kind)) - \\(.instance_count) instances\"' \\\n   migration-source-inventory.json &gt;&gt; migration-plan.md\necho \"\" &gt;&gt; migration-plan.md\n\necho \"## Operators to Reinstall\" &gt;&gt; migration-plan.md\njq -r '.operators[] | \"- \\(.name) (\\(.operator_type)) - \\(.namespace) - \\(.operator_framework // \"Manual\")\"' \\\n   migration-source-inventory.json &gt;&gt; migration-plan.md\n</code></pre>"},{"location":"examples/database-workflows/#post-migration-verification","title":"Post-Migration Verification","text":"<pre><code># Document target cluster state\nk8s-datamodel --context target-cluster database store \\\n    --notes \"Migration Target - GKE v1.29 - Post-migration - $(date +%Y-%m-%d)\"\n\n# Export target cluster inventory\nk8s-datamodel database export 2 --file migration-target-inventory.json\n\n# Verify migration completeness\necho \"=== Migration Verification ===\" &gt; migration-verification.md\necho \"Generated: $(date)\" &gt;&gt; migration-verification.md\necho \"\" &gt;&gt; migration-verification.md\n\n# Compare CRD counts\nSOURCE_CRDS=$(jq '.crds | length' migration-source-inventory.json)\nTARGET_CRDS=$(jq '.crds | length' migration-target-inventory.json)\necho \"## CRD Migration Status\" &gt;&gt; migration-verification.md\necho \"- Source: $SOURCE_CRDS CRDs\" &gt;&gt; migration-verification.md  \necho \"- Target: $TARGET_CRDS CRDs\" &gt;&gt; migration-verification.md\necho \"- Status: $( [ $SOURCE_CRDS -eq $TARGET_CRDS ] &amp;&amp; echo \"\u2705 COMPLETE\" || echo \"\u26a0\ufe0f  INCOMPLETE\" )\" &gt;&gt; migration-verification.md\necho \"\" &gt;&gt; migration-verification.md\n\n# Find missing CRDs\necho \"## Missing CRDs\" &gt;&gt; migration-verification.md\ncomm -23 &lt;(jq -r '.crds[].name' migration-source-inventory.json | sort) \\\n         &lt;(jq -r '.crds[].name' migration-target-inventory.json | sort) | \\\nwhile read crd; do echo \"- \u274c $crd\"; done &gt;&gt; migration-verification.md\n</code></pre>"},{"location":"examples/database-workflows/#configuration-drift-detection","title":"Configuration Drift Detection","text":""},{"location":"examples/database-workflows/#establishing-configuration-baseline","title":"Establishing Configuration Baseline","text":"<pre><code># Create golden configuration baseline\nk8s-datamodel database store \\\n    --notes \"Golden Configuration Baseline - Approved by Platform Team - $(date +%Y-%m-%d)\"\n\n# Store the baseline ID for future comparisons\necho \"1\" &gt; .baseline-snapshot-id\n</code></pre>"},{"location":"examples/database-workflows/#weekly-drift-detection","title":"Weekly Drift Detection","text":"<pre><code># Weekly drift detection script\n#!/bin/bash\nBASELINE_ID=$(cat .baseline-snapshot-id)\nCURRENT_DATE=$(date +%Y-%m-%d)\n\n# Store current state\nk8s-datamodel database store --notes \"Weekly drift check - $CURRENT_DATE\"\nCURRENT_ID=$(k8s-datamodel database list --limit 1 --output json | jq -r '.[0].id')\n\n# Export both snapshots\nk8s-datamodel database export $BASELINE_ID --file baseline.json\nk8s-datamodel database export $CURRENT_ID --file current.json\n\n# Generate drift report\necho \"=== Configuration Drift Report - $CURRENT_DATE ===\" &gt; drift-report.md\necho \"\" &gt;&gt; drift-report.md\n\n# Compare CRD counts\nBASELINE_CRD_COUNT=$(jq '.crds | length' baseline.json)\nCURRENT_CRD_COUNT=$(jq '.crds | length' current.json)\n\necho \"## CRD Changes\" &gt;&gt; drift-report.md\necho \"- Baseline: $BASELINE_CRD_COUNT CRDs\" &gt;&gt; drift-report.md\necho \"- Current: $CURRENT_CRD_COUNT CRDs\" &gt;&gt; drift-report.md\necho \"- Change: $(($CURRENT_CRD_COUNT - $BASELINE_CRD_COUNT))\" &gt;&gt; drift-report.md\necho \"\" &gt;&gt; drift-report.md\n\n# Find new CRDs\necho \"### New CRDs Added\" &gt;&gt; drift-report.md\ncomm -13 &lt;(jq -r '.crds[].name' baseline.json | sort) \\\n         &lt;(jq -r '.crds[].name' current.json | sort) | \\\nwhile read crd; do echo \"- \u2705 $crd\"; done &gt;&gt; drift-report.md\n\n# Find removed CRDs  \necho \"\" &gt;&gt; drift-report.md\necho \"### CRDs Removed\" &gt;&gt; drift-report.md\ncomm -23 &lt;(jq -r '.crds[].name' baseline.json | sort) \\\n         &lt;(jq -r '.crds[].name' current.json | sort) | \\\nwhile read crd; do echo \"- \u274c $crd\"; done &gt;&gt; drift-report.md\n\n# Compare operator configurations\necho \"\" &gt;&gt; drift-report.md\necho \"## Operator Configuration Changes\" &gt;&gt; drift-report.md\n\n# Check for operator image changes\njq -r '.operators[] | \"\\(.name)|\\(.image)\"' baseline.json | sort &gt; baseline-images.txt\njq -r '.operators[] | \"\\(.name)|\\(.image)\"' current.json | sort &gt; current-images.txt\n\necho \"### Image Changes\" &gt;&gt; drift-report.md\ndiff baseline-images.txt current-images.txt | grep '^&gt;' | sed 's/^&gt; /- /' &gt;&gt; drift-report.md\n</code></pre>"},{"location":"examples/database-workflows/#security-analysis","title":"Security Analysis","text":""},{"location":"examples/database-workflows/#security-audit-workflow","title":"Security Audit Workflow","text":"<pre><code># Store current state for security analysis\nk8s-datamodel database store \\\n    --notes \"Security Audit - $(date +%Y-%m-%d) - Comprehensive security review\"\n\n# Export for detailed security analysis\nk8s-datamodel database export 1 --file security-audit.json\n\n# Generate security report\necho \"=== Security Audit Report - $(date +%Y-%m-%d) ===\" &gt; security-report.md\necho \"\" &gt;&gt; security-report.md\n\necho \"## Privileged Containers Analysis\" &gt;&gt; security-report.md\necho \"### Operators with Privileged Containers\" &gt;&gt; security-report.md\njq -r '.operators[] | select(.spec.spec.template.spec.containers[0].securityContext.privileged == true) | \n       \"- **\\(.name)** (namespace: \\(.namespace))\"' security-audit.json &gt;&gt; security-report.md\necho \"\" &gt;&gt; security-report.md\n\necho \"### Operators with Host Network Access\" &gt;&gt; security-report.md\njq -r '.operators[] | select(.spec.spec.template.spec.hostNetwork == true) | \n       \"- **\\(.name)** (namespace: \\(.namespace))\"' security-audit.json &gt;&gt; security-report.md\necho \"\" &gt;&gt; security-report.md\n\necho \"### Operators without Resource Limits\" &gt;&gt; security-report.md\njq -r '.operators[] | select(.spec.spec.template.spec.containers[0].resources.limits == null) | \n       \"- **\\(.name)** (namespace: \\(.namespace)) - No resource limits set\"' security-audit.json &gt;&gt; security-report.md\necho \"\" &gt;&gt; security-report.md\n\necho \"## RBAC Analysis from OLM CSVs\" &gt;&gt; security-report.md\necho \"### ClusterPermissions Summary\" &gt;&gt; security-report.md\njq -r '.csvs[] | \n       \"- **\\(.name)**: \\(.spec.spec.install.spec.clusterPermissions | length) cluster-level permissions\"' \\\n   security-audit.json &gt;&gt; security-report.md\necho \"\" &gt;&gt; security-report.md\n\necho \"### High-Risk Permissions\" &gt;&gt; security-report.md\n# Find CSVs with cluster-admin or dangerous permissions\njq -r '.csvs[] | select(.spec.spec.install.spec.clusterPermissions[]?.rules[]?.resources[]? == \"*\") | \n       \"- **\\(.name)**: Has wildcard resource permissions\"' security-audit.json &gt;&gt; security-report.md\n\necho \"## Recommendations\" &gt;&gt; security-report.md\necho \"1. Review all privileged containers and implement least-privilege principle\" &gt;&gt; security-report.md\necho \"2. Add resource limits to all operators without limits\" &gt;&gt; security-report.md  \necho \"3. Audit RBAC permissions and implement role-based access control\" &gt;&gt; security-report.md\necho \"4. Consider using Pod Security Standards for additional security\" &gt;&gt; security-report.md\n</code></pre>"},{"location":"examples/database-workflows/#security-monitoring-setup","title":"Security Monitoring Setup","text":"<pre><code># Create security monitoring script\ncat &gt; security-monitor.sh &lt;&lt; 'EOF'\n#!/bin/bash\n# Daily security monitoring\n\nDATE=$(date +%Y-%m-%d)\nk8s-datamodel database store --notes \"Security monitoring - $DATE\"\n\n# Get latest snapshot\nLATEST_ID=$(k8s-datamodel database list --limit 1 --output json | jq -r '.[0].id')\nk8s-datamodel database export $LATEST_ID --file daily-security.json\n\n# Check for security violations\nPRIVILEGED_COUNT=$(jq '[.operators[] | select(.spec.spec.template.spec.containers[0].securityContext.privileged == true)] | length' daily-security.json)\nNO_LIMITS_COUNT=$(jq '[.operators[] | select(.spec.spec.template.spec.containers[0].resources.limits == null)] | length' daily-security.json)\n\nif [ $PRIVILEGED_COUNT -gt 0 ] || [ $NO_LIMITS_COUNT -gt 0 ]; then\n    echo \"SECURITY ALERT - $DATE\" | mail -s \"K8s Security Issues Detected\" security-team@company.com\n    echo \"Privileged containers: $PRIVILEGED_COUNT\" \n    echo \"Containers without limits: $NO_LIMITS_COUNT\"\nfi\nEOF\n\nchmod +x security-monitor.sh\n</code></pre>"},{"location":"examples/database-workflows/#automated-monitoring","title":"Automated Monitoring","text":""},{"location":"examples/database-workflows/#daily-inventory-collection","title":"Daily Inventory Collection","text":"<pre><code># Create automated daily inventory script\ncat &gt; daily-inventory.sh &lt;&lt; 'EOF'\n#!/bin/bash\n# Daily automated inventory collection\n\nDATE=$(date +%Y-%m-%d)\nCONTEXTS=(\"prod-cluster\" \"staging-cluster\" \"dev-cluster\")\n\nfor CONTEXT in \"${CONTEXTS[@]}\"; do\n    echo \"Collecting inventory for $CONTEXT...\"\n    k8s-datamodel --context $CONTEXT database store \\\n        --notes \"Automated daily snapshot - $CONTEXT - $DATE\"\ndone\n\n# Cleanup old snapshots (keep 30 days)\nk8s-datamodel database cleanup --keep 30\n\n# Generate daily summary\necho \"=== Daily Inventory Summary - $DATE ===\" &gt; daily-summary.txt\nk8s-datamodel database stats &gt;&gt; daily-summary.txt\necho \"\" &gt;&gt; daily-summary.txt\necho \"Recent snapshots:\" &gt;&gt; daily-summary.txt\nk8s-datamodel database list --limit 10 &gt;&gt; daily-summary.txt\nEOF\n\nchmod +x daily-inventory.sh\n\n# Add to crontab for daily execution at 2 AM\necho \"0 2 * * * /path/to/daily-inventory.sh\" | crontab -\n</code></pre>"},{"location":"examples/database-workflows/#trend-analysis","title":"Trend Analysis","text":"<pre><code># Weekly trend analysis script\ncat &gt; weekly-trends.sh &lt;&lt; 'EOF'\n#!/bin/bash\n# Weekly trend analysis\n\nWEEK_AGO=$(date -d '7 days ago' +%Y-%m-%d)\nTODAY=$(date +%Y-%m-%d)\n\necho \"=== Weekly Trends Report - $TODAY ===\" &gt; weekly-trends.md\necho \"\" &gt;&gt; weekly-trends.md\n\n# Get snapshots from the last week for each cluster\nfor CONTEXT in prod-cluster staging-cluster dev-cluster; do\n    echo \"## $CONTEXT Trends\" &gt;&gt; weekly-trends.md\n\n    # Get snapshot IDs from the last week\n    SNAPSHOTS=$(k8s-datamodel database list --cluster-context $CONTEXT --output json | \\\n                jq -r '.[] | select(.timestamp &gt;= \"'$WEEK_AGO'\") | .id')\n\n    if [ -n \"$SNAPSHOTS\" ]; then\n        FIRST_ID=$(echo \"$SNAPSHOTS\" | tail -1)\n        LATEST_ID=$(echo \"$SNAPSHOTS\" | head -1)\n\n        # Export snapshots\n        k8s-datamodel database export $FIRST_ID --file week-start-$CONTEXT.json\n        k8s-datamodel database export $LATEST_ID --file week-end-$CONTEXT.json\n\n        # Calculate changes\n        START_CRDS=$(jq '.crds | length' week-start-$CONTEXT.json)\n        END_CRDS=$(jq '.crds | length' week-end-$CONTEXT.json)\n        CRD_CHANGE=$((END_CRDS - START_CRDS))\n\n        START_OPS=$(jq '.operators | length' week-start-$CONTEXT.json)\n        END_OPS=$(jq '.operators | length' week-end-$CONTEXT.json)\n        OP_CHANGE=$((END_OPS - START_OPS))\n\n        echo \"- CRDs: $START_CRDS \u2192 $END_CRDS (change: $CRD_CHANGE)\" &gt;&gt; weekly-trends.md\n        echo \"- Operators: $START_OPS \u2192 $END_OPS (change: $OP_CHANGE)\" &gt;&gt; weekly-trends.md\n        echo \"\" &gt;&gt; weekly-trends.md\n\n        # Cleanup temp files\n        rm week-start-$CONTEXT.json week-end-$CONTEXT.json\n    else\n        echo \"- No snapshots found for the past week\" &gt;&gt; weekly-trends.md\n        echo \"\" &gt;&gt; weekly-trends.md\n    fi\ndone\nEOF\n\nchmod +x weekly-trends.sh\n</code></pre>"},{"location":"examples/database-workflows/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"examples/database-workflows/#github-actions-integration","title":"GitHub Actions Integration","text":"<pre><code># .github/workflows/inventory-tracking.yml\nname: Kubernetes Inventory Tracking\n\non:\n  schedule:\n    - cron: '0 6 * * *'  # Daily at 6 AM UTC\n  workflow_dispatch:\n  push:\n    branches: [main]\n\njobs:\n  inventory:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n\n    - name: Setup Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: '3.10'\n\n    - name: Install k8s-datamodel\n      run: pipx install k8s-datamodel\n\n    - name: Configure kubectl\n      run: |\n        echo \"${{ secrets.KUBECONFIG }}\" | base64 -d &gt; /tmp/kubeconfig\n        export KUBECONFIG=/tmp/kubeconfig\n\n    - name: Store inventory snapshot\n      env:\n        KUBECONFIG: /tmp/kubeconfig\n      run: |\n        k8s-datamodel database store \\\n          --notes \"CI/CD automated snapshot - $(date +%Y-%m-%d) - ${{ github.sha }}\"\n\n    - name: Generate inventory report\n      env:\n        KUBECONFIG: /tmp/kubeconfig\n      run: |\n        # Get latest snapshot\n        LATEST_ID=$(k8s-datamodel database list --limit 1 --output json | jq -r '.[0].id')\n\n        # Export inventory\n        k8s-datamodel database export $LATEST_ID --file inventory-report.json\n\n        # Generate summary\n        echo \"# Kubernetes Inventory Report - $(date)\" &gt; inventory-summary.md\n        echo \"\" &gt;&gt; inventory-summary.md\n        echo \"**Generated by:** GitHub Actions\" &gt;&gt; inventory-summary.md\n        echo \"**Commit:** ${{ github.sha }}\" &gt;&gt; inventory-summary.md\n        echo \"\" &gt;&gt; inventory-summary.md\n\n        CRD_COUNT=$(jq '.crds | length' inventory-report.json)\n        OP_COUNT=$(jq '.operators | length' inventory-report.json)\n        CSV_COUNT=$(jq '.csvs | length' inventory-report.json)\n\n        echo \"## Summary\" &gt;&gt; inventory-summary.md\n        echo \"- **CRDs:** $CRD_COUNT\" &gt;&gt; inventory-summary.md\n        echo \"- **Operators:** $OP_COUNT\" &gt;&gt; inventory-summary.md  \n        echo \"- **OLM CSVs:** $CSV_COUNT\" &gt;&gt; inventory-summary.md\n\n    - name: Upload database\n      uses: actions/upload-artifact@v4\n      with:\n        name: inventory-database-${{ github.run_number }}\n        path: ~/.k8s-inventory/inventory.db\n        retention-days: 30\n\n    - name: Upload reports\n      uses: actions/upload-artifact@v4\n      with:\n        name: inventory-reports-${{ github.run_number }}\n        path: |\n          inventory-report.json\n          inventory-summary.md\n        retention-days: 30\n</code></pre>"},{"location":"examples/database-workflows/#terraform-integration","title":"Terraform Integration","text":"<pre><code># terraform/modules/k8s-inventory/main.tf\nresource \"null_resource\" \"k8s_inventory\" {\n  triggers = {\n    cluster_endpoint = var.cluster_endpoint\n    always_run       = timestamp()\n  }\n\n  provisioner \"local-exec\" {\n    command = &lt;&lt;-EOT\n      # Configure kubectl for the cluster\n      aws eks update-kubeconfig --region ${var.region} --name ${var.cluster_name}\n\n      # Store inventory snapshot\n      k8s-datamodel database store \\\n        --notes \"Terraform deployment - ${var.environment} - $(date +%Y-%m-%d-%H-%M)\"\n\n      # Export inventory for terraform outputs\n      LATEST_ID=$(k8s-datamodel database list --limit 1 --output json | jq -r '.[0].id')\n      k8s-datamodel database export $LATEST_ID --file ${var.output_path}/cluster-inventory.json\n    EOT\n  }\n\n  depends_on = [\n    kubernetes_namespace.applications\n  ]\n}\n\n# Output the inventory summary\ndata \"external\" \"inventory_summary\" {\n  program = [\"jq\", \"-n\", \"--slurpfile\", \"inventory\", \"${var.output_path}/cluster-inventory.json\", \n             \"{crds: ($inventory[0].crds | length), operators: ($inventory[0].operators | length), csvs: ($inventory[0].csvs | length)}\"]\n\n  depends_on = [null_resource.k8s_inventory]\n}\n\noutput \"inventory_summary\" {\n  description = \"Summary of Kubernetes resources in the cluster\"\n  value = {\n    crds      = data.external.inventory_summary.result[\"crds\"]\n    operators = data.external.inventory_summary.result[\"operators\"]\n    csvs      = data.external.inventory_summary.result[\"csvs\"]\n    snapshot_file = \"${var.output_path}/cluster-inventory.json\"\n  }\n}\n</code></pre>"},{"location":"examples/database-workflows/#monitoring-integration-with-prometheus","title":"Monitoring Integration with Prometheus","text":"<pre><code># Create Prometheus metrics exporter\ncat &gt; inventory-metrics-exporter.sh &lt;&lt; 'EOF'\n#!/bin/bash\n# Export k8s-datamodel metrics for Prometheus\n\n# Store current snapshot\nk8s-datamodel database store --notes \"Metrics collection - $(date)\"\n\n# Get latest snapshot\nLATEST_ID=$(k8s-datamodel database list --limit 1 --output json | jq -r '.[0].id')\nk8s-datamodel database export $LATEST_ID --file metrics-inventory.json\n\n# Generate Prometheus metrics\ncat &gt; /var/lib/node_exporter/k8s_inventory.prom &lt;&lt; METRICS\n# HELP k8s_inventory_crds_total Total number of CRDs in cluster\n# TYPE k8s_inventory_crds_total gauge\nk8s_inventory_crds_total $(jq '.crds | length' metrics-inventory.json)\n\n# HELP k8s_inventory_operators_total Total number of operators in cluster  \n# TYPE k8s_inventory_operators_total gauge\nk8s_inventory_operators_total $(jq '.operators | length' metrics-inventory.json)\n\n# HELP k8s_inventory_csvs_total Total number of OLM CSVs in cluster\n# TYPE k8s_inventory_csvs_total gauge\nk8s_inventory_csvs_total $(jq '.csvs | length' metrics-inventory.json)\n\n# HELP k8s_inventory_privileged_operators Total number of privileged operators\n# TYPE k8s_inventory_privileged_operators gauge\nk8s_inventory_privileged_operators $(jq '[.operators[] | select(.spec.spec.template.spec.containers[0].securityContext.privileged == true)] | length' metrics-inventory.json)\n\n# HELP k8s_inventory_operators_no_limits Total number of operators without resource limits\n# TYPE k8s_inventory_operators_no_limits gauge\nk8s_inventory_operators_no_limits $(jq '[.operators[] | select(.spec.spec.template.spec.containers[0].resources.limits == null)] | length' metrics-inventory.json)\n\n# HELP k8s_inventory_database_size_bytes Size of inventory database in bytes\n# TYPE k8s_inventory_database_size_bytes gauge\nk8s_inventory_database_size_bytes $(stat -c%s ~/.k8s-inventory/inventory.db)\nMETRICS\n\necho \"Metrics exported to /var/lib/node_exporter/k8s_inventory.prom\"\nrm metrics-inventory.json\nEOF\n\nchmod +x inventory-metrics-exporter.sh\n\n# Add to crontab for regular metrics collection\necho \"*/15 * * * * /path/to/inventory-metrics-exporter.sh\" | crontab -\n</code></pre>"},{"location":"examples/database-workflows/#best-practices-and-tips","title":"Best Practices and Tips","text":""},{"location":"examples/database-workflows/#1-snapshot-naming-conventions","title":"1. Snapshot Naming Conventions","text":"<pre><code># Use consistent naming patterns\nk8s-datamodel database store --notes \"TYPE-PURPOSE-DATE-DETAILS\"\n\n# Examples:\nk8s-datamodel database store --notes \"BASELINE-initial-cluster-setup-$(date +%Y-%m-%d)\"\nk8s-datamodel database store --notes \"AUDIT-sox-compliance-pre-$(date +%Y-%m-%d)\"\nk8s-datamodel database store --notes \"MIGRATION-source-cluster-$(date +%Y-%m-%d-%H-%M)\"\nk8s-datamodel database store --notes \"INCIDENT-post-recovery-$(date +%Y-%m-%d-%H-%M)\"\n</code></pre>"},{"location":"examples/database-workflows/#2-database-maintenance","title":"2. Database Maintenance","text":"<pre><code># Regular cleanup script\ncat &gt; db-maintenance.sh &lt;&lt; 'EOF'\n#!/bin/bash\n# Database maintenance routine\n\necho \"=== K8s Inventory Database Maintenance - $(date) ===\"\n\n# Show current statistics\necho \"Current database statistics:\"\nk8s-datamodel database stats\n\n# Clean up old snapshots (keep 30 most recent)\necho \"Cleaning up old snapshots...\"\nk8s-datamodel database cleanup --keep 30\n\n# Vacuum database to reclaim space\necho \"Vacuuming database...\"\nsqlite3 ~/.k8s-inventory/inventory.db \"VACUUM;\"\n\n# Show updated statistics\necho \"Updated database statistics:\"\nk8s-datamodel database stats\nEOF\n\nchmod +x db-maintenance.sh\n</code></pre>"},{"location":"examples/database-workflows/#3-error-handling-and-retry-logic","title":"3. Error Handling and Retry Logic","text":"<pre><code># Robust snapshot collection with retry\ncat &gt; robust-snapshot.sh &lt;&lt; 'EOF'\n#!/bin/bash\n# Robust snapshot collection with retry logic\n\nMAX_RETRIES=3\nRETRY_DELAY=30\nCONTEXT=${1:-\"default\"}\nNOTES=${2:-\"Automated snapshot - $(date)\"}\n\nfor i in $(seq 1 $MAX_RETRIES); do\n    echo \"Attempt $i of $MAX_RETRIES for context $CONTEXT\"\n\n    if k8s-datamodel --context $CONTEXT database store --notes \"$NOTES\"; then\n        echo \"\u2705 Successfully stored snapshot for $CONTEXT\"\n        exit 0\n    else\n        echo \"\u274c Failed attempt $i for $CONTEXT\"\n        if [ $i -lt $MAX_RETRIES ]; then\n            echo \"Waiting $RETRY_DELAY seconds before retry...\"\n            sleep $RETRY_DELAY\n        fi\n    fi\ndone\n\necho \"\ud83d\udea8 All attempts failed for context $CONTEXT\"\nexit 1\nEOF\n\nchmod +x robust-snapshot.sh\n</code></pre>"},{"location":"examples/database-workflows/#conclusion","title":"Conclusion","text":"<p>These examples demonstrate the powerful capabilities of k8s-datamodel's database functionality for real-world Kubernetes management scenarios. The tool enables comprehensive cluster tracking, compliance monitoring, security analysis, and operational insights through persistent storage of complete resource specifications.</p> <p>Key benefits demonstrated:</p> <ul> <li>Comprehensive Tracking: Complete cluster state preservation with datetime handling</li> <li>Multi-Environment Management: Consistent inventory across environments  </li> <li>Security Analysis: Deep inspection of RBAC, security contexts, and permissions</li> <li>Configuration Drift Detection: Automated detection of unauthorized changes</li> <li>Compliance Support: Audit trails and compliance reporting capabilities</li> <li>CI/CD Integration: Automated inventory collection in deployment pipelines</li> <li>Operational Monitoring: Trend analysis and alerting for cluster changes</li> </ul> <p>For additional examples and advanced use cases, refer to the complete documentation in the docs/ directory.</p>"},{"location":"examples/olm-workflows/","title":"OLM (Operator Lifecycle Manager) Workflow Examples","text":"<p>This document provides comprehensive examples for managing and analyzing OLM-deployed operators using k8s-datamodel.</p>"},{"location":"examples/olm-workflows/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Basic OLM Operations</li> <li>ClusterServiceVersion Analysis</li> <li>Operator Lifecycle Management</li> <li>RBAC and Security Analysis</li> <li>Upgrade and Version Management</li> <li>Multi-Environment OLM Management</li> <li>Troubleshooting and Diagnostics</li> <li>Integration with Monitoring</li> </ol>"},{"location":"examples/olm-workflows/#basic-olm-operations","title":"Basic OLM Operations","text":""},{"location":"examples/olm-workflows/#discovering-olm-managed-operators","title":"Discovering OLM-Managed Operators","text":"<pre><code># List all ClusterServiceVersions\nk8s-datamodel olm list\n\n# List with rich formatting for better readability\nk8s-datamodel olm list --output rich\n\n# Filter by installation status\nk8s-datamodel olm list --phase Succeeded\nk8s-datamodel olm list --phase Failed\nk8s-datamodel olm list --phase Installing\n\n# List OLM operators in specific namespace\nk8s-datamodel olm list --namespace operators\n</code></pre> <p>Expected Output: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Name                                \u2502 Namespace      \u2502 Display Name        \u2502 Version   \u2502 Phase                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 azure-service-operator.v1.0.28631   \u2502 operators      \u2502 Azure Service Operator \u2502 1.0.28631 \u2502 Succeeded                              \u2502\n\u2502 cloudnative-pg.v1.27.0              \u2502 operators      \u2502 CloudNativePG        \u2502 1.27.0    \u2502 Succeeded                              \u2502\n\u2502 mariadb-operator.v25.8.3            \u2502 operators      \u2502 MariaDB Operator     \u2502 25.8.3    \u2502 Succeeded                              \u2502\n\u2502 oracle-database-operator.v1.2.0     \u2502 operators      \u2502 Oracle DB Operator   \u2502 1.2.0     \u2502 Succeeded                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"examples/olm-workflows/#getting-detailed-csv-information","title":"Getting Detailed CSV Information","text":"<pre><code># Get detailed information about a specific CSV\nk8s-datamodel olm get azure-service-operator.v1.0.28631 --namespace operators\n\n# Get CSV details in JSON format for processing\nk8s-datamodel olm get cloudnative-pg.v1.27.0 --namespace operators --output json\n\n# Get CSV details in YAML format for human readability\nk8s-datamodel olm get mariadb-operator.v25.8.3 --namespace operators --output yaml\n</code></pre>"},{"location":"examples/olm-workflows/#olm-statistics-and-health","title":"OLM Statistics and Health","text":"<pre><code># Get comprehensive OLM statistics\nk8s-datamodel olm stats\n\n# Get statistics with rich formatting\nk8s-datamodel olm stats --output rich\n\n# Get statistics in JSON format for monitoring\nk8s-datamodel olm stats --output json\n</code></pre> <p>Expected Output: <pre><code>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 OLM Statistics \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Total ClusterServiceVersions: 33                                                                                               \u2502\n\u2502 Succeeded: 29                                                                                                                  \u2502\n\u2502 Failed: 2                                                                                                                      \u2502\n\u2502 Installing: 2                                                                                                                  \u2502\n\u2502                                                                                                                                \u2502\n\u2502 Total Owned CRDs: 156                                                                                                         \u2502\n\u2502 Total Required CRDs: 23                                                                                                       \u2502\n\u2502                                                                                                                                \u2502\n\u2502 Unique Providers: 12                                                                                                          \u2502\n\u2502 Namespaces with OLM: 4                                                                                                        \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre></p>"},{"location":"examples/olm-workflows/#clusterserviceversion-analysis","title":"ClusterServiceVersion Analysis","text":""},{"location":"examples/olm-workflows/#analyzing-csv-metadata-and-configuration","title":"Analyzing CSV Metadata and Configuration","text":"<pre><code># Store current OLM state for analysis\nk8s-datamodel database store --notes \"OLM Analysis - $(date +%Y-%m-%d)\"\n\n# Export OLM data for detailed analysis\nk8s-datamodel database export 1 --file olm-analysis.json\n\n# Analyze CSV providers\necho \"=== OLM Provider Analysis ===\"\njq -r '.csvs[] | \"\\(.provider): \\(.display_name) (\\(.version))\"' olm-analysis.json | sort | uniq -c | sort -nr\n\n# Analyze installation strategies\necho \"=== Installation Strategy Breakdown ===\"\njq -r '.csvs[] | .install_strategy' olm-analysis.json | sort | uniq -c\n\n# Find CSVs with specific capabilities\necho \"=== CSVs with Full Lifecycle Management ===\"\njq -r '.csvs[] | select(.spec.spec.installModes[]?.type == \"AllNamespaces\") | \n       \"\\(.name): \\(.display_name) - Supports AllNamespaces\"' olm-analysis.json\n</code></pre>"},{"location":"examples/olm-workflows/#crd-ownership-analysis","title":"CRD Ownership Analysis","text":"<pre><code># Analyze CRD ownership patterns\necho \"=== CRD Ownership Analysis ===\"\n\n# Find CSVs with the most owned CRDs\necho \"## Top CRD Owners:\"\njq -r '.csvs[] | \"\\(.owned_crds | length) \\(.name) \\(.display_name)\"' olm-analysis.json | \n    sort -nr | head -10\n\n# Find CRDs managed by multiple operators\necho \"## CRDs with Multiple Owners:\"\njq -r '.csvs[] | .owned_crds[] as $crd | \"\\($crd) \\(.name)\"' olm-analysis.json | \n    sort | uniq | cut -d' ' -f1 | sort | uniq -d | \n    while read crd; do\n        echo \"CRD: $crd\"\n        grep \"^$crd \" &lt;(jq -r '.csvs[] | .owned_crds[] as $crd | \"\\($crd) \\(.name)\"' olm-analysis.json) | \n            sed 's/^[^ ]* /  Owned by: /'\n        echo\n    done\n\n# Analyze CRD dependencies  \necho \"## CRD Dependencies:\"\njq -r '.csvs[] | select(.required_crds | length &gt; 0) | \n       \"\\(.name) requires: \\(.required_crds | join(\\\", \\\"))\"' olm-analysis.json\n</code></pre>"},{"location":"examples/olm-workflows/#csv-resource-requirements-analysis","title":"CSV Resource Requirements Analysis","text":"<pre><code># Analyze resource requirements from CSV specs\necho \"=== CSV Resource Requirements Analysis ===\"\n\n# Extract deployment specifications from CSVs\njq -r '.csvs[] | select(.spec.spec.install.strategy == \"deployment\") | \n       {name: .name, deployments: .spec.spec.install.spec.deployments[].spec.template.spec.containers[0].resources}' \\\n       olm-analysis.json &gt; csv-resources.json\n\n# Find CSVs without resource limits\necho \"## CSVs without Resource Limits:\"\njq -r 'select(.deployments.limits == null) | .name' csv-resources.json\n\n# Calculate total resource requests\necho \"## Total Resource Requests:\"\njq -r 'select(.deployments.requests != null) | \n       \"\\(.name): CPU=\\(.deployments.requests.cpu // \"none\"), Memory=\\(.deployments.requests.memory // \"none\")\"' \\\n       csv-resources.json\n\n# Find high-resource CSVs\necho \"## High Resource CSVs:\"\njq -r 'select(.deployments.requests.memory != null) | \n       select(.deployments.requests.memory | test(\"Gi\")) | \n       \"\\(.name): \\(.deployments.requests.memory)\"' csv-resources.json\n</code></pre>"},{"location":"examples/olm-workflows/#operator-lifecycle-management","title":"Operator Lifecycle Management","text":""},{"location":"examples/olm-workflows/#monitoring-operator-health","title":"Monitoring Operator Health","text":"<pre><code># Create OLM health monitoring script\ncat &gt; olm-health-monitor.sh &lt;&lt; 'EOF'\n#!/bin/bash\n# OLM Health Monitoring Script\n\nDATE=$(date +%Y-%m-%d-%H-%M)\nLOG_FILE=\"olm-health-$DATE.log\"\n\necho \"=== OLM Health Check - $(date) ===\" | tee $LOG_FILE\n\n# Check overall OLM status\necho \"## Overall OLM Status\" | tee -a $LOG_FILE\nk8s-datamodel olm stats --output table | tee -a $LOG_FILE\necho \"\" | tee -a $LOG_FILE\n\n# Check failed CSVs\necho \"## Failed ClusterServiceVersions\" | tee -a $LOG_FILE\nFAILED_CSVS=$(k8s-datamodel olm list --phase Failed --output json)\nif [ \"$(echo \"$FAILED_CSVS\" | jq '. | length')\" -gt 0 ]; then\n    echo \"$FAILED_CSVS\" | jq -r '.[] | \"\u274c \\(.name) in \\(.namespace) - \\(.phase)\"' | tee -a $LOG_FILE\nelse\n    echo \"\u2705 No failed CSVs detected\" | tee -a $LOG_FILE\nfi\necho \"\" | tee -a $LOG_FILE\n\n# Check installing CSVs (potential stuck installations)\necho \"## Installing ClusterServiceVersions\" | tee -a $LOG_FILE  \nINSTALLING_CSVS=$(k8s-datamodel olm list --phase Installing --output json)\nif [ \"$(echo \"$INSTALLING_CSVS\" | jq '. | length')\" -gt 0 ]; then\n    echo \"\u26a0\ufe0f CSVs currently installing:\" | tee -a $LOG_FILE\n    echo \"$INSTALLING_CSVS\" | jq -r '.[] | \"   \\(.name) in \\(.namespace)\"' | tee -a $LOG_FILE\nelse\n    echo \"\u2705 No CSVs currently installing\" | tee -a $LOG_FILE\nfi\necho \"\" | tee -a $LOG_FILE\n\n# Check for version mismatches\necho \"## Version Consistency Check\" | tee -a $LOG_FILE\nk8s-datamodel database export $(k8s-datamodel database list --limit 1 --output json | jq -r '.[0].id') --file current-olm.json\njq -r '.csvs[] | select(.replaces != null and .replaces != \"\") | \n       \"Upgrade detected: \\(.name) replaces \\(.replaces)\"' current-olm.json | tee -a $LOG_FILE\n\necho \"Health check complete. Results saved to $LOG_FILE\"\nEOF\n\nchmod +x olm-health-monitor.sh\n</code></pre>"},{"location":"examples/olm-workflows/#upgrade-planning-and-tracking","title":"Upgrade Planning and Tracking","text":"<pre><code># Create upgrade planning workflow\ncat &gt; olm-upgrade-planner.sh &lt;&lt; 'EOF'\n#!/bin/bash\n# OLM Upgrade Planning Script\n\nUPGRADE_PLAN_FILE=\"olm-upgrade-plan-$(date +%Y-%m-%d).md\"\n\necho \"# OLM Upgrade Plan - $(date)\" &gt; $UPGRADE_PLAN_FILE\necho \"\" &gt;&gt; $UPGRADE_PLAN_FILE\n\n# Store pre-upgrade snapshot\nk8s-datamodel database store --notes \"Pre-upgrade baseline - $(date +%Y-%m-%d)\"\nBASELINE_ID=$(k8s-datamodel database list --limit 1 --output json | jq -r '.[0].id')\n\n# Export current state\nk8s-datamodel database export $BASELINE_ID --file pre-upgrade-olm.json\n\necho \"## Current OLM State\" &gt;&gt; $UPGRADE_PLAN_FILE\necho \"- Total CSVs: $(jq '.csvs | length' pre-upgrade-olm.json)\" &gt;&gt; $UPGRADE_PLAN_FILE\necho \"- Succeeded: $(jq '[.csvs[] | select(.phase == \"Succeeded\")] | length' pre-upgrade-olm.json)\" &gt;&gt; $UPGRADE_PLAN_FILE\necho \"- Failed: $(jq '[.csvs[] | select(.phase == \"Failed\")] | length' pre-upgrade-olm.json)\" &gt;&gt; $UPGRADE_PLAN_FILE\necho \"\" &gt;&gt; $UPGRADE_PLAN_FILE\n\necho \"## Operators Ready for Upgrade\" &gt;&gt; $UPGRADE_PLAN_FILE\n# Find CSVs that have newer versions available (based on replaces field analysis)\njq -r '.csvs[] | select(.replaces != null and .replaces != \"\") | \n       \"- **\\(.display_name)**: \\(.version) (replaces: \\(.replaces))\"' pre-upgrade-olm.json &gt;&gt; $UPGRADE_PLAN_FILE\necho \"\" &gt;&gt; $UPGRADE_PLAN_FILE\n\necho \"## Upgrade Dependencies\" &gt;&gt; $UPGRADE_PLAN_FILE\n# Analyze required CRDs for upgrade compatibility\njq -r '.csvs[] | select(.required_crds | length &gt; 0) | \n       \"- **\\(.display_name)**: requires \\(.required_crds | join(\", \"))\"' pre-upgrade-olm.json &gt;&gt; $UPGRADE_PLAN_FILE\necho \"\" &gt;&gt; $UPGRADE_PLAN_FILE\n\necho \"## Pre-Upgrade Checklist\" &gt;&gt; $UPGRADE_PLAN_FILE\necho \"- [ ] Backup cluster state\" &gt;&gt; $UPGRADE_PLAN_FILE\necho \"- [ ] Verify all CSVs are in Succeeded state\" &gt;&gt; $UPGRADE_PLAN_FILE  \necho \"- [ ] Check for stuck installations\" &gt;&gt; $UPGRADE_PLAN_FILE\necho \"- [ ] Review upgrade dependencies\" &gt;&gt; $UPGRADE_PLAN_FILE\necho \"- [ ] Schedule maintenance window\" &gt;&gt; $UPGRADE_PLAN_FILE\necho \"\" &gt;&gt; $UPGRADE_PLAN_FILE\n\necho \"Upgrade plan generated: $UPGRADE_PLAN_FILE\"\necho \"Baseline snapshot ID: $BASELINE_ID\"\nEOF\n\nchmod +x olm-upgrade-planner.sh\n</code></pre>"},{"location":"examples/olm-workflows/#post-upgrade-verification","title":"Post-Upgrade Verification","text":"<pre><code># Create post-upgrade verification script\ncat &gt; olm-upgrade-verify.sh &lt;&lt; 'EOF'\n#!/bin/bash\n# OLM Post-Upgrade Verification Script\n\nBASELINE_ID=${1:-$(cat .pre-upgrade-snapshot-id 2&gt;/dev/null)}\nif [ -z \"$BASELINE_ID\" ]; then\n    echo \"Error: Please provide baseline snapshot ID\"\n    echo \"Usage: $0 &lt;baseline_snapshot_id&gt;\"\n    exit 1\nfi\n\nVERIFICATION_REPORT=\"olm-upgrade-verification-$(date +%Y-%m-%d).md\"\n\necho \"# OLM Upgrade Verification Report - $(date)\" &gt; $VERIFICATION_REPORT\necho \"\" &gt;&gt; $VERIFICATION_REPORT\n\n# Store post-upgrade snapshot\nk8s-datamodel database store --notes \"Post-upgrade verification - $(date +%Y-%m-%d)\"\nPOST_UPGRADE_ID=$(k8s-datamodel database list --limit 1 --output json | jq -r '.[0].id')\n\n# Export both snapshots\nk8s-datamodel database export $BASELINE_ID --file pre-upgrade.json\nk8s-datamodel database export $POST_UPGRADE_ID --file post-upgrade.json\n\necho \"## Upgrade Summary\" &gt;&gt; $VERIFICATION_REPORT\necho \"- Baseline Snapshot: $BASELINE_ID\" &gt;&gt; $VERIFICATION_REPORT\necho \"- Post-Upgrade Snapshot: $POST_UPGRADE_ID\" &gt;&gt; $VERIFICATION_REPORT\necho \"\" &gt;&gt; $VERIFICATION_REPORT\n\n# Compare CSV counts\nPRE_COUNT=$(jq '.csvs | length' pre-upgrade.json)\nPOST_COUNT=$(jq '.csvs | length' post-upgrade.json)\necho \"## CSV Count Comparison\" &gt;&gt; $VERIFICATION_REPORT\necho \"- Pre-upgrade: $PRE_COUNT CSVs\" &gt;&gt; $VERIFICATION_REPORT\necho \"- Post-upgrade: $POST_COUNT CSVs\" &gt;&gt; $VERIFICATION_REPORT\necho \"- Change: $(($POST_COUNT - $PRE_COUNT))\" &gt;&gt; $VERIFICATION_REPORT\necho \"\" &gt;&gt; $VERIFICATION_REPORT\n\n# Check for failed CSVs\necho \"## Failed CSVs After Upgrade\" &gt;&gt; $VERIFICATION_REPORT\nFAILED_CSVS=$(jq -r '.csvs[] | select(.phase == \"Failed\") | .name' post-upgrade.json)\nif [ -n \"$FAILED_CSVS\" ]; then\n    echo \"\u26a0\ufe0f Failed CSVs detected:\" &gt;&gt; $VERIFICATION_REPORT\n    echo \"$FAILED_CSVS\" | while read csv; do echo \"- \u274c $csv\"; done &gt;&gt; $VERIFICATION_REPORT\nelse\n    echo \"\u2705 No failed CSVs detected\" &gt;&gt; $VERIFICATION_REPORT\nfi\necho \"\" &gt;&gt; $VERIFICATION_REPORT\n\n# Check version changes\necho \"## Version Changes\" &gt;&gt; $VERIFICATION_REPORT\necho \"### Upgraded CSVs\" &gt;&gt; $VERIFICATION_REPORT\ncomm -13 &lt;(jq -r '.csvs[] | \"\\(.name) \\(.version)\"' pre-upgrade.json | sort) \\\n         &lt;(jq -r '.csvs[] | \"\\(.name) \\(.version)\"' post-upgrade.json | sort) | \\\nwhile read csv_version; do echo \"- \u2705 $csv_version\"; done &gt;&gt; $VERIFICATION_REPORT\n\necho \"\" &gt;&gt; $VERIFICATION_REPORT\necho \"### New CSVs Added\" &gt;&gt; $VERIFICATION_REPORT\ncomm -13 &lt;(jq -r '.csvs[].name' pre-upgrade.json | sort) \\\n         &lt;(jq -r '.csvs[].name' post-upgrade.json | sort) | \\\nwhile read csv; do echo \"- \u2795 $csv\"; done &gt;&gt; $VERIFICATION_REPORT\n\necho \"\" &gt;&gt; $VERIFICATION_REPORT\necho \"### CSVs Removed\" &gt;&gt; $VERIFICATION_REPORT\ncomm -23 &lt;(jq -r '.csvs[].name' pre-upgrade.json | sort) \\\n         &lt;(jq -r '.csvs[].name' post-upgrade.json | sort) | \\\nwhile read csv; do echo \"- \u2796 $csv\"; done &gt;&gt; $VERIFICATION_REPORT\n\necho \"\" &gt;&gt; $VERIFICATION_REPORT\necho \"## Verification Status\" &gt;&gt; $VERIFICATION_REPORT\nif [ -z \"$FAILED_CSVS\" ]; then\n    echo \"\u2705 Upgrade verification PASSED\" &gt;&gt; $VERIFICATION_REPORT\nelse\n    echo \"\u26a0\ufe0f Upgrade verification REQUIRES ATTENTION\" &gt;&gt; $VERIFICATION_REPORT\nfi\n\necho \"Verification report generated: $VERIFICATION_REPORT\"\nEOF\n\nchmod +x olm-upgrade-verify.sh\n</code></pre>"},{"location":"examples/olm-workflows/#rbac-and-security-analysis","title":"RBAC and Security Analysis","text":""},{"location":"examples/olm-workflows/#comprehensive-rbac-analysis","title":"Comprehensive RBAC Analysis","text":"<pre><code># Create comprehensive RBAC analysis script  \ncat &gt; olm-rbac-analyzer.sh &lt;&lt; 'EOF'\n#!/bin/bash\n# OLM RBAC Analysis Script\n\nREPORT_FILE=\"olm-rbac-analysis-$(date +%Y-%m-%d).md\"\n\necho \"# OLM RBAC Security Analysis - $(date)\" &gt; $REPORT_FILE\necho \"\" &gt;&gt; $REPORT_FILE\n\n# Store current state for analysis\nk8s-datamodel database store --notes \"RBAC Security Analysis - $(date +%Y-%m-%d)\"\nSNAPSHOT_ID=$(k8s-datamodel database list --limit 1 --output json | jq -r '.[0].id')\nk8s-datamodel database export $SNAPSHOT_ID --file rbac-analysis.json\n\necho \"## Executive Summary\" &gt;&gt; $REPORT_FILE\nTOTAL_CSVS=$(jq '.csvs | length' rbac-analysis.json)\nCSVS_WITH_CLUSTER_PERMS=$(jq '[.csvs[] | select(.spec.spec.install.spec.clusterPermissions | length &gt; 0)] | length' rbac-analysis.json)\necho \"- Total CSVs analyzed: $TOTAL_CSVS\" &gt;&gt; $REPORT_FILE\necho \"- CSVs with cluster permissions: $CSVS_WITH_CLUSTER_PERMS\" &gt;&gt; $REPORT_FILE\necho \"- Security risk level: $([ $CSVS_WITH_CLUSTER_PERMS -gt $(($TOTAL_CSVS / 2)) ] &amp;&amp; echo \"HIGH\" || echo \"MODERATE\")\" &gt;&gt; $REPORT_FILE\necho \"\" &gt;&gt; $REPORT_FILE\n\necho \"## Cluster-Level Permissions Analysis\" &gt;&gt; $REPORT_FILE\necho \"### CSVs with Cluster Permissions\" &gt;&gt; $REPORT_FILE\njq -r '.csvs[] | select(.spec.spec.install.spec.clusterPermissions | length &gt; 0) | \n       \"- **\\(.display_name)** (\\(.name)): \\(.spec.spec.install.spec.clusterPermissions | length) cluster permissions\"' \\\n       rbac-analysis.json &gt;&gt; $REPORT_FILE\necho \"\" &gt;&gt; $REPORT_FILE\n\necho \"### High-Risk Permissions\" &gt;&gt; $REPORT_FILE\necho \"#### Wildcard Resource Access (*)\" &gt;&gt; $REPORT_FILE\njq -r '.csvs[] | select(.spec.spec.install.spec.clusterPermissions[]?.rules[]?.resources[]? == \"*\") | \n       \"- \ud83d\udea8 **\\(.display_name)**: Has wildcard (*) resource access\"' rbac-analysis.json &gt;&gt; $REPORT_FILE\n\necho \"\" &gt;&gt; $REPORT_FILE\necho \"#### Wildcard Verb Access (*)\" &gt;&gt; $REPORT_FILE\njq -r '.csvs[] | select(.spec.spec.install.spec.clusterPermissions[]?.rules[]?.verbs[]? == \"*\") | \n       \"- \ud83d\udea8 **\\(.display_name)**: Has wildcard (*) verb access\"' rbac-analysis.json &gt;&gt; $REPORT_FILE\n\necho \"\" &gt;&gt; $REPORT_FILE  \necho \"#### Dangerous Resource Access\" &gt;&gt; $REPORT_FILE\nDANGEROUS_RESOURCES=(\"nodes\" \"persistentvolumes\" \"clusterroles\" \"clusterrolebindings\" \"secrets\")\nfor resource in \"${DANGEROUS_RESOURCES[@]}\"; do\n    echo \"##### Access to $resource\" &gt;&gt; $REPORT_FILE\n    jq -r --arg res \"$resource\" '.csvs[] | \n           select(.spec.spec.install.spec.clusterPermissions[]?.rules[]?.resources[]? == $res) | \n           \"- \u26a0\ufe0f **\\(.display_name)**: Can access \\($res)\"' rbac-analysis.json &gt;&gt; $REPORT_FILE\ndone\n\necho \"\" &gt;&gt; $REPORT_FILE\necho \"## Namespace-Level Permissions Analysis\" &gt;&gt; $REPORT_FILE\njq -r '.csvs[] | select(.spec.spec.install.spec.permissions | length &gt; 0) | \n       \"- **\\(.display_name)**: \\(.spec.spec.install.spec.permissions | length) namespace permissions\"' \\\n       rbac-analysis.json &gt;&gt; $REPORT_FILE\n\necho \"\" &gt;&gt; $REPORT_FILE\necho \"## Security Recommendations\" &gt;&gt; $REPORT_FILE\necho \"1. **Review Wildcard Permissions**: CSVs with wildcard access should be carefully reviewed\" &gt;&gt; $REPORT_FILE\necho \"2. **Implement Least Privilege**: Ensure operators only have necessary permissions\" &gt;&gt; $REPORT_FILE  \necho \"3. **Monitor Privilege Escalation**: Track changes in operator permissions over time\" &gt;&gt; $REPORT_FILE\necho \"4. **Audit Dangerous Resources**: Special attention to operators accessing sensitive resources\" &gt;&gt; $REPORT_FILE\necho \"5. **Regular Security Reviews**: Schedule periodic RBAC permission audits\" &gt;&gt; $REPORT_FILE\n\necho \"RBAC analysis complete: $REPORT_FILE\"\nEOF\n\nchmod +x olm-rbac-analyzer.sh\n</code></pre>"},{"location":"examples/olm-workflows/#security-context-analysis","title":"Security Context Analysis","text":"<pre><code># Analyze security contexts of OLM-managed operators\ncat &gt; olm-security-context-analyzer.sh &lt;&lt; 'EOF'\n#!/bin/bash\n# OLM Security Context Analysis Script\n\nREPORT_FILE=\"olm-security-contexts-$(date +%Y-%m-%d).md\"\n\necho \"# OLM Security Context Analysis - $(date)\" &gt; $REPORT_FILE\necho \"\" &gt;&gt; $REPORT_FILE\n\n# Get current cluster state\nk8s-datamodel database store --notes \"Security Context Analysis - $(date +%Y-%m-%d)\"\nSNAPSHOT_ID=$(k8s-datamodel database list --limit 1 --output json | jq -r '.[0].id')\nk8s-datamodel database export $SNAPSHOT_ID --file security-context-analysis.json\n\necho \"## Security Context Summary\" &gt;&gt; $REPORT_FILE\n\n# Find operators managed by OLM (deployed via CSVs)\nOLM_OPERATORS=$(jq -r '.csvs[] | .spec.spec.install.spec.deployments[]?.name' security-context-analysis.json | sort | uniq)\n\necho \"### OLM-Managed Operators Security Analysis\" &gt;&gt; $REPORT_FILE\nwhile read operator; do\n    if [ -n \"$operator\" ]; then\n        echo \"#### $operator\" &gt;&gt; $REPORT_FILE\n\n        # Find corresponding operator in operators list\n        OPERATOR_INFO=$(jq --arg op \"$operator\" '.operators[] | select(.name == $op)' security-context-analysis.json)\n\n        if [ \"$OPERATOR_INFO\" != \"null\" ] &amp;&amp; [ -n \"$OPERATOR_INFO\" ]; then\n            # Check security context\n            PRIVILEGED=$(echo \"$OPERATOR_INFO\" | jq -r '.spec.spec.template.spec.containers[0].securityContext.privileged // false')\n            RUN_AS_ROOT=$(echo \"$OPERATOR_INFO\" | jq -r '.spec.spec.template.spec.containers[0].securityContext.runAsUser // \"not_set\"')\n            HOST_NETWORK=$(echo \"$OPERATOR_INFO\" | jq -r '.spec.spec.template.spec.hostNetwork // false')\n\n            echo \"- Privileged: $PRIVILEGED\" &gt;&gt; $REPORT_FILE\n            echo \"- Run as root: $([ \"$RUN_AS_ROOT\" = \"0\" ] &amp;&amp; echo \"true\" || echo \"false ($RUN_AS_ROOT)\")\" &gt;&gt; $REPORT_FILE\n            echo \"- Host network: $HOST_NETWORK\" &gt;&gt; $REPORT_FILE\n\n            # Security score\n            SECURITY_ISSUES=0\n            [ \"$PRIVILEGED\" = \"true\" ] &amp;&amp; ((SECURITY_ISSUES++))\n            [ \"$RUN_AS_ROOT\" = \"0\" ] &amp;&amp; ((SECURITY_ISSUES++))  \n            [ \"$HOST_NETWORK\" = \"true\" ] &amp;&amp; ((SECURITY_ISSUES++))\n\n            if [ $SECURITY_ISSUES -eq 0 ]; then\n                echo \"- **Security Level: \u2705 GOOD**\" &gt;&gt; $REPORT_FILE\n            elif [ $SECURITY_ISSUES -eq 1 ]; then\n                echo \"- **Security Level: \u26a0\ufe0f MODERATE RISK**\" &gt;&gt; $REPORT_FILE\n            else\n                echo \"- **Security Level: \ud83d\udea8 HIGH RISK**\" &gt;&gt; $REPORT_FILE\n            fi\n        else\n            echo \"- **Status: Not found in operator inventory**\" &gt;&gt; $REPORT_FILE\n        fi\n        echo \"\" &gt;&gt; $REPORT_FILE\n    fi\ndone &lt;&lt;&lt; \"$OLM_OPERATORS\"\n\necho \"## High-Risk Security Configurations\" &gt;&gt; $REPORT_FILE\necho \"### Privileged Containers\" &gt;&gt; $REPORT_FILE\njq -r '.operators[] | select(.spec.spec.template.spec.containers[0].securityContext.privileged == true) | \n       \"- \ud83d\udea8 **\\(.name)** (namespace: \\(.namespace)): Running privileged\"' security-context-analysis.json &gt;&gt; $REPORT_FILE\n\necho \"\" &gt;&gt; $REPORT_FILE  \necho \"### Host Network Access\" &gt;&gt; $REPORT_FILE\njq -r '.operators[] | select(.spec.spec.template.spec.hostNetwork == true) | \n       \"- \u26a0\ufe0f **\\(.name)** (namespace: \\(.namespace)): Has host network access\"' security-context-analysis.json &gt;&gt; $REPORT_FILE\n\necho \"\" &gt;&gt; $REPORT_FILE\necho \"### Root User Execution\" &gt;&gt; $REPORT_FILE\njq -r '.operators[] | select(.spec.spec.template.spec.containers[0].securityContext.runAsUser == 0) | \n       \"- \u26a0\ufe0f **\\(.name)** (namespace: \\(.namespace)): Running as root user\"' security-context-analysis.json &gt;&gt; $REPORT_FILE\n\necho \"Security context analysis complete: $REPORT_FILE\"\nEOF\n\nchmod +x olm-security-context-analyzer.sh\n</code></pre>"},{"location":"examples/olm-workflows/#upgrade-and-version-management","title":"Upgrade and Version Management","text":""},{"location":"examples/olm-workflows/#version-tracking-and-analysis","title":"Version Tracking and Analysis","text":"<pre><code># Create version tracking script\ncat &gt; olm-version-tracker.sh &lt;&lt; 'EOF'\n#!/bin/bash\n# OLM Version Tracking Script\n\nREPORT_FILE=\"olm-version-report-$(date +%Y-%m-%d).md\"\n\necho \"# OLM Version Tracking Report - $(date)\" &gt; $REPORT_FILE\necho \"\" &gt;&gt; $REPORT_FILE\n\n# Store current state\nk8s-datamodel database store --notes \"Version tracking - $(date +%Y-%m-%d)\"\nCURRENT_ID=$(k8s-datamodel database list --limit 1 --output json | jq -r '.[0].id')\nk8s-datamodel database export $CURRENT_ID --file current-versions.json\n\necho \"## Current Version Inventory\" &gt;&gt; $REPORT_FILE\necho \"| Operator | Current Version | Replaces | Min Kube Version |\" &gt;&gt; $REPORT_FILE\necho \"|----------|----------------|----------|------------------|\" &gt;&gt; $REPORT_FILE\n\njq -r '.csvs[] | \"| \\(.display_name) | \\(.version) | \\(.replaces // \"None\") | \\(.min_kube_version // \"Not specified\") |\"' \\\n   current-versions.json &gt;&gt; $REPORT_FILE\n\necho \"\" &gt;&gt; $REPORT_FILE\necho \"## Version Management Analysis\" &gt;&gt; $REPORT_FILE\n\n# Check for upgrade chains\necho \"### Active Upgrade Chains\" &gt;&gt; $REPORT_FILE\njq -r '.csvs[] | select(.replaces != null and .replaces != \"\") | \n       \"- **\\(.display_name)**: \\(.replaces) \u2192 \\(.version)\"' current-versions.json &gt;&gt; $REPORT_FILE\n\necho \"\" &gt;&gt; $REPORT_FILE\necho \"### Skipped Versions\" &gt;&gt; $REPORT_FILE\njq -r '.csvs[] | select(.skips | length &gt; 0) | \n       \"- **\\(.display_name)**: skips versions \\(.skips | join(\\\", \\\"))\"' current-versions.json &gt;&gt; $REPORT_FILE\n\n# Compare with previous snapshot if available\nPREVIOUS_ID=$(k8s-datamodel database list --offset 1 --limit 1 --output json | jq -r '.[0].id // empty')\nif [ -n \"$PREVIOUS_ID\" ]; then\n    echo \"\" &gt;&gt; $REPORT_FILE\n    echo \"## Changes Since Last Snapshot (ID: $PREVIOUS_ID)\" &gt;&gt; $REPORT_FILE\n\n    k8s-datamodel database export $PREVIOUS_ID --file previous-versions.json\n\n    echo \"### Version Updates\" &gt;&gt; $REPORT_FILE\n    comm -13 &lt;(jq -r '.csvs[] | \"\\(.name) \\(.version)\"' previous-versions.json | sort) \\\n             &lt;(jq -r '.csvs[] | \"\\(.name) \\(.version)\"' current-versions.json | sort) | \\\n    while read update; do echo \"- \u2705 $update\"; done &gt;&gt; $REPORT_FILE\n\n    echo \"\" &gt;&gt; $REPORT_FILE\n    echo \"### New Operators\" &gt;&gt; $REPORT_FILE  \n    comm -13 &lt;(jq -r '.csvs[].name' previous-versions.json | sort) \\\n             &lt;(jq -r '.csvs[].name' current-versions.json | sort) | \\\n    while read new_op; do echo \"- \u2795 $new_op\"; done &gt;&gt; $REPORT_FILE\n\n    echo \"\" &gt;&gt; $REPORT_FILE\n    echo \"### Removed Operators\" &gt;&gt; $REPORT_FILE\n    comm -23 &lt;(jq -r '.csvs[].name' previous-versions.json | sort) \\\n             &lt;(jq -r '.csvs[].name' current-versions.json | sort) | \\\n    while read removed_op; do echo \"- \u2796 $removed_op\"; done &gt;&gt; $REPORT_FILE\nfi\n\necho \"Version tracking report generated: $REPORT_FILE\"\nEOF\n\nchmod +x olm-version-tracker.sh\n</code></pre>"},{"location":"examples/olm-workflows/#multi-environment-olm-management","title":"Multi-Environment OLM Management","text":""},{"location":"examples/olm-workflows/#cross-environment-olm-comparison","title":"Cross-Environment OLM Comparison","text":"<pre><code># Create multi-environment OLM comparison script\ncat &gt; olm-multi-env-compare.sh &lt;&lt; 'EOF'\n#!/bin/bash\n# Multi-Environment OLM Comparison Script\n\nENVIRONMENTS=(\"prod-cluster\" \"staging-cluster\" \"dev-cluster\")\nREPORT_FILE=\"olm-multi-env-comparison-$(date +%Y-%m-%d).md\"\n\necho \"# Multi-Environment OLM Comparison - $(date)\" &gt; $REPORT_FILE\necho \"\" &gt;&gt; $REPORT_FILE\n\n# Store snapshots for each environment\ndeclare -A ENV_SNAPSHOTS\nfor env in \"${ENVIRONMENTS[@]}\"; do\n    echo \"Collecting OLM data for $env...\"\n    k8s-datamodel --context $env database store --notes \"Multi-env comparison - $env - $(date +%Y-%m-%d)\"\n    ENV_SNAPSHOTS[$env]=$(k8s-datamodel database list --cluster-context $env --limit 1 --output json | jq -r '.[0].id')\n    k8s-datamodel database export ${ENV_SNAPSHOTS[$env]} --file \"olm-$env.json\"\ndone\n\necho \"## Environment Summary\" &gt;&gt; $REPORT_FILE\necho \"| Environment | Total CSVs | Succeeded | Failed | Installing |\" &gt;&gt; $REPORT_FILE\necho \"|-------------|------------|-----------|---------|------------|\" &gt;&gt; $REPORT_FILE\n\nfor env in \"${ENVIRONMENTS[@]}\"; do\n    TOTAL=$(jq '.csvs | length' \"olm-$env.json\")\n    SUCCEEDED=$(jq '[.csvs[] | select(.phase == \"Succeeded\")] | length' \"olm-$env.json\")\n    FAILED=$(jq '[.csvs[] | select(.phase == \"Failed\")] | length' \"olm-$env.json\")  \n    INSTALLING=$(jq '[.csvs[] | select(.phase == \"Installing\")] | length' \"olm-$env.json\")\n\n    echo \"| $env | $TOTAL | $SUCCEEDED | $FAILED | $INSTALLING |\" &gt;&gt; $REPORT_FILE\ndone\n\necho \"\" &gt;&gt; $REPORT_FILE\necho \"## Operator Consistency Analysis\" &gt;&gt; $REPORT_FILE\n\n# Find operators present in all environments\necho \"### Operators in All Environments\" &gt;&gt; $REPORT_FILE\nALL_OPERATORS=\"\"\nfor env in \"${ENVIRONMENTS[@]}\"; do\n    if [ -z \"$ALL_OPERATORS\" ]; then\n        ALL_OPERATORS=$(jq -r '.csvs[].name' \"olm-$env.json\" | sort)\n    else\n        ALL_OPERATORS=$(comm -12 &lt;(echo \"$ALL_OPERATORS\") &lt;(jq -r '.csvs[].name' \"olm-$env.json\" | sort))\n    fi\ndone\n\nwhile read operator; do\n    if [ -n \"$operator\" ]; then\n        echo \"#### $operator\" &gt;&gt; $REPORT_FILE\n        for env in \"${ENVIRONMENTS[@]}\"; do\n            VERSION=$(jq -r --arg op \"$operator\" '.csvs[] | select(.name == $op) | .version' \"olm-$env.json\")\n            PHASE=$(jq -r --arg op \"$operator\" '.csvs[] | select(.name == $op) | .phase' \"olm-$env.json\")\n            echo \"- $env: $VERSION ($PHASE)\" &gt;&gt; $REPORT_FILE\n        done\n        echo \"\" &gt;&gt; $REPORT_FILE\n    fi\ndone &lt;&lt;&lt; \"$ALL_OPERATORS\"\n\n# Find environment-specific operators\necho \"### Environment-Specific Operators\" &gt;&gt; $REPORT_FILE\nfor env in \"${ENVIRONMENTS[@]}\"; do\n    echo \"#### Unique to $env\" &gt;&gt; $REPORT_FILE\n    UNIQUE_OPS=\"\"\n    OTHER_OPS=\"\"\n\n    for other_env in \"${ENVIRONMENTS[@]}\"; do\n        if [ \"$other_env\" != \"$env\" ]; then\n            OTHER_OPS=\"$OTHER_OPS $(jq -r '.csvs[].name' \"olm-$other_env.json\")\"\n        fi\n    done\n\n    jq -r '.csvs[].name' \"olm-$env.json\" | while read op; do\n        if ! echo \"$OTHER_OPS\" | grep -q \"$op\"; then\n            echo \"- $op\" &gt;&gt; $REPORT_FILE\n        fi\n    done\n    echo \"\" &gt;&gt; $REPORT_FILE\ndone\n\necho \"## Version Drift Analysis\" &gt;&gt; $REPORT_FILE\necho \"### Operators with Version Differences\" &gt;&gt; $REPORT_FILE\nwhile read operator; do\n    if [ -n \"$operator\" ]; then\n        VERSIONS=\"\"\n        for env in \"${ENVIRONMENTS[@]}\"; do\n            VERSION=$(jq -r --arg op \"$operator\" '.csvs[] | select(.name == $op) | .version' \"olm-$env.json\")\n            VERSIONS=\"$VERSIONS $VERSION\"\n        done\n\n        # Check if all versions are the same\n        UNIQUE_VERSIONS=$(echo \"$VERSIONS\" | tr ' ' '\\n' | sort -u | wc -l)\n        if [ $UNIQUE_VERSIONS -gt 1 ]; then\n            echo \"#### $operator\" &gt;&gt; $REPORT_FILE\n            for env in \"${ENVIRONMENTS[@]}\"; do\n                VERSION=$(jq -r --arg op \"$operator\" '.csvs[] | select(.name == $op) | .version' \"olm-$env.json\")\n                echo \"- $env: $VERSION\" &gt;&gt; $REPORT_FILE\n            done\n            echo \"\" &gt;&gt; $REPORT_FILE\n        fi\n    fi\ndone &lt;&lt;&lt; \"$ALL_OPERATORS\"\n\n# Cleanup temp files\nfor env in \"${ENVIRONMENTS[@]}\"; do\n    rm \"olm-$env.json\"\ndone\n\necho \"Multi-environment comparison complete: $REPORT_FILE\"\nEOF\n\nchmod +x olm-multi-env-compare.sh\n</code></pre>"},{"location":"examples/olm-workflows/#troubleshooting-and-diagnostics","title":"Troubleshooting and Diagnostics","text":""},{"location":"examples/olm-workflows/#olm-troubleshooting-toolkit","title":"OLM Troubleshooting Toolkit","text":"<pre><code># Create comprehensive OLM troubleshooting script\ncat &gt; olm-troubleshoot.sh &lt;&lt; 'EOF'\n#!/bin/bash\n# OLM Troubleshooting Toolkit\n\nISSUE_TYPE=${1:-\"general\"}\nOPERATOR_NAME=${2:-\"\"}\nNAMESPACE=${3:-\"operators\"}\n\nREPORT_FILE=\"olm-troubleshoot-$(date +%Y-%m-%d-%H-%M).log\"\n\necho \"=== OLM Troubleshooting Report - $(date) ===\" | tee $REPORT_FILE\necho \"Issue Type: $ISSUE_TYPE\" | tee -a $REPORT_FILE\necho \"Operator: ${OPERATOR_NAME:-\"All\"}\" | tee -a $REPORT_FILE\necho \"Namespace: $NAMESPACE\" | tee -a $REPORT_FILE\necho \"\" | tee -a $REPORT_FILE\n\ncase $ISSUE_TYPE in\n    \"stuck-install\")\n        echo \"## Diagnosing Stuck Installation\" | tee -a $REPORT_FILE\n\n        # Check installing CSVs\n        echo \"### CSVs in Installing State\" | tee -a $REPORT_FILE\n        k8s-datamodel olm list --phase Installing | tee -a $REPORT_FILE\n\n        # Check for resource conflicts\n        echo \"### Checking for Resource Conflicts\" | tee -a $REPORT_FILE\n        if [ -n \"$OPERATOR_NAME\" ]; then\n            CSV_INFO=$(k8s-datamodel olm get \"$OPERATOR_NAME\" --namespace \"$NAMESPACE\" --output json 2&gt;/dev/null)\n            if [ $? -eq 0 ]; then\n                echo \"Owned CRDs:\" | tee -a $REPORT_FILE\n                echo \"$CSV_INFO\" | jq -r '.owned_crds[]? // \"None\"' | sed 's/^/  /' | tee -a $REPORT_FILE\n\n                echo \"Required CRDs:\" | tee -a $REPORT_FILE  \n                echo \"$CSV_INFO\" | jq -r '.required_crds[]? // \"None\"' | sed 's/^/  /' | tee -a $REPORT_FILE\n            fi\n        fi\n        ;;\n\n    \"failed-csv\")\n        echo \"## Diagnosing Failed CSV\" | tee -a $REPORT_FILE\n\n        # List all failed CSVs\n        echo \"### Failed CSVs\" | tee -a $REPORT_FILE\n        k8s-datamodel olm list --phase Failed | tee -a $REPORT_FILE\n\n        if [ -n \"$OPERATOR_NAME\" ]; then\n            echo \"### Specific CSV Analysis: $OPERATOR_NAME\" | tee -a $REPORT_FILE\n            CSV_DETAILS=$(k8s-datamodel olm get \"$OPERATOR_NAME\" --namespace \"$NAMESPACE\" --output json 2&gt;/dev/null)\n            if [ $? -eq 0 ]; then\n                echo \"Display Name: $(echo \"$CSV_DETAILS\" | jq -r '.display_name')\" | tee -a $REPORT_FILE\n                echo \"Version: $(echo \"$CSV_DETAILS\" | jq -r '.version')\" | tee -a $REPORT_FILE\n                echo \"Provider: $(echo \"$CSV_DETAILS\" | jq -r '.provider')\" | tee -a $REPORT_FILE\n                echo \"Install Strategy: $(echo \"$CSV_DETAILS\" | jq -r '.install_strategy')\" | tee -a $REPORT_FILE\n            fi\n        fi\n        ;;\n\n    \"permission-issues\")\n        echo \"## Diagnosing Permission Issues\" | tee -a $REPORT_FILE\n\n        # Store current state for RBAC analysis\n        k8s-datamodel database store --notes \"Permission troubleshooting - $(date)\"\n        SNAPSHOT_ID=$(k8s-datamodel database list --limit 1 --output json | jq -r '.[0].id')\n        k8s-datamodel database export $SNAPSHOT_ID --file troubleshoot-rbac.json\n\n        if [ -n \"$OPERATOR_NAME\" ]; then\n            echo \"### RBAC Analysis for $OPERATOR_NAME\" | tee -a $REPORT_FILE\n\n            # Find CSV for the operator\n            CSV_RBAC=$(jq --arg name \"$OPERATOR_NAME\" '.csvs[] | select(.name == $name or .display_name == $name)' troubleshoot-rbac.json)\n\n            if [ \"$CSV_RBAC\" != \"null\" ] &amp;&amp; [ -n \"$CSV_RBAC\" ]; then\n                echo \"Cluster Permissions:\" | tee -a $REPORT_FILE\n                echo \"$CSV_RBAC\" | jq -r '.spec.spec.install.spec.clusterPermissions[]?.rules[]? | \n                    \"  - Resources: \\(.resources | join(\", \")) | Verbs: \\(.verbs | join(\", \"))\"' | tee -a $REPORT_FILE\n\n                echo \"Namespace Permissions:\" | tee -a $REPORT_FILE  \n                echo \"$CSV_RBAC\" | jq -r '.spec.spec.install.spec.permissions[]?.rules[]? | \n                    \"  - Resources: \\(.resources | join(\", \")) | Verbs: \\(.verbs | join(\", \"))\"' | tee -a $REPORT_FILE\n            else\n                echo \"CSV not found for operator: $OPERATOR_NAME\" | tee -a $REPORT_FILE\n            fi\n        fi\n\n        rm troubleshoot-rbac.json\n        ;;\n\n    \"general\"|*)\n        echo \"## General OLM Health Check\" | tee -a $REPORT_FILE\n\n        # Overall OLM statistics\n        echo \"### OLM Statistics\" | tee -a $REPORT_FILE\n        k8s-datamodel olm stats | tee -a $REPORT_FILE\n\n        # Check for problematic CSVs\n        echo \"### Problematic CSVs\" | tee -a $REPORT_FILE\n        echo \"Failed CSVs:\" | tee -a $REPORT_FILE\n        k8s-datamodel olm list --phase Failed --output table | tee -a $REPORT_FILE\n\n        echo \"Installing CSVs (potential stuck installations):\" | tee -a $REPORT_FILE\n        k8s-datamodel olm list --phase Installing --output table | tee -a $REPORT_FILE\n        ;;\nesac\n\necho \"\" | tee -a $REPORT_FILE\necho \"## Recommendations\" | tee -a $REPORT_FILE\n\ncase $ISSUE_TYPE in\n    \"stuck-install\")\n        echo \"1. Check if required CRDs are available in the cluster\" | tee -a $REPORT_FILE\n        echo \"2. Verify sufficient RBAC permissions\" | tee -a $REPORT_FILE\n        echo \"3. Check for resource conflicts with existing operators\" | tee -a $REPORT_FILE\n        echo \"4. Review OLM operator logs for detailed error messages\" | tee -a $REPORT_FILE\n        ;;\n    \"failed-csv\") \n        echo \"1. Review CSV conditions for specific error messages\" | tee -a $REPORT_FILE\n        echo \"2. Check if all required CRDs are satisfied\" | tee -a $REPORT_FILE\n        echo \"3. Verify CSV syntax and format\" | tee -a $REPORT_FILE\n        echo \"4. Check for conflicting CSV versions\" | tee -a $REPORT_FILE\n        ;;\n    \"permission-issues\")\n        echo \"1. Verify ServiceAccount has necessary ClusterRole bindings\" | tee -a $REPORT_FILE\n        echo \"2. Check for missing permissions in CSV RBAC definition\" | tee -a $REPORT_FILE  \n        echo \"3. Review namespace-level permissions\" | tee -a $REPORT_FILE\n        echo \"4. Consider if operator requires cluster-admin privileges\" | tee -a $REPORT_FILE\n        ;;\n    *)\n        echo \"1. Monitor CSV phases for state changes\" | tee -a $REPORT_FILE\n        echo \"2. Regular health checks with 'k8s-datamodel olm stats'\" | tee -a $REPORT_FILE\n        echo \"3. Keep snapshots for historical analysis\" | tee -a $REPORT_FILE\n        echo \"4. Implement automated monitoring for failed CSVs\" | tee -a $REPORT_FILE\n        ;;\nesac\n\necho \"Troubleshooting report saved to: $REPORT_FILE\"\nEOF\n\nchmod +x olm-troubleshoot.sh\n\n# Usage examples:\n# ./olm-troubleshoot.sh general\n# ./olm-troubleshoot.sh stuck-install cert-manager.v1.12.0 cert-manager  \n# ./olm-troubleshoot.sh failed-csv my-operator.v1.0.0 operators\n# ./olm-troubleshoot.sh permission-issues cloudnative-pg.v1.27.0 operators\n</code></pre>"},{"location":"examples/olm-workflows/#integration-with-monitoring","title":"Integration with Monitoring","text":""},{"location":"examples/olm-workflows/#prometheus-metrics-for-olm","title":"Prometheus Metrics for OLM","text":"<pre><code># Create OLM metrics exporter for Prometheus\ncat &gt; olm-metrics-exporter.sh &lt;&lt; 'EOF'\n#!/bin/bash\n# OLM Metrics Exporter for Prometheus\n\nMETRICS_FILE=\"/var/lib/node_exporter/olm_metrics.prom\"\n\n# Store current OLM state\nk8s-datamodel database store --notes \"Metrics collection - $(date)\"\nSNAPSHOT_ID=$(k8s-datamodel database list --limit 1 --output json | jq -r '.[0].id')\nk8s-datamodel database export $SNAPSHOT_ID --file metrics-olm.json\n\n# Generate Prometheus metrics\ncat &gt; $METRICS_FILE &lt;&lt; METRICS\n# HELP olm_csvs_total Total number of ClusterServiceVersions\n# TYPE olm_csvs_total gauge\nolm_csvs_total $(jq '.csvs | length' metrics-olm.json)\n\n# HELP olm_csvs_succeeded Number of succeeded CSVs\n# TYPE olm_csvs_succeeded gauge  \nolm_csvs_succeeded $(jq '[.csvs[] | select(.phase == \"Succeeded\")] | length' metrics-olm.json)\n\n# HELP olm_csvs_failed Number of failed CSVs\n# TYPE olm_csvs_failed gauge\nolm_csvs_failed $(jq '[.csvs[] | select(.phase == \"Failed\")] | length' metrics-olm.json)\n\n# HELP olm_csvs_installing Number of installing CSVs\n# TYPE olm_csvs_installing gauge\nolm_csvs_installing $(jq '[.csvs[] | select(.phase == \"Installing\")] | length' metrics-olm.json)\n\n# HELP olm_owned_crds_total Total number of CRDs owned by OLM operators\n# TYPE olm_owned_crds_total gauge\nolm_owned_crds_total $(jq '[.csvs[].owned_crds | length] | add' metrics-olm.json)\n\n# HELP olm_required_crds_total Total number of CRDs required by OLM operators  \n# TYPE olm_required_crds_total gauge\nolm_required_crds_total $(jq '[.csvs[].required_crds | length] | add' metrics-olm.json)\n\n# HELP olm_cluster_permissions_total Total cluster permissions across all CSVs\n# TYPE olm_cluster_permissions_total gauge\nolm_cluster_permissions_total $(jq '[.csvs[] | .spec.spec.install.spec.clusterPermissions | length] | add' metrics-olm.json)\n\n# HELP olm_namespace_permissions_total Total namespace permissions across all CSVs\n# TYPE olm_namespace_permissions_total gauge  \nolm_namespace_permissions_total $(jq '[.csvs[] | .spec.spec.install.spec.permissions | length] | add' metrics-olm.json)\n\n# HELP olm_high_risk_csvs Number of CSVs with wildcard permissions\n# TYPE olm_high_risk_csvs gauge\nolm_high_risk_csvs $(jq '[.csvs[] | select(.spec.spec.install.spec.clusterPermissions[]?.rules[]?.resources[]? == \"*\" or .spec.spec.install.spec.clusterPermissions[]?.rules[]?.verbs[]? == \"*\")] | length' metrics-olm.json)\n\nMETRICS\n\necho \"OLM metrics exported to $METRICS_FILE\"\nrm metrics-olm.json\nEOF\n\nchmod +x olm-metrics-exporter.sh\n</code></pre>"},{"location":"examples/olm-workflows/#alerting-rules-for-olm","title":"Alerting Rules for OLM","text":"<pre><code># Create Prometheus alerting rules for OLM\ncat &gt; olm-alerting-rules.yml &lt;&lt; 'EOF'\ngroups:\n- name: olm.rules\n  rules:\n  - alert: OLMCSVFailed\n    expr: olm_csvs_failed &gt; 0\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"OLM ClusterServiceVersion(s) failed\"\n      description: \"{{ $value }} ClusterServiceVersion(s) are in Failed state\"\n\n  - alert: OLMCSVStuckInstalling  \n    expr: olm_csvs_installing &gt; 0\n    for: 30m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"OLM ClusterServiceVersion(s) stuck installing\"\n      description: \"{{ $value }} ClusterServiceVersion(s) have been installing for &gt;30 minutes\"\n\n  - alert: OLMHighRiskPermissions\n    expr: olm_high_risk_csvs &gt; 0\n    for: 0m\n    labels:\n      severity: critical\n    annotations:\n      summary: \"OLM operators with high-risk permissions detected\"\n      description: \"{{ $value }} ClusterServiceVersion(s) have wildcard (*) permissions\"\n\n  - alert: OLMCSVCountChanged\n    expr: abs(delta(olm_csvs_total[1h])) &gt; 0\n    for: 0m  \n    labels:\n      severity: info\n    annotations:\n      summary: \"OLM ClusterServiceVersion count changed\"\n      description: \"Number of CSVs changed by {{ $value }} in the last hour\"\nEOF\n</code></pre> <p>This comprehensive collection of OLM examples provides:</p> <ol> <li>Basic Operations: Discovery, analysis, and health monitoring</li> <li>Advanced Analysis: RBAC security, resource requirements, and CRD ownership  </li> <li>Lifecycle Management: Upgrade planning, verification, and version tracking</li> <li>Security: Permission analysis and security context evaluation</li> <li>Multi-Environment: Cross-environment comparison and consistency checking</li> <li>Troubleshooting: Diagnostic tools for common OLM issues</li> <li>Monitoring: Prometheus metrics and alerting integration</li> </ol> <p>These examples enable comprehensive OLM management with the k8s-datamodel tool, supporting enterprise-grade operator lifecycle management workflows.</p>"},{"location":"examples/security-compliance/","title":"Security and Compliance Analysis Examples","text":"<p>This document provides comprehensive examples for security analysis and compliance reporting using k8s-datamodel's database functionality and spec analysis capabilities.</p>"},{"location":"examples/security-compliance/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Security Baseline Establishment</li> <li>RBAC Analysis and Auditing</li> <li>Security Context Analysis</li> <li>Compliance Reporting</li> <li>Vulnerability Assessment</li> <li>Policy Enforcement Monitoring</li> <li>Security Drift Detection</li> <li>Automated Security Monitoring</li> </ol>"},{"location":"examples/security-compliance/#security-baseline-establishment","title":"Security Baseline Establishment","text":""},{"location":"examples/security-compliance/#creating-security-baseline","title":"Creating Security Baseline","text":"<pre><code># Establish comprehensive security baseline\nk8s-datamodel database store \\\n    --notes \"SECURITY-BASELINE-$(date +%Y-%m-%d) - Initial security assessment and baseline\"\n\n# Export baseline for detailed analysis\nBASELINE_ID=$(k8s-datamodel database list --limit 1 --output json | jq -r '.[0].id')\nk8s-datamodel database export $BASELINE_ID --file security-baseline.json\n\necho \"Security baseline established with snapshot ID: $BASELINE_ID\"\necho $BASELINE_ID &gt; .security-baseline-id\n\n# Generate baseline security report\ncat &gt; security-baseline-report.md &lt;&lt; 'EOF'\n# Security Baseline Report\n\n**Generated:** $(date)\n**Baseline Snapshot ID:** $BASELINE_ID\n\n## Executive Summary\n\nThis document establishes the security baseline for the Kubernetes cluster, documenting the current security posture of all operators, CRDs, and OLM-managed components.\n\n## Methodology\n\nThe security baseline was established using k8s-datamodel to:\n1. Capture complete cluster specifications including security contexts\n2. Analyze RBAC permissions for all operators and CSVs\n3. Document privileged containers and high-risk configurations\n4. Establish metrics for ongoing security monitoring\n\n## Baseline Metrics\nEOF\n\n# Add baseline metrics to report\necho \"- **Total CRDs:** $(jq '.crds | length' security-baseline.json)\" &gt;&gt; security-baseline-report.md\necho \"- **Total Operators:** $(jq '.operators | length' security-baseline.json)\" &gt;&gt; security-baseline-report.md\necho \"- **Total OLM CSVs:** $(jq '.csvs | length' security-baseline.json)\" &gt;&gt; security-baseline-report.md\necho \"- **Privileged Containers:** $(jq '[.operators[] | select(.spec.spec.template.spec.containers[0].securityContext.privileged == true)] | length' security-baseline.json)\" &gt;&gt; security-baseline-report.md\necho \"- **Containers without Limits:** $(jq '[.operators[] | select(.spec.spec.template.spec.containers[0].resources.limits == null)] | length' security-baseline.json)\" &gt;&gt; security-baseline-report.md\necho \"- **Host Network Access:** $(jq '[.operators[] | select(.spec.spec.template.spec.hostNetwork == true)] | length' security-baseline.json)\" &gt;&gt; security-baseline-report.md\n\necho \"Baseline security report generated: security-baseline-report.md\"\n</code></pre>"},{"location":"examples/security-compliance/#security-baseline-validation","title":"Security Baseline Validation","text":"<pre><code># Create security baseline validation script\ncat &gt; validate-security-baseline.sh &lt;&lt; 'EOF'\n#!/bin/bash\n# Security Baseline Validation Script\n\nBASELINE_ID=${1:-$(cat .security-baseline-id 2&gt;/dev/null)}\nif [ -z \"$BASELINE_ID\" ]; then\n    echo \"Error: Baseline snapshot ID required\"\n    echo \"Usage: $0 &lt;baseline_snapshot_id&gt;\"\n    exit 1\nfi\n\nVALIDATION_REPORT=\"security-baseline-validation-$(date +%Y-%m-%d).md\"\n\necho \"# Security Baseline Validation - $(date)\" &gt; $VALIDATION_REPORT\necho \"\" &gt;&gt; $VALIDATION_REPORT\n\n# Export baseline for comparison\nk8s-datamodel database export $BASELINE_ID --file baseline-validation.json\n\n# Current snapshot for comparison\nk8s-datamodel database store --notes \"Security validation against baseline - $(date +%Y-%m-%d)\"\nCURRENT_ID=$(k8s-datamodel database list --limit 1 --output json | jq -r '.[0].id')\nk8s-datamodel database export $CURRENT_ID --file current-validation.json\n\necho \"## Validation Summary\" &gt;&gt; $VALIDATION_REPORT\necho \"- **Baseline Snapshot:** $BASELINE_ID\" &gt;&gt; $VALIDATION_REPORT\necho \"- **Current Snapshot:** $CURRENT_ID\" &gt;&gt; $VALIDATION_REPORT\necho \"- **Validation Date:** $(date)\" &gt;&gt; $VALIDATION_REPORT\necho \"\" &gt;&gt; $VALIDATION_REPORT\n\n# Compare security metrics\necho \"## Security Metrics Comparison\" &gt;&gt; $VALIDATION_REPORT\n\nBASELINE_PRIVILEGED=$(jq '[.operators[] | select(.spec.spec.template.spec.containers[0].securityContext.privileged == true)] | length' baseline-validation.json)\nCURRENT_PRIVILEGED=$(jq '[.operators[] | select(.spec.spec.template.spec.containers[0].securityContext.privileged == true)] | length' current-validation.json)\n\nBASELINE_NO_LIMITS=$(jq '[.operators[] | select(.spec.spec.template.spec.containers[0].resources.limits == null)] | length' baseline-validation.json)\nCURRENT_NO_LIMITS=$(jq '[.operators[] | select(.spec.spec.template.spec.containers[0].resources.limits == null)] | length' current-validation.json)\n\nBASELINE_HOST_NET=$(jq '[.operators[] | select(.spec.spec.template.spec.hostNetwork == true)] | length' baseline-validation.json)\nCURRENT_HOST_NET=$(jq '[.operators[] | select(.spec.spec.template.spec.hostNetwork == true)] | length' current-validation.json)\n\necho \"| Metric | Baseline | Current | Change | Status |\" &gt;&gt; $VALIDATION_REPORT\necho \"|--------|----------|---------|--------|--------|\" &gt;&gt; $VALIDATION_REPORT\necho \"| Privileged Containers | $BASELINE_PRIVILEGED | $CURRENT_PRIVILEGED | $(($CURRENT_PRIVILEGED - $BASELINE_PRIVILEGED)) | $( [ $CURRENT_PRIVILEGED -le $BASELINE_PRIVILEGED ] &amp;&amp; echo \"\u2705 OK\" || echo \"\u26a0\ufe0f INCREASED\" ) |\" &gt;&gt; $VALIDATION_REPORT\necho \"| Containers w/o Limits | $BASELINE_NO_LIMITS | $CURRENT_NO_LIMITS | $(($CURRENT_NO_LIMITS - $BASELINE_NO_LIMITS)) | $( [ $CURRENT_NO_LIMITS -le $BASELINE_NO_LIMITS ] &amp;&amp; echo \"\u2705 OK\" || echo \"\u26a0\ufe0f INCREASED\" ) |\" &gt;&gt; $VALIDATION_REPORT  \necho \"| Host Network Access | $BASELINE_HOST_NET | $CURRENT_HOST_NET | $(($CURRENT_HOST_NET - $BASELINE_HOST_NET)) | $( [ $CURRENT_HOST_NET -le $BASELINE_HOST_NET ] &amp;&amp; echo \"\u2705 OK\" || echo \"\u26a0\ufe0f INCREASED\" ) |\" &gt;&gt; $VALIDATION_REPORT\n\necho \"\" &gt;&gt; $VALIDATION_REPORT\necho \"## Security Violations\" &gt;&gt; $VALIDATION_REPORT\n\n# Find new security violations\necho \"### New Privileged Containers\" &gt;&gt; $VALIDATION_REPORT\ncomm -13 &lt;(jq -r '.operators[] | select(.spec.spec.template.spec.containers[0].securityContext.privileged == true) | .name' baseline-validation.json | sort) \\\n         &lt;(jq -r '.operators[] | select(.spec.spec.template.spec.containers[0].securityContext.privileged == true) | .name' current-validation.json | sort) | \\\nwhile read container; do echo \"- \u26a0\ufe0f $container\"; done &gt;&gt; $VALIDATION_REPORT\n\necho \"\" &gt;&gt; $VALIDATION_REPORT\necho \"### New Containers without Resource Limits\" &gt;&gt; $VALIDATION_REPORT  \ncomm -13 &lt;(jq -r '.operators[] | select(.spec.spec.template.spec.containers[0].resources.limits == null) | .name' baseline-validation.json | sort) \\\n         &lt;(jq -r '.operators[] | select(.spec.spec.template.spec.containers[0].resources.limits == null) | .name' current-validation.json | sort) | \\\nwhile read container; do echo \"- \u26a0\ufe0f $container\"; done &gt;&gt; $VALIDATION_REPORT\n\necho \"\" &gt;&gt; $VALIDATION_REPORT\necho \"## Recommendations\" &gt;&gt; $VALIDATION_REPORT\n\n# Generate recommendations based on findings\nTOTAL_VIOLATIONS=$(($CURRENT_PRIVILEGED + $CURRENT_NO_LIMITS + $CURRENT_HOST_NET))\nif [ $TOTAL_VIOLATIONS -eq 0 ]; then\n    echo \"\u2705 **Excellent security posture** - No major security violations detected\" &gt;&gt; $VALIDATION_REPORT\nelif [ $TOTAL_VIOLATIONS -lt 5 ]; then\n    echo \"\u26a0\ufe0f **Good security posture** - Minor violations detected that should be addressed\" &gt;&gt; $VALIDATION_REPORT\nelse\n    echo \"\ud83d\udea8 **Security attention required** - Multiple violations detected requiring immediate attention\" &gt;&gt; $VALIDATION_REPORT\nfi\n\necho \"\" &gt;&gt; $VALIDATION_REPORT\necho \"1. Review and remediate any new privileged containers\" &gt;&gt; $VALIDATION_REPORT\necho \"2. Implement resource limits for all containers without limits\" &gt;&gt; $VALIDATION_REPORT\necho \"3. Evaluate necessity of host network access\" &gt;&gt; $VALIDATION_REPORT\necho \"4. Schedule regular security baseline validations\" &gt;&gt; $VALIDATION_REPORT\n\nrm baseline-validation.json current-validation.json\necho \"Security baseline validation complete: $VALIDATION_REPORT\"\nEOF\n\nchmod +x validate-security-baseline.sh\n</code></pre>"},{"location":"examples/security-compliance/#rbac-analysis-and-auditing","title":"RBAC Analysis and Auditing","text":""},{"location":"examples/security-compliance/#comprehensive-rbac-audit","title":"Comprehensive RBAC Audit","text":"<pre><code># Create comprehensive RBAC audit script\ncat &gt; rbac-security-audit.sh &lt;&lt; 'EOF'\n#!/bin/bash\n# Comprehensive RBAC Security Audit Script\n\nAUDIT_REPORT=\"rbac-security-audit-$(date +%Y-%m-%d).md\"\n\necho \"# RBAC Security Audit Report - $(date)\" &gt; $AUDIT_REPORT\necho \"\" &gt;&gt; $AUDIT_REPORT\n\n# Store current state for analysis\nk8s-datamodel database store --notes \"RBAC Security Audit - $(date +%Y-%m-%d)\"\nSNAPSHOT_ID=$(k8s-datamodel database list --limit 1 --output json | jq -r '.[0].id')\nk8s-datamodel database export $SNAPSHOT_ID --file rbac-audit.json\n\necho \"## Executive Summary\" &gt;&gt; $AUDIT_REPORT\necho \"\" &gt;&gt; $AUDIT_REPORT\n\nTOTAL_CSVS=$(jq '.csvs | length' rbac-audit.json)\nCSVS_WITH_CLUSTER_PERMS=$(jq '[.csvs[] | select(.spec.spec.install.spec.clusterPermissions | length &gt; 0)] | length' rbac-audit.json)\nCSVS_WITH_WILDCARD=$(jq '[.csvs[] | select(.spec.spec.install.spec.clusterPermissions[]?.rules[]?.resources[]? == \"*\" or .spec.spec.install.spec.clusterPermissions[]?.rules[]?.verbs[]? == \"*\")] | length' rbac-audit.json)\n\necho \"- **Total ClusterServiceVersions:** $TOTAL_CSVS\" &gt;&gt; $AUDIT_REPORT\necho \"- **CSVs with Cluster Permissions:** $CSVS_WITH_CLUSTER_PERMS\" &gt;&gt; $AUDIT_REPORT  \necho \"- **CSVs with Wildcard Permissions:** $CSVS_WITH_WILDCARD\" &gt;&gt; $AUDIT_REPORT\necho \"- **Risk Level:** $( [ $CSVS_WITH_WILDCARD -eq 0 ] &amp;&amp; echo \"LOW\" || [ $CSVS_WITH_WILDCARD -lt 3 ] &amp;&amp; echo \"MEDIUM\" || echo \"HIGH\" )\" &gt;&gt; $AUDIT_REPORT\n\necho \"\" &gt;&gt; $AUDIT_REPORT\necho \"## Critical Security Findings\" &gt;&gt; $AUDIT_REPORT\n\n# Find dangerous permissions\necho \"### \ud83d\udea8 CRITICAL: Wildcard Resource Access\" &gt;&gt; $AUDIT_REPORT\njq -r '.csvs[] | select(.spec.spec.install.spec.clusterPermissions[]?.rules[]?.resources[]? == \"*\") | \n       \"- **\\(.display_name)** (\\(.name)): Full resource access (*)\"' rbac-audit.json &gt;&gt; $AUDIT_REPORT\n\necho \"\" &gt;&gt; $AUDIT_REPORT\necho \"### \ud83d\udea8 CRITICAL: Wildcard Verb Access\" &gt;&gt; $AUDIT_REPORT\njq -r '.csvs[] | select(.spec.spec.install.spec.clusterPermissions[]?.rules[]?.verbs[]? == \"*\") | \n       \"- **\\(.display_name)** (\\(.name)): Full verb access (*)\"' rbac-audit.json &gt;&gt; $AUDIT_REPORT\n\necho \"\" &gt;&gt; $AUDIT_REPORT\necho \"### \u26a0\ufe0f HIGH RISK: Sensitive Resource Access\" &gt;&gt; $AUDIT_REPORT\n\n# Check access to sensitive resources\nSENSITIVE_RESOURCES=(\"secrets\" \"nodes\" \"clusterroles\" \"clusterrolebindings\" \"persistentvolumes\" \"serviceaccounts\")\n\nfor resource in \"${SENSITIVE_RESOURCES[@]}\"; do\n    echo \"#### Access to $resource\" &gt;&gt; $AUDIT_REPORT\n    jq -r --arg res \"$resource\" '.csvs[] | \n           select(.spec.spec.install.spec.clusterPermissions[]?.rules[]?.resources[]? == $res) |\n           \"- **\\(.display_name)**: Can access \\($res)\"' rbac-audit.json &gt;&gt; $AUDIT_REPORT\ndone\n\necho \"\" &gt;&gt; $AUDIT_REPORT\necho \"### \u26a0\ufe0f HIGH RISK: Privileged Verbs\" &gt;&gt; $AUDIT_REPORT\n\nPRIVILEGED_VERBS=(\"create\" \"delete\" \"patch\" \"update\")\nfor verb in \"${PRIVILEGED_VERBS[@]}\"; do\n    echo \"#### $verb Permissions on Critical Resources\" &gt;&gt; $AUDIT_REPORT\n    jq -r --arg verb \"$verb\" '.csvs[] | \n           select(.spec.spec.install.spec.clusterPermissions[]?.rules[]? | \n                  (.verbs | contains([$verb])) and \n                  (.resources | contains([\"clusterroles\", \"clusterrolebindings\", \"nodes\", \"secrets\"]))) |\n           \"- **\\(.display_name)**: Can \\($verb) sensitive resources\"' rbac-audit.json &gt;&gt; $AUDIT_REPORT\ndone\n\necho \"\" &gt;&gt; $AUDIT_REPORT\necho \"## Detailed Permission Analysis\" &gt;&gt; $AUDIT_REPORT\n\n# Create detailed permission matrix\necho \"### Permission Matrix\" &gt;&gt; $AUDIT_REPORT\necho \"| Operator | Cluster Perms | NS Perms | Dangerous Resources | Wildcard | Risk Level |\" &gt;&gt; $AUDIT_REPORT\necho \"|----------|---------------|----------|-------------------|----------|------------|\" &gt;&gt; $AUDIT_REPORT\n\njq -r '.csvs[] | \n       {\n           name: .display_name,\n           cluster_perms: (.spec.spec.install.spec.clusterPermissions | length),\n           ns_perms: (.spec.spec.install.spec.permissions | length),\n           has_wildcard: ((.spec.spec.install.spec.clusterPermissions[]?.rules[]?.resources[]? == \"*\") or \n                         (.spec.spec.install.spec.clusterPermissions[]?.rules[]?.verbs[]? == \"*\")),\n           has_sensitive: ((.spec.spec.install.spec.clusterPermissions[]?.rules[]?.resources[]? | \n                          . as $r | [\"secrets\", \"nodes\", \"clusterroles\"] | any(. == $r)) // false)\n       } |\n       \"| \\(.name) | \\(.cluster_perms) | \\(.ns_perms) | \\(.has_sensitive) | \\(.has_wildcard) | \\(if .has_wildcard then \"\ud83d\udea8 CRITICAL\" elif .has_sensitive then \"\u26a0\ufe0f HIGH\" elif .cluster_perms &gt; 5 then \"\u26a0\ufe0f MEDIUM\" else \"\u2705 LOW\" end) |\"' \\\n       rbac-audit.json &gt;&gt; $AUDIT_REPORT\n\necho \"\" &gt;&gt; $AUDIT_REPORT\necho \"## Security Recommendations\" &gt;&gt; $AUDIT_REPORT\n\necho \"### Immediate Actions Required\" &gt;&gt; $AUDIT_REPORT\nif [ $CSVS_WITH_WILDCARD -gt 0 ]; then\n    echo \"1. **\ud83d\udea8 URGENT**: Review and remediate CSVs with wildcard permissions\" &gt;&gt; $AUDIT_REPORT\n    echo \"2. Implement least-privilege principle for all operators\" &gt;&gt; $AUDIT_REPORT\nelse\n    echo \"1. \u2705 No wildcard permissions detected - good security posture\" &gt;&gt; $AUDIT_REPORT\nfi\n\necho \"3. Regular RBAC audit schedule (monthly)\" &gt;&gt; $AUDIT_REPORT\necho \"4. Implement automated monitoring for permission changes\" &gt;&gt; $AUDIT_REPORT\necho \"5. Consider using admission controllers to prevent dangerous permissions\" &gt;&gt; $AUDIT_REPORT\n\necho \"\" &gt;&gt; $AUDIT_REPORT\necho \"### Best Practices\" &gt;&gt; $AUDIT_REPORT\necho \"- Use namespace-scoped permissions when possible\" &gt;&gt; $AUDIT_REPORT\necho \"- Implement specific resource and verb permissions\" &gt;&gt; $AUDIT_REPORT\necho \"- Regular review of operator permissions\" &gt;&gt; $AUDIT_REPORT\necho \"- Use Pod Security Standards for additional protection\" &gt;&gt; $AUDIT_REPORT\n\nrm rbac-audit.json\necho \"RBAC security audit complete: $AUDIT_REPORT\"\nEOF\n\nchmod +x rbac-security-audit.sh\n</code></pre>"},{"location":"examples/security-compliance/#rbac-change-detection","title":"RBAC Change Detection","text":"<pre><code># Create RBAC change detection script\ncat &gt; rbac-change-detector.sh &lt;&lt; 'EOF'\n#!/bin/bash\n# RBAC Change Detection Script\n\nBASELINE_ID=${1:-$(cat .security-baseline-id 2&gt;/dev/null)}\nif [ -z \"$BASELINE_ID\" ]; then\n    echo \"Error: Baseline snapshot ID required\"\n    echo \"Usage: $0 &lt;baseline_snapshot_id&gt;\"\n    exit 1\nfi\n\nCHANGE_REPORT=\"rbac-changes-$(date +%Y-%m-%d).md\"\n\necho \"# RBAC Change Detection Report - $(date)\" &gt; $CHANGE_REPORT\necho \"\" &gt;&gt; $CHANGE_REPORT\n\n# Get current state\nk8s-datamodel database store --notes \"RBAC change detection - $(date +%Y-%m-%d)\"\nCURRENT_ID=$(k8s-datamodel database list --limit 1 --output json | jq -r '.[0].id')\n\n# Export snapshots\nk8s-datamodel database export $BASELINE_ID --file rbac-baseline.json\nk8s-datamodel database export $CURRENT_ID --file rbac-current.json\n\necho \"## Change Summary\" &gt;&gt; $CHANGE_REPORT\necho \"- **Baseline Snapshot:** $BASELINE_ID\" &gt;&gt; $CHANGE_REPORT\necho \"- **Current Snapshot:** $CURRENT_ID\" &gt;&gt; $CHANGE_REPORT\necho \"- **Analysis Date:** $(date)\" &gt;&gt; $CHANGE_REPORT\necho \"\" &gt;&gt; $CHANGE_REPORT\n\n# Analyze permission changes\necho \"## Permission Changes Detected\" &gt;&gt; $CHANGE_REPORT\n\n# Check for new CSVs with dangerous permissions\necho \"### New High-Risk CSVs\" &gt;&gt; $CHANGE_REPORT\nBASELINE_DANGEROUS=$(jq -r '.csvs[] | select(.spec.spec.install.spec.clusterPermissions[]?.rules[]?.resources[]? == \"*\") | .name' rbac-baseline.json | sort)\nCURRENT_DANGEROUS=$(jq -r '.csvs[] | select(.spec.spec.install.spec.clusterPermissions[]?.rules[]?.resources[]? == \"*\") | .name' rbac-current.json | sort)\n\nNEW_DANGEROUS=$(comm -13 &lt;(echo \"$BASELINE_DANGEROUS\") &lt;(echo \"$CURRENT_DANGEROUS\"))\nif [ -n \"$NEW_DANGEROUS\" ]; then\n    echo \"\ud83d\udea8 **CRITICAL ALERT**: New CSVs with wildcard permissions detected!\" &gt;&gt; $CHANGE_REPORT\n    while read csv; do\n        echo \"- $csv\" &gt;&gt; $CHANGE_REPORT\n    done &lt;&lt;&lt; \"$NEW_DANGEROUS\"\nelse\n    echo \"\u2705 No new high-risk CSVs detected\" &gt;&gt; $CHANGE_REPORT\nfi\n\necho \"\" &gt;&gt; $CHANGE_REPORT\necho \"### Permission Escalations\" &gt;&gt; $CHANGE_REPORT\n\n# Check for CSVs that gained cluster permissions\nBASELINE_CLUSTER_CSVS=$(jq -r '.csvs[] | select(.spec.spec.install.spec.clusterPermissions | length &gt; 0) | .name' rbac-baseline.json | sort)\nCURRENT_CLUSTER_CSVS=$(jq -r '.csvs[] | select(.spec.spec.install.spec.clusterPermissions | length &gt; 0) | .name' rbac-current.json | sort)\n\nNEW_CLUSTER_CSVS=$(comm -13 &lt;(echo \"$BASELINE_CLUSTER_CSVS\") &lt;(echo \"$CURRENT_CLUSTER_CSVS\"))\nif [ -n \"$NEW_CLUSTER_CSVS\" ]; then\n    echo \"\u26a0\ufe0f **New cluster permissions detected:**\" &gt;&gt; $CHANGE_REPORT\n    while read csv; do\n        echo \"- $csv gained cluster-level permissions\" &gt;&gt; $CHANGE_REPORT\n    done &lt;&lt;&lt; \"$NEW_CLUSTER_CSVS\"\nelse\n    echo \"\u2705 No new cluster permission escalations\" &gt;&gt; $CHANGE_REPORT\nfi\n\necho \"\" &gt;&gt; $CHANGE_REPORT\necho \"### Detailed Permission Analysis\" &gt;&gt; $CHANGE_REPORT\n\n# For each CSV, compare permission counts\necho \"| CSV | Baseline Cluster Perms | Current Cluster Perms | Change | Status |\" &gt;&gt; $CHANGE_REPORT\necho \"|-----|------------------------|----------------------|--------|--------|\" &gt;&gt; $CHANGE_REPORT\n\n# Get common CSVs between snapshots\nCOMMON_CSVS=$(comm -12 &lt;(jq -r '.csvs[].name' rbac-baseline.json | sort) &lt;(jq -r '.csvs[].name' rbac-current.json | sort))\n\nwhile read csv; do\n    if [ -n \"$csv\" ]; then\n        BASELINE_COUNT=$(jq -r --arg csv \"$csv\" '.csvs[] | select(.name == $csv) | .spec.spec.install.spec.clusterPermissions | length' rbac-baseline.json)\n        CURRENT_COUNT=$(jq -r --arg csv \"$csv\" '.csvs[] | select(.name == $csv) | .spec.spec.install.spec.clusterPermissions | length' rbac-current.json)\n        CHANGE=$(($CURRENT_COUNT - $BASELINE_COUNT))\n\n        if [ $CHANGE -gt 0 ]; then\n            STATUS=\"\u26a0\ufe0f INCREASED\"\n        elif [ $CHANGE -lt 0 ]; then\n            STATUS=\"\u2705 DECREASED\"\n        else\n            STATUS=\"\u2796 NO CHANGE\"\n        fi\n\n        echo \"| $csv | $BASELINE_COUNT | $CURRENT_COUNT | $CHANGE | $STATUS |\" &gt;&gt; $CHANGE_REPORT\n    fi\ndone &lt;&lt;&lt; \"$COMMON_CSVS\"\n\necho \"\" &gt;&gt; $CHANGE_REPORT\necho \"## Recommendations\" &gt;&gt; $CHANGE_REPORT\n\nif [ -n \"$NEW_DANGEROUS\" ] || [ -n \"$NEW_CLUSTER_CSVS\" ]; then\n    echo \"\ud83d\udea8 **Immediate action required:**\" &gt;&gt; $CHANGE_REPORT\n    echo \"1. Review all new high-risk permissions immediately\" &gt;&gt; $CHANGE_REPORT\n    echo \"2. Validate business justification for permission escalations\" &gt;&gt; $CHANGE_REPORT\n    echo \"3. Consider implementing admission controllers to prevent dangerous permissions\" &gt;&gt; $CHANGE_REPORT\nelse\n    echo \"\u2705 **No critical RBAC changes detected**\" &gt;&gt; $CHANGE_REPORT\n    echo \"1. Continue regular monitoring of RBAC changes\" &gt;&gt; $CHANGE_REPORT\n    echo \"2. Maintain security baseline updates\" &gt;&gt; $CHANGE_REPORT\nfi\n\necho \"4. Schedule regular RBAC audits\" &gt;&gt; $CHANGE_REPORT\necho \"5. Implement automated alerting for permission changes\" &gt;&gt; $CHANGE_REPORT\n\nrm rbac-baseline.json rbac-current.json\necho \"RBAC change detection complete: $CHANGE_REPORT\"\nEOF\n\nchmod +x rbac-change-detector.sh\n</code></pre>"},{"location":"examples/security-compliance/#security-context-analysis","title":"Security Context Analysis","text":""},{"location":"examples/security-compliance/#container-security-analysis","title":"Container Security Analysis","text":"<pre><code># Create comprehensive container security analysis\ncat &gt; container-security-analyzer.sh &lt;&lt; 'EOF'\n#!/bin/bash\n# Container Security Analysis Script\n\nSECURITY_REPORT=\"container-security-analysis-$(date +%Y-%m-%d).md\"\n\necho \"# Container Security Analysis Report - $(date)\" &gt; $SECURITY_REPORT\necho \"\" &gt;&gt; $SECURITY_REPORT\n\n# Store current state\nk8s-datamodel database store --notes \"Container security analysis - $(date +%Y-%m-%d)\"\nSNAPSHOT_ID=$(k8s-datamodel database list --limit 1 --output json | jq -r '.[0].id')\nk8s-datamodel database export $SNAPSHOT_ID --file container-security.json\n\necho \"## Security Posture Overview\" &gt;&gt; $SECURITY_REPORT\necho \"\" &gt;&gt; $SECURITY_REPORT\n\n# Calculate security metrics\nTOTAL_OPERATORS=$(jq '.operators | length' container-security.json)\nPRIVILEGED_CONTAINERS=$(jq '[.operators[] | select(.spec.spec.template.spec.containers[0].securityContext.privileged == true)] | length' container-security.json)\nROOT_CONTAINERS=$(jq '[.operators[] | select(.spec.spec.template.spec.containers[0].securityContext.runAsUser == 0)] | length' container-security.json)\nHOST_NETWORK_CONTAINERS=$(jq '[.operators[] | select(.spec.spec.template.spec.hostNetwork == true)] | length' container-security.json)\nNO_LIMITS_CONTAINERS=$(jq '[.operators[] | select(.spec.spec.template.spec.containers[0].resources.limits == null)] | length' container-security.json)\nHOST_PID_CONTAINERS=$(jq '[.operators[] | select(.spec.spec.template.spec.hostPID == true)] | length' container-security.json)\n\necho \"| Security Metric | Count | Percentage | Risk Level |\" &gt;&gt; $SECURITY_REPORT\necho \"|-----------------|-------|------------|------------|\" &gt;&gt; $SECURITY_REPORT\necho \"| Total Operators | $TOTAL_OPERATORS | 100% | - |\" &gt;&gt; $SECURITY_REPORT\necho \"| Privileged Containers | $PRIVILEGED_CONTAINERS | $(echo \"scale=1; $PRIVILEGED_CONTAINERS * 100 / $TOTAL_OPERATORS\" | bc)% | $( [ $PRIVILEGED_CONTAINERS -eq 0 ] &amp;&amp; echo \"\u2705 LOW\" || echo \"\ud83d\udea8 CRITICAL\" ) |\" &gt;&gt; $SECURITY_REPORT\necho \"| Running as Root | $ROOT_CONTAINERS | $(echo \"scale=1; $ROOT_CONTAINERS * 100 / $TOTAL_OPERATORS\" | bc)% | $( [ $ROOT_CONTAINERS -eq 0 ] &amp;&amp; echo \"\u2705 LOW\" || [ $ROOT_CONTAINERS -lt 3 ] &amp;&amp; echo \"\u26a0\ufe0f MEDIUM\" || echo \"\ud83d\udea8 HIGH\" ) |\" &gt;&gt; $SECURITY_REPORT\necho \"| Host Network Access | $HOST_NETWORK_CONTAINERS | $(echo \"scale=1; $HOST_NETWORK_CONTAINERS * 100 / $TOTAL_OPERATORS\" | bc)% | $( [ $HOST_NETWORK_CONTAINERS -eq 0 ] &amp;&amp; echo \"\u2705 LOW\" || echo \"\u26a0\ufe0f MEDIUM\" ) |\" &gt;&gt; $SECURITY_REPORT\necho \"| No Resource Limits | $NO_LIMITS_CONTAINERS | $(echo \"scale=1; $NO_LIMITS_CONTAINERS * 100 / $TOTAL_OPERATORS\" | bc)% | $( [ $NO_LIMITS_CONTAINERS -eq 0 ] &amp;&amp; echo \"\u2705 LOW\" || [ $NO_LIMITS_CONTAINERS -lt 5 ] &amp;&amp; echo \"\u26a0\ufe0f MEDIUM\" || echo \"\ud83d\udea8 HIGH\" ) |\" &gt;&gt; $SECURITY_REPORT\necho \"| Host PID Access | $HOST_PID_CONTAINERS | $(echo \"scale=1; $HOST_PID_CONTAINERS * 100 / $TOTAL_OPERATORS\" | bc)% | $( [ $HOST_PID_CONTAINERS -eq 0 ] &amp;&amp; echo \"\u2705 LOW\" || echo \"\ud83d\udea8 CRITICAL\" ) |\" &gt;&gt; $SECURITY_REPORT\n\necho \"\" &gt;&gt; $SECURITY_REPORT\necho \"## Critical Security Violations\" &gt;&gt; $SECURITY_REPORT\n\n# Detailed analysis of security violations\necho \"### \ud83d\udea8 CRITICAL: Privileged Containers\" &gt;&gt; $SECURITY_REPORT\nif [ $PRIVILEGED_CONTAINERS -gt 0 ]; then\n    jq -r '.operators[] | select(.spec.spec.template.spec.containers[0].securityContext.privileged == true) | \n           \"- **\\(.name)** (namespace: \\(.namespace)) - Image: \\(.image // \"unknown\")\"' container-security.json &gt;&gt; $SECURITY_REPORT\n    echo \"\" &gt;&gt; $SECURITY_REPORT\n    echo \"**Impact:** Privileged containers have full access to host resources and can escape container isolation.\" &gt;&gt; $SECURITY_REPORT\n    echo \"**Recommendation:** Review necessity and implement least-privilege alternatives.\" &gt;&gt; $SECURITY_REPORT\nelse\n    echo \"\u2705 No privileged containers detected\" &gt;&gt; $SECURITY_REPORT\nfi\n\necho \"\" &gt;&gt; $SECURITY_REPORT\necho \"### \u26a0\ufe0f HIGH RISK: Containers Running as Root\" &gt;&gt; $SECURITY_REPORT\nif [ $ROOT_CONTAINERS -gt 0 ]; then\n    jq -r '.operators[] | select(.spec.spec.template.spec.containers[0].securityContext.runAsUser == 0) | \n           \"- **\\(.name)** (namespace: \\(.namespace)) - Image: \\(.image // \"unknown\")\"' container-security.json &gt;&gt; $SECURITY_REPORT\n    echo \"\" &gt;&gt; $SECURITY_REPORT\n    echo \"**Impact:** Root containers increase attack surface and privilege escalation risk.\" &gt;&gt; $SECURITY_REPORT\n    echo \"**Recommendation:** Configure containers to run as non-root users.\" &gt;&gt; $SECURITY_REPORT\nelse\n    echo \"\u2705 No containers running as root detected\" &gt;&gt; $SECURITY_REPORT\nfi\n\necho \"\" &gt;&gt; $SECURITY_REPORT\necho \"### \u26a0\ufe0f MEDIUM RISK: Host Network Access\" &gt;&gt; $SECURITY_REPORT\nif [ $HOST_NETWORK_CONTAINERS -gt 0 ]; then\n    jq -r '.operators[] | select(.spec.spec.template.spec.hostNetwork == true) | \n           \"- **\\(.name)** (namespace: \\(.namespace)) - Image: \\(.image // \"unknown\")\"' container-security.json &gt;&gt; $SECURITY_REPORT\n    echo \"\" &gt;&gt; $SECURITY_REPORT\n    echo \"**Impact:** Host network access bypasses Kubernetes network isolation.\" &gt;&gt; $SECURITY_REPORT\n    echo \"**Recommendation:** Use Kubernetes Services instead of host networking when possible.\" &gt;&gt; $SECURITY_REPORT\nelse\n    echo \"\u2705 No host network access detected\" &gt;&gt; $SECURITY_REPORT\nfi\n\necho \"\" &gt;&gt; $SECURITY_REPORT\necho \"### \u26a0\ufe0f MEDIUM RISK: Containers without Resource Limits\" &gt;&gt; $SECURITY_REPORT\nif [ $NO_LIMITS_CONTAINERS -gt 0 ]; then\n    jq -r '.operators[] | select(.spec.spec.template.spec.containers[0].resources.limits == null) | \n           \"- **\\(.name)** (namespace: \\(.namespace)) - Image: \\(.image // \"unknown\")\"' container-security.json &gt;&gt; $SECURITY_REPORT\n    echo \"\" &gt;&gt; $SECURITY_REPORT\n    echo \"**Impact:** Containers without limits can consume unlimited resources, enabling DoS attacks.\" &gt;&gt; $SECURITY_REPORT\n    echo \"**Recommendation:** Implement CPU and memory limits for all containers.\" &gt;&gt; $SECURITY_REPORT\nelse\n    echo \"\u2705 All containers have resource limits\" &gt;&gt; $SECURITY_REPORT\nfi\n\necho \"\" &gt;&gt; $SECURITY_REPORT\necho \"## Security Context Analysis\" &gt;&gt; $SECURITY_REPORT\n\n# Detailed security context analysis\necho \"### Detailed Security Context Matrix\" &gt;&gt; $SECURITY_REPORT\necho \"| Operator | Privileged | RunAsUser | ReadOnlyRootFS | AllowPrivilegeEsc | HostNetwork | Risk Score |\" &gt;&gt; $SECURITY_REPORT\necho \"|----------|------------|-----------|----------------|-------------------|-------------|-----------|\" &gt;&gt; $SECURITY_REPORT\n\njq -r '.operators[] | \n       {\n           name: .name,\n           privileged: (.spec.spec.template.spec.containers[0].securityContext.privileged // false),\n           runAsUser: (.spec.spec.template.spec.containers[0].securityContext.runAsUser // \"not_set\"),\n           readOnlyRootFS: (.spec.spec.template.spec.containers[0].securityContext.readOnlyRootFilesystem // false),\n           allowPrivilegeEsc: (.spec.spec.template.spec.containers[0].securityContext.allowPrivilegeEscalation // true),\n           hostNetwork: (.spec.spec.template.spec.hostNetwork // false)\n       } |\n       # Calculate risk score\n       (.privileged | if . then 10 else 0 end) +\n       (.runAsUser | if . == 0 then 5 elif . == \"not_set\" then 3 else 0 end) +\n       (.readOnlyRootFS | if . then -2 else 2 end) +\n       (.allowPrivilegeEsc | if . then 3 else -1 end) +\n       (.hostNetwork | if . then 4 else 0 end) as $risk |\n       \"| \\(.name) | \\(.privileged) | \\(.runAsUser) | \\(.readOnlyRootFS) | \\(.allowPrivilegeEsc) | \\(.hostNetwork) | \\($risk) \\(if $risk &gt;= 10 then \"\ud83d\udea8\" elif $risk &gt;= 6 then \"\u26a0\ufe0f\" elif $risk &gt;= 3 then \"\u26a0\ufe0f\" else \"\u2705\" end) |\"' \\\n       container-security.json &gt;&gt; $SECURITY_REPORT\n\necho \"\" &gt;&gt; $SECURITY_REPORT\necho \"**Risk Score Legend:**\" &gt;&gt; $SECURITY_REPORT\necho \"- \ud83d\udea8 **10+ Critical**: Immediate attention required\" &gt;&gt; $SECURITY_REPORT\necho \"- \u26a0\ufe0f **6-9 High**: Should be addressed soon\" &gt;&gt; $SECURITY_REPORT  \necho \"- \u26a0\ufe0f **3-5 Medium**: Consider improvements\" &gt;&gt; $SECURITY_REPORT\necho \"- \u2705 **0-2 Low**: Good security posture\" &gt;&gt; $SECURITY_REPORT\n\necho \"\" &gt;&gt; $SECURITY_REPORT\necho \"## Remediation Plan\" &gt;&gt; $SECURITY_REPORT\n\n# Generate remediation recommendations based on findings\nTOTAL_VIOLATIONS=$(($PRIVILEGED_CONTAINERS + $ROOT_CONTAINERS + $HOST_NETWORK_CONTAINERS))\n\nif [ $TOTAL_VIOLATIONS -eq 0 ]; then\n    echo \"\u2705 **Excellent Security Posture**\" &gt;&gt; $SECURITY_REPORT\n    echo \"No critical security violations detected. Continue monitoring.\" &gt;&gt; $SECURITY_REPORT\nelif [ $TOTAL_VIOLATIONS -lt 3 ]; then\n    echo \"\u26a0\ufe0f **Good Security Posture with Minor Issues**\" &gt;&gt; $SECURITY_REPORT\n    echo \"Address the following items to improve security:\" &gt;&gt; $SECURITY_REPORT\nelse\n    echo \"\ud83d\udea8 **Security Attention Required**\" &gt;&gt; $SECURITY_REPORT\n    echo \"Multiple security violations detected requiring immediate attention:\" &gt;&gt; $SECURITY_REPORT\nfi\n\necho \"\" &gt;&gt; $SECURITY_REPORT\necho \"### Immediate Actions\" &gt;&gt; $SECURITY_REPORT\n[ $PRIVILEGED_CONTAINERS -gt 0 ] &amp;&amp; echo \"1. **CRITICAL**: Review and remediate all privileged containers\" &gt;&gt; $SECURITY_REPORT\n[ $ROOT_CONTAINERS -gt 0 ] &amp;&amp; echo \"2. **HIGH**: Configure non-root users for containers\" &gt;&gt; $SECURITY_REPORT\n[ $HOST_NETWORK_CONTAINERS -gt 0 ] &amp;&amp; echo \"3. **MEDIUM**: Evaluate host network necessity\" &gt;&gt; $SECURITY_REPORT\n[ $NO_LIMITS_CONTAINERS -gt 0 ] &amp;&amp; echo \"4. **MEDIUM**: Implement resource limits for all containers\" &gt;&gt; $SECURITY_REPORT\n\necho \"\" &gt;&gt; $SECURITY_REPORT\necho \"### Long-term Improvements\" &gt;&gt; $SECURITY_REPORT\necho \"1. Implement Pod Security Standards\" &gt;&gt; $SECURITY_REPORT\necho \"2. Use admission controllers (e.g., OPA Gatekeeper)\" &gt;&gt; $SECURITY_REPORT\necho \"3. Regular security scanning of container images\" &gt;&gt; $SECURITY_REPORT\necho \"4. Implement runtime security monitoring\" &gt;&gt; $SECURITY_REPORT\necho \"5. Regular security context audits\" &gt;&gt; $SECURITY_REPORT\n\nrm container-security.json\necho \"Container security analysis complete: $SECURITY_REPORT\"\nEOF\n\nchmod +x container-security-analyzer.sh\n</code></pre>"},{"location":"examples/security-compliance/#compliance-reporting","title":"Compliance Reporting","text":""},{"location":"examples/security-compliance/#soc-2-compliance-report","title":"SOC 2 Compliance Report","text":"<pre><code># Create SOC 2 compliance reporting script\ncat &gt; soc2-compliance-report.sh &lt;&lt; 'EOF'\n#!/bin/bash\n# SOC 2 Compliance Report Generator\n\nCOMPLIANCE_REPORT=\"soc2-compliance-report-$(date +%Y-%m-%d).md\"\nAUDIT_PERIOD_START=${1:-$(date -d '30 days ago' +%Y-%m-%d)}\nAUDIT_PERIOD_END=${2:-$(date +%Y-%m-%d)}\n\necho \"# SOC 2 Compliance Report\" &gt; $COMPLIANCE_REPORT\necho \"\" &gt;&gt; $COMPLIANCE_REPORT\necho \"**Report Date:** $(date)\" &gt;&gt; $COMPLIANCE_REPORT\necho \"**Audit Period:** $AUDIT_PERIOD_START to $AUDIT_PERIOD_END\" &gt;&gt; $COMPLIANCE_REPORT\necho \"**Scope:** Kubernetes Cluster Security Controls\" &gt;&gt; $COMPLIANCE_REPORT\necho \"\" &gt;&gt; $COMPLIANCE_REPORT\n\n# Store current state\nk8s-datamodel database store --notes \"SOC2 Compliance Assessment - $(date +%Y-%m-%d)\"\nSNAPSHOT_ID=$(k8s-datamodel database list --limit 1 --output json | jq -r '.[0].id')\nk8s-datamodel database export $SNAPSHOT_ID --file soc2-compliance.json\n\necho \"## Executive Summary\" &gt;&gt; $COMPLIANCE_REPORT\necho \"\" &gt;&gt; $COMPLIANCE_REPORT\n\n# Calculate compliance metrics\nTOTAL_COMPONENTS=$(jq '[.crds, .operators, .csvs] | map(length) | add' soc2-compliance.json)\nPRIVILEGED_CONTAINERS=$(jq '[.operators[] | select(.spec.spec.template.spec.containers[0].securityContext.privileged == true)] | length' soc2-compliance.json)\nWILDCARD_PERMISSIONS=$(jq '[.csvs[] | select(.spec.spec.install.spec.clusterPermissions[]?.rules[]?.resources[]? == \"*\")] | length' soc2-compliance.json)\n\necho \"- **Total Components Assessed:** $TOTAL_COMPONENTS\" &gt;&gt; $COMPLIANCE_REPORT\necho \"- **High-Risk Configurations:** $(($PRIVILEGED_CONTAINERS + $WILDCARD_PERMISSIONS))\" &gt;&gt; $COMPLIANCE_REPORT\necho \"- **Compliance Status:** $( [ $(($PRIVILEGED_CONTAINERS + $WILDCARD_PERMISSIONS)) -eq 0 ] &amp;&amp; echo \"\u2705 COMPLIANT\" || echo \"\u26a0\ufe0f NON-COMPLIANT\" )\" &gt;&gt; $COMPLIANCE_REPORT\n\necho \"\" &gt;&gt; $COMPLIANCE_REPORT\necho \"## SOC 2 Control Assessment\" &gt;&gt; $COMPLIANCE_REPORT\n\necho \"\" &gt;&gt; $COMPLIANCE_REPORT\necho \"### CC6.1 - Logical and Physical Access Controls\" &gt;&gt; $COMPLIANCE_REPORT\necho \"**Control Objective:** The entity implements logical and physical access controls to restrict unauthorized access.\" &gt;&gt; $COMPLIANCE_REPORT\necho \"\" &gt;&gt; $COMPLIANCE_REPORT\n\n# Access control assessment\nRBAC_VIOLATIONS=$(jq '[.csvs[] | select(.spec.spec.install.spec.clusterPermissions[]?.rules[]? | (.resources | contains([\"*\"])) or (.verbs | contains([\"*\"])))] | length' soc2-compliance.json)\n\nif [ $RBAC_VIOLATIONS -eq 0 ]; then\n    echo \"\u2705 **COMPLIANT**: No wildcard RBAC permissions detected\" &gt;&gt; $COMPLIANCE_REPORT\n    echo \"- All operators follow least-privilege principle\" &gt;&gt; $COMPLIANCE_REPORT\n    echo \"- No excessive permissions identified\" &gt;&gt; $COMPLIANCE_REPORT\nelse\n    echo \"\u274c **NON-COMPLIANT**: $RBAC_VIOLATIONS operators with excessive permissions\" &gt;&gt; $COMPLIANCE_REPORT\n    echo \"**Violations:**\" &gt;&gt; $COMPLIANCE_REPORT\n    jq -r '.csvs[] | select(.spec.spec.install.spec.clusterPermissions[]?.rules[]?.resources[]? == \"*\") | \n           \"- \\(.display_name): Wildcard resource access\"' soc2-compliance.json &gt;&gt; $COMPLIANCE_REPORT\nfi\n\necho \"\" &gt;&gt; $COMPLIANCE_REPORT\necho \"### CC6.2 - System Security\" &gt;&gt; $COMPLIANCE_REPORT\necho \"**Control Objective:** The entity implements system security controls to protect against unauthorized access.\" &gt;&gt; $COMPLIANCE_REPORT\necho \"\" &gt;&gt; $COMPLIANCE_REPORT\n\nif [ $PRIVILEGED_CONTAINERS -eq 0 ]; then\n    echo \"\u2705 **COMPLIANT**: No privileged containers detected\" &gt;&gt; $COMPLIANCE_REPORT\n    echo \"- Container isolation maintained\" &gt;&gt; $COMPLIANCE_REPORT\n    echo \"- No host-level access violations\" &gt;&gt; $COMPLIANCE_REPORT\nelse\n    echo \"\u274c **NON-COMPLIANT**: $PRIVILEGED_CONTAINERS privileged containers detected\" &gt;&gt; $COMPLIANCE_REPORT\n    echo \"**Violations:**\" &gt;&gt; $COMPLIANCE_REPORT\n    jq -r '.operators[] | select(.spec.spec.template.spec.containers[0].securityContext.privileged == true) | \n           \"- \\(.name) in \\(.namespace): Privileged container\"' soc2-compliance.json &gt;&gt; $COMPLIANCE_REPORT\nfi\n\necho \"\" &gt;&gt; $COMPLIANCE_REPORT\necho \"### CC6.3 - Data Security and Privacy\" &gt;&gt; $COMPLIANCE_REPORT\necho \"**Control Objective:** The entity protects data in transmission and at rest.\" &gt;&gt; $COMPLIANCE_REPORT\necho \"\" &gt;&gt; $COMPLIANCE_REPORT\n\n# Check for secret access\nSECRET_ACCESS=$(jq '[.csvs[] | select(.spec.spec.install.spec.clusterPermissions[]?.rules[]?.resources[]? == \"secrets\")] | length' soc2-compliance.json)\n\nif [ $SECRET_ACCESS -eq 0 ]; then\n    echo \"\u2705 **COMPLIANT**: No direct secret access permissions\" &gt;&gt; $COMPLIANCE_REPORT\nelse\n    echo \"\u26a0\ufe0f **ATTENTION REQUIRED**: $SECRET_ACCESS operators with secret access\" &gt;&gt; $COMPLIANCE_REPORT\n    echo \"**Review Required:**\" &gt;&gt; $COMPLIANCE_REPORT\n    jq -r '.csvs[] | select(.spec.spec.install.spec.clusterPermissions[]?.rules[]?.resources[]? == \"secrets\") | \n           \"- \\(.display_name): Can access secrets\"' soc2-compliance.json &gt;&gt; $COMPLIANCE_REPORT\nfi\n\necho \"\" &gt;&gt; $COMPLIANCE_REPORT\necho \"### CC7.1 - System Monitoring\" &gt;&gt; $COMPLIANCE_REPORT\necho \"**Control Objective:** The entity monitors system components and operations for anomalies.\" &gt;&gt; $COMPLIANCE_REPORT\necho \"\" &gt;&gt; $COMPLIANCE_REPORT\n\necho \"\u2705 **COMPLIANT**: Monitoring controls implemented\" &gt;&gt; $COMPLIANCE_REPORT\necho \"- k8s-datamodel provides continuous monitoring\" &gt;&gt; $COMPLIANCE_REPORT\necho \"- Historical snapshots maintained for audit trail\" &gt;&gt; $COMPLIANCE_REPORT\necho \"- Security baselines established and monitored\" &gt;&gt; $COMPLIANCE_REPORT\n\necho \"\" &gt;&gt; $COMPLIANCE_REPORT\necho \"## Remediation Requirements\" &gt;&gt; $COMPLIANCE_REPORT\n\nTOTAL_VIOLATIONS=$(($RBAC_VIOLATIONS + $PRIVILEGED_CONTAINERS))\n\nif [ $TOTAL_VIOLATIONS -eq 0 ]; then\n    echo \"\u2705 **No remediation required** - All controls are compliant\" &gt;&gt; $COMPLIANCE_REPORT\nelse\n    echo \"\u26a0\ufe0f **Remediation required** - $TOTAL_VIOLATIONS violations must be addressed\" &gt;&gt; $COMPLIANCE_REPORT\n    echo \"\" &gt;&gt; $COMPLIANCE_REPORT\n    echo \"### Required Actions\" &gt;&gt; $COMPLIANCE_REPORT\n    [ $RBAC_VIOLATIONS -gt 0 ] &amp;&amp; echo \"1. **CRITICAL**: Remove wildcard RBAC permissions\" &gt;&gt; $COMPLIANCE_REPORT\n    [ $PRIVILEGED_CONTAINERS -gt 0 ] &amp;&amp; echo \"2. **CRITICAL**: Eliminate privileged containers\" &gt;&gt; $COMPLIANCE_REPORT\n    echo \"3. Implement additional monitoring and alerting\" &gt;&gt; $COMPLIANCE_REPORT\n    echo \"4. Establish regular compliance validation schedule\" &gt;&gt; $COMPLIANCE_REPORT\nfi\n\necho \"\" &gt;&gt; $COMPLIANCE_REPORT\necho \"## Audit Evidence\" &gt;&gt; $COMPLIANCE_REPORT\necho \"- **Snapshot ID:** $SNAPSHOT_ID\" &gt;&gt; $COMPLIANCE_REPORT\necho \"- **Assessment Tool:** k8s-datamodel\" &gt;&gt; $COMPLIANCE_REPORT\necho \"- **Evidence Location:** Database snapshot contains complete cluster configuration\" &gt;&gt; $COMPLIANCE_REPORT\necho \"- **Retention:** Snapshots retained per data retention policy\" &gt;&gt; $COMPLIANCE_REPORT\n\necho \"\" &gt;&gt; $COMPLIANCE_REPORT\necho \"## Appendix: Detailed Findings\" &gt;&gt; $COMPLIANCE_REPORT\n\n# Detailed technical findings\necho \"\" &gt;&gt; $COMPLIANCE_REPORT\necho \"### RBAC Permission Matrix\" &gt;&gt; $COMPLIANCE_REPORT\necho \"| Operator | Cluster Permissions | Namespace Permissions | Risk Level |\" &gt;&gt; $COMPLIANCE_REPORT\necho \"|----------|-------------------|---------------------|-----------|\" &gt;&gt; $COMPLIANCE_REPORT\n\njq -r '.csvs[] | \n       {\n           name: .display_name,\n           cluster_perms: (.spec.spec.install.spec.clusterPermissions | length),\n           ns_perms: (.spec.spec.install.spec.permissions | length),\n           has_wildcard: ((.spec.spec.install.spec.clusterPermissions[]?.rules[]?.resources[]? == \"*\") or \n                         (.spec.spec.install.spec.clusterPermissions[]?.rules[]?.verbs[]? == \"*\"))\n       } |\n       \"| \\(.name) | \\(.cluster_perms) | \\(.ns_perms) | \\(if .has_wildcard then \"\ud83d\udea8 HIGH\" elif .cluster_perms &gt; 3 then \"\u26a0\ufe0f MEDIUM\" else \"\u2705 LOW\" end) |\"' \\\n       soc2-compliance.json &gt;&gt; $COMPLIANCE_REPORT\n\nrm soc2-compliance.json\necho \"SOC 2 compliance report generated: $COMPLIANCE_REPORT\"\nEOF\n\nchmod +x soc2-compliance-report.sh\n</code></pre>"},{"location":"examples/security-compliance/#pci-dss-compliance-assessment","title":"PCI DSS Compliance Assessment","text":"<pre><code># Create PCI DSS compliance assessment script\ncat &gt; pci-dss-compliance.sh &lt;&lt; 'EOF'\n#!/bin/bash\n# PCI DSS Compliance Assessment Script\n\nPCI_REPORT=\"pci-dss-compliance-$(date +%Y-%m-%d).md\"\n\necho \"# PCI DSS Compliance Assessment Report\" &gt; $PCI_REPORT\necho \"\" &gt;&gt; $PCI_REPORT\necho \"**Assessment Date:** $(date)\" &gt;&gt; $PCI_REPORT\necho \"**PCI DSS Version:** 4.0\" &gt;&gt; $PCI_REPORT\necho \"**Scope:** Kubernetes Infrastructure Security Controls\" &gt;&gt; $PCI_REPORT\necho \"\" &gt;&gt; $PCI_REPORT\n\n# Store current state\nk8s-datamodel database store --notes \"PCI DSS Compliance Assessment - $(date +%Y-%m-%d)\"\nSNAPSHOT_ID=$(k8s-datamodel database list --limit 1 --output json | jq -r '.[0].id')\nk8s-datamodel database export $SNAPSHOT_ID --file pci-compliance.json\n\necho \"## Executive Summary\" &gt;&gt; $PCI_REPORT\necho \"\" &gt;&gt; $PCI_REPORT\n\n# PCI DSS specific security metrics\nNETWORK_VIOLATIONS=$(jq '[.operators[] | select(.spec.spec.template.spec.hostNetwork == true)] | length' pci-compliance.json)\nACCESS_VIOLATIONS=$(jq '[.csvs[] | select(.spec.spec.install.spec.clusterPermissions[]?.rules[]?.resources[]? == \"*\")] | length' pci-compliance.json)\nPRIVILEGE_VIOLATIONS=$(jq '[.operators[] | select(.spec.spec.template.spec.containers[0].securityContext.privileged == true)] | length' pci-compliance.json)\n\nTOTAL_VIOLATIONS=$(($NETWORK_VIOLATIONS + $ACCESS_VIOLATIONS + $PRIVILEGE_VIOLATIONS))\n\necho \"**Compliance Status:** $( [ $TOTAL_VIOLATIONS -eq 0 ] &amp;&amp; echo \"\u2705 COMPLIANT\" || echo \"\u274c NON-COMPLIANT\" )\" &gt;&gt; $PCI_REPORT\necho \"**Total Security Violations:** $TOTAL_VIOLATIONS\" &gt;&gt; $PCI_REPORT\necho \"**Risk Level:** $( [ $TOTAL_VIOLATIONS -eq 0 ] &amp;&amp; echo \"LOW\" || [ $TOTAL_VIOLATIONS -lt 5 ] &amp;&amp; echo \"MEDIUM\" || echo \"HIGH\" )\" &gt;&gt; $PCI_REPORT\n\necho \"\" &gt;&gt; $PCI_REPORT\necho \"## PCI DSS Requirement Assessment\" &gt;&gt; $PCI_REPORT\n\necho \"\" &gt;&gt; $PCI_REPORT\necho \"### Requirement 1: Install and maintain network security controls\" &gt;&gt; $PCI_REPORT\n\nif [ $NETWORK_VIOLATIONS -eq 0 ]; then\n    echo \"\u2705 **COMPLIANT**: Network isolation maintained\" &gt;&gt; $PCI_REPORT\n    echo \"- No host network access detected\" &gt;&gt; $PCI_REPORT\n    echo \"- Container network isolation in place\" &gt;&gt; $PCI_REPORT\nelse\n    echo \"\u274c **NON-COMPLIANT**: $NETWORK_VIOLATIONS network security violations\" &gt;&gt; $PCI_REPORT\n    echo \"**Violations:**\" &gt;&gt; $PCI_REPORT\n    jq -r '.operators[] | select(.spec.spec.template.spec.hostNetwork == true) | \n           \"- \\(.name): Host network access enabled\"' pci-compliance.json &gt;&gt; $PCI_REPORT\nfi\n\necho \"\" &gt;&gt; $PCI_REPORT\necho \"### Requirement 7: Restrict access by business need to know\" &gt;&gt; $PCI_REPORT\n\nif [ $ACCESS_VIOLATIONS -eq 0 ]; then\n    echo \"\u2705 **COMPLIANT**: Access controls properly implemented\" &gt;&gt; $PCI_REPORT\n    echo \"- No excessive permissions detected\" &gt;&gt; $PCI_REPORT\n    echo \"- Least privilege principle followed\" &gt;&gt; $PCI_REPORT\nelse\n    echo \"\u274c **NON-COMPLIANT**: $ACCESS_VIOLATIONS access control violations\" &gt;&gt; $PCI_REPORT\n    echo \"**Violations:**\" &gt;&gt; $PCI_REPORT\n    jq -r '.csvs[] | select(.spec.spec.install.spec.clusterPermissions[]?.rules[]?.resources[]? == \"*\") | \n           \"- \\(.display_name): Excessive cluster permissions\"' pci-compliance.json &gt;&gt; $PCI_REPORT\nfi\n\necho \"\" &gt;&gt; $PCI_REPORT\necho \"### Requirement 8: Identify users and authenticate access\" &gt;&gt; $PCI_REPORT\n\n# Check for service account configurations\nSA_COUNT=$(jq '[.csvs[] | .spec.spec.install.spec.deployments[]?.spec.template.spec.serviceAccountName] | map(select(. != null)) | length' pci-compliance.json)\n\nif [ $SA_COUNT -gt 0 ]; then\n    echo \"\u2705 **COMPLIANT**: Service accounts properly configured\" &gt;&gt; $PCI_REPORT\n    echo \"- $SA_COUNT operators use dedicated service accounts\" &gt;&gt; $PCI_REPORT\nelse\n    echo \"\u26a0\ufe0f **REVIEW REQUIRED**: Service account usage should be verified\" &gt;&gt; $PCI_REPORT\nfi\n\necho \"\" &gt;&gt; $PCI_REPORT\necho \"### Requirement 11: Regularly test security systems and processes\" &gt;&gt; $PCI_REPORT\n\necho \"\u2705 **COMPLIANT**: Security testing framework in place\" &gt;&gt; $PCI_REPORT\necho \"- Automated security assessments implemented\" &gt;&gt; $PCI_REPORT\necho \"- Regular compliance monitoring active\" &gt;&gt; $PCI_REPORT\necho \"- Historical security data maintained\" &gt;&gt; $PCI_REPORT\n\necho \"\" &gt;&gt; $PCI_REPORT\necho \"## Detailed Security Analysis\" &gt;&gt; $PCI_REPORT\n\necho \"\" &gt;&gt; $PCI_REPORT\necho \"### Network Security Assessment\" &gt;&gt; $PCI_REPORT\necho \"| Operator | Host Network | Host PID | Risk Level |\" &gt;&gt; $PCI_REPORT\necho \"|----------|-------------|----------|-----------|\" &gt;&gt; $PCI_REPORT\n\njq -r '.operators[] | \n       {\n           name: .name,\n           hostNetwork: (.spec.spec.template.spec.hostNetwork // false),\n           hostPID: (.spec.spec.template.spec.hostPID // false)\n       } |\n       \"| \\(.name) | \\(.hostNetwork) | \\(.hostPID) | \\(if .hostNetwork or .hostPID then \"\ud83d\udea8 HIGH\" else \"\u2705 LOW\" end) |\"' \\\n       pci-compliance.json &gt;&gt; $PCI_REPORT\n\necho \"\" &gt;&gt; $PCI_REPORT\necho \"### Access Control Matrix\" &gt;&gt; $PCI_REPORT\necho \"| Component | Type | Permissions | Compliance Status |\" &gt;&gt; $PCI_REPORT\necho \"|-----------|------|-------------|------------------|\" &gt;&gt; $PCI_REPORT\n\njq -r '.csvs[] | \n       {\n           name: .display_name,\n           cluster_perms: (.spec.spec.install.spec.clusterPermissions | length),\n           has_wildcard: (.spec.spec.install.spec.clusterPermissions[]?.rules[]?.resources[]? == \"*\")\n       } |\n       \"| \\(.name) | CSV | \\(.cluster_perms) cluster perms | \\(if .has_wildcard then \"\u274c NON-COMPLIANT\" else \"\u2705 COMPLIANT\" end) |\"' \\\n       pci-compliance.json &gt;&gt; $PCI_REPORT\n\necho \"\" &gt;&gt; $PCI_REPORT\necho \"## Remediation Plan\" &gt;&gt; $PCI_REPORT\n\nif [ $TOTAL_VIOLATIONS -eq 0 ]; then\n    echo \"\u2705 **No remediation required** - All PCI DSS requirements met\" &gt;&gt; $PCI_REPORT\n    echo \"\" &gt;&gt; $PCI_REPORT\n    echo \"### Maintenance Activities\" &gt;&gt; $PCI_REPORT\n    echo \"1. Continue regular compliance monitoring\" &gt;&gt; $PCI_REPORT\n    echo \"2. Maintain current security baselines\" &gt;&gt; $PCI_REPORT\n    echo \"3. Schedule quarterly compliance reviews\" &gt;&gt; $PCI_REPORT\nelse\n    echo \"\u274c **Immediate remediation required** - $TOTAL_VIOLATIONS violations must be addressed\" &gt;&gt; $PCI_REPORT\n    echo \"\" &gt;&gt; $PCI_REPORT\n    echo \"### Critical Actions\" &gt;&gt; $PCI_REPORT\n    [ $NETWORK_VIOLATIONS -gt 0 ] &amp;&amp; echo \"1. **URGENT**: Remove host network access\" &gt;&gt; $PCI_REPORT\n    [ $ACCESS_VIOLATIONS -gt 0 ] &amp;&amp; echo \"2. **URGENT**: Implement least-privilege access controls\" &gt;&gt; $PCI_REPORT\n    [ $PRIVILEGE_VIOLATIONS -gt 0 ] &amp;&amp; echo \"3. **URGENT**: Eliminate privileged containers\" &gt;&gt; $PCI_REPORT\n\n    echo \"\" &gt;&gt; $PCI_REPORT\n    echo \"### Timeline\" &gt;&gt; $PCI_REPORT\n    echo \"- **Immediate (0-7 days):** Address critical security violations\" &gt;&gt; $PCI_REPORT\n    echo \"- **Short-term (1-4 weeks):** Implement additional controls\" &gt;&gt; $PCI_REPORT\n    echo \"- **Long-term (1-3 months):** Establish continuous compliance monitoring\" &gt;&gt; $PCI_REPORT\nfi\n\necho \"\" &gt;&gt; $PCI_REPORT\necho \"## Compensating Controls\" &gt;&gt; $PCI_REPORT\n\nif [ $TOTAL_VIOLATIONS -gt 0 ]; then\n    echo \"The following compensating controls should be implemented:\" &gt;&gt; $PCI_REPORT\n    echo \"1. **Network Segmentation:** Implement strict network policies\" &gt;&gt; $PCI_REPORT\n    echo \"2. **Enhanced Monitoring:** Deploy runtime security monitoring\" &gt;&gt; $PCI_REPORT\n    echo \"3. **Regular Auditing:** Increase audit frequency to weekly\" &gt;&gt; $PCI_REPORT\n    echo \"4. **Admission Control:** Implement policy-based admission controllers\" &gt;&gt; $PCI_REPORT\nelse\n    echo \"No compensating controls required - direct compliance achieved\" &gt;&gt; $PCI_REPORT\nfi\n\nrm pci-compliance.json\necho \"PCI DSS compliance assessment complete: $PCI_REPORT\"\nEOF\n\nchmod +x pci-dss-compliance.sh\n</code></pre>"},{"location":"examples/security-compliance/#automated-security-monitoring","title":"Automated Security Monitoring","text":""},{"location":"examples/security-compliance/#continuous-security-monitoring","title":"Continuous Security Monitoring","text":"<pre><code># Create continuous security monitoring script\ncat &gt; security-continuous-monitoring.sh &lt;&lt; 'EOF'\n#!/bin/bash\n# Continuous Security Monitoring Script\n\nMONITORING_LOG=\"/var/log/k8s-security-monitor.log\"\nALERT_THRESHOLD_PRIVILEGED=0\nALERT_THRESHOLD_WILDCARD=0\nALERT_EMAIL=\"security-team@company.com\"\n\n# Function to send alert\nsend_alert() {\n    local alert_type=\"$1\"\n    local message=\"$2\"\n\n    echo \"$(date): SECURITY ALERT - $alert_type: $message\" | tee -a \"$MONITORING_LOG\"\n\n    # Send email alert (requires mail command)\n    if command -v mail &gt; /dev/null; then\n        echo \"$message\" | mail -s \"K8s Security Alert: $alert_type\" \"$ALERT_EMAIL\"\n    fi\n\n    # Send to syslog\n    logger -p security.warning \"k8s-security-monitor: $alert_type - $message\"\n}\n\n# Store current security snapshot\nk8s-datamodel database store --notes \"Security monitoring - $(date +%Y-%m-%d-%H-%M)\"\nSNAPSHOT_ID=$(k8s-datamodel database list --limit 1 --output json | jq -r '.[0].id')\nk8s-datamodel database export $SNAPSHOT_ID --file security-monitoring.json\n\necho \"$(date): Security monitoring check started\" | tee -a \"$MONITORING_LOG\"\n\n# Check for privileged containers\nPRIVILEGED_COUNT=$(jq '[.operators[] | select(.spec.spec.template.spec.containers[0].securityContext.privileged == true)] | length' security-monitoring.json)\nif [ $PRIVILEGED_COUNT -gt $ALERT_THRESHOLD_PRIVILEGED ]; then\n    PRIVILEGED_CONTAINERS=$(jq -r '.operators[] | select(.spec.spec.template.spec.containers[0].securityContext.privileged == true) | .name' security-monitoring.json | tr '\\n' ', ' | sed 's/,$//')\n    send_alert \"PRIVILEGED_CONTAINERS\" \"Found $PRIVILEGED_COUNT privileged containers: $PRIVILEGED_CONTAINERS\"\nfi\n\n# Check for wildcard permissions\nWILDCARD_COUNT=$(jq '[.csvs[] | select(.spec.spec.install.spec.clusterPermissions[]?.rules[]?.resources[]? == \"*\")] | length' security-monitoring.json)\nif [ $WILDCARD_COUNT -gt $ALERT_THRESHOLD_WILDCARD ]; then\n    WILDCARD_CSVS=$(jq -r '.csvs[] | select(.spec.spec.install.spec.clusterPermissions[]?.rules[]?.resources[]? == \"*\") | .display_name' security-monitoring.json | tr '\\n' ', ' | sed 's/,$//')\n    send_alert \"WILDCARD_PERMISSIONS\" \"Found $WILDCARD_COUNT CSVs with wildcard permissions: $WILDCARD_CSVS\"\nfi\n\n# Check for host network access\nHOST_NETWORK_COUNT=$(jq '[.operators[] | select(.spec.spec.template.spec.hostNetwork == true)] | length' security-monitoring.json)\nif [ $HOST_NETWORK_COUNT -gt 0 ]; then\n    HOST_NETWORK_OPERATORS=$(jq -r '.operators[] | select(.spec.spec.template.spec.hostNetwork == true) | .name' security-monitoring.json | tr '\\n' ', ' | sed 's/,$//')\n    send_alert \"HOST_NETWORK_ACCESS\" \"Found $HOST_NETWORK_COUNT operators with host network access: $HOST_NETWORK_OPERATORS\"\nfi\n\n# Check for containers without resource limits\nNO_LIMITS_COUNT=$(jq '[.operators[] | select(.spec.spec.template.spec.containers[0].resources.limits == null)] | length' security-monitoring.json)\nif [ $NO_LIMITS_COUNT -gt 5 ]; then  # Alert if more than 5 containers without limits\n    send_alert \"RESOURCE_LIMITS\" \"Found $NO_LIMITS_COUNT containers without resource limits\"\nfi\n\n# Generate daily security summary\nif [ $(date +%H%M) = \"0800\" ]; then  # Daily at 8 AM\n    SUMMARY_FILE=\"/var/log/k8s-security-daily-$(date +%Y-%m-%d).summary\"\n\n    cat &gt; \"$SUMMARY_FILE\" &lt;&lt; SUMMARY\nDaily Security Summary - $(date)\n================================\n\nCluster Security Metrics:\n- Total Operators: $(jq '.operators | length' security-monitoring.json)\n- Privileged Containers: $PRIVILEGED_COUNT\n- Wildcard Permissions: $WILDCARD_COUNT\n- Host Network Access: $HOST_NETWORK_COUNT\n- Containers w/o Limits: $NO_LIMITS_COUNT\n\nSecurity Status: $([ $(($PRIVILEGED_COUNT + $WILDCARD_COUNT)) -eq 0 ] &amp;&amp; echo \"\u2705 SECURE\" || echo \"\u26a0\ufe0f ATTENTION REQUIRED\")\n\nDatabase Info:\n- Latest Snapshot: $SNAPSHOT_ID\n- Storage Location: $(dirname $(k8s-datamodel database list --limit 1 --output json | jq -r '.[0].id' 2&gt;/dev/null) 2&gt;/dev/null || echo \"~/.k8s-inventory/\")/inventory.db\n\nSUMMARY\n\n    # Email daily summary\n    if command -v mail &gt; /dev/null; then\n        cat \"$SUMMARY_FILE\" | mail -s \"K8s Daily Security Summary - $(date +%Y-%m-%d)\" \"$ALERT_EMAIL\"\n    fi\nfi\n\n# Cleanup old monitoring data\nrm security-monitoring.json\n\necho \"$(date): Security monitoring check completed\" | tee -a \"$MONITORING_LOG\"\n\n# Rotate logs if they get too large (keep last 1000 lines)\nif [ -f \"$MONITORING_LOG\" ] &amp;&amp; [ $(wc -l &lt; \"$MONITORING_LOG\") -gt 1000 ]; then\n    tail -1000 \"$MONITORING_LOG\" &gt; \"${MONITORING_LOG}.tmp\"\n    mv \"${MONITORING_LOG}.tmp\" \"$MONITORING_LOG\"\nfi\nEOF\n\nchmod +x security-continuous-monitoring.sh\n</code></pre>"},{"location":"examples/security-compliance/#security-alerting-integration","title":"Security Alerting Integration","text":"<pre><code># Create security alerting integration with popular tools\ncat &gt; security-alerting-integration.sh &lt;&lt; 'EOF'\n#!/bin/bash\n# Security Alerting Integration Script\n\n# Configuration\nSLACK_WEBHOOK_URL=${SLACK_WEBHOOK_URL:-\"\"}\nTEAMS_WEBHOOK_URL=${TEAMS_WEBHOOK_URL:-\"\"}\nPAGERDUTY_INTEGRATION_KEY=${PAGERDUTY_INTEGRATION_KEY:-\"\"}\n\n# Function to send Slack alert\nsend_slack_alert() {\n    local alert_type=\"$1\"\n    local message=\"$2\"\n    local severity=\"$3\"\n\n    if [ -n \"$SLACK_WEBHOOK_URL\" ]; then\n        local color=\"danger\"\n        [ \"$severity\" = \"low\" ] &amp;&amp; color=\"warning\"\n        [ \"$severity\" = \"info\" ] &amp;&amp; color=\"good\"\n\n        curl -X POST -H 'Content-type: application/json' \\\n            --data \"{\n                \\\"attachments\\\": [{\n                    \\\"color\\\": \\\"$color\\\",\n                    \\\"title\\\": \\\"Kubernetes Security Alert\\\",\n                    \\\"fields\\\": [\n                        {\\\"title\\\": \\\"Alert Type\\\", \\\"value\\\": \\\"$alert_type\\\", \\\"short\\\": true},\n                        {\\\"title\\\": \\\"Severity\\\", \\\"value\\\": \\\"$severity\\\", \\\"short\\\": true},\n                        {\\\"title\\\": \\\"Message\\\", \\\"value\\\": \\\"$message\\\", \\\"short\\\": false},\n                        {\\\"title\\\": \\\"Timestamp\\\", \\\"value\\\": \\\"$(date)\\\", \\\"short\\\": true}\n                    ]\n                }]\n            }\" \\\n            \"$SLACK_WEBHOOK_URL\"\n    fi\n}\n\n# Function to send Teams alert\nsend_teams_alert() {\n    local alert_type=\"$1\"\n    local message=\"$2\"\n    local severity=\"$3\"\n\n    if [ -n \"$TEAMS_WEBHOOK_URL\" ]; then\n        local color=\"FF0000\"\n        [ \"$severity\" = \"low\" ] &amp;&amp; color=\"FFA500\"\n        [ \"$severity\" = \"info\" ] &amp;&amp; color=\"00FF00\"\n\n        curl -X POST -H 'Content-type: application/json' \\\n            --data \"{\n                \\\"@type\\\": \\\"MessageCard\\\",\n                \\\"@context\\\": \\\"http://schema.org/extensions\\\",\n                \\\"themeColor\\\": \\\"$color\\\",\n                \\\"summary\\\": \\\"Kubernetes Security Alert\\\",\n                \\\"sections\\\": [{\n                    \\\"activityTitle\\\": \\\"Kubernetes Security Alert\\\",\n                    \\\"activitySubtitle\\\": \\\"$alert_type\\\",\n                    \\\"facts\\\": [\n                        {\\\"name\\\": \\\"Severity\\\", \\\"value\\\": \\\"$severity\\\"},\n                        {\\\"name\\\": \\\"Message\\\", \\\"value\\\": \\\"$message\\\"},\n                        {\\\"name\\\": \\\"Timestamp\\\", \\\"value\\\": \\\"$(date)\\\"}\n                    ]\n                }]\n            }\" \\\n            \"$TEAMS_WEBHOOK_URL\"\n    fi\n}\n\n# Function to send PagerDuty alert\nsend_pagerduty_alert() {\n    local alert_type=\"$1\"\n    local message=\"$2\"\n    local severity=\"$3\"\n\n    if [ -n \"$PAGERDUTY_INTEGRATION_KEY\" ]; then\n        curl -X POST -H 'Content-Type: application/json' \\\n            --data \"{\n                \\\"routing_key\\\": \\\"$PAGERDUTY_INTEGRATION_KEY\\\",\n                \\\"event_action\\\": \\\"trigger\\\",\n                \\\"payload\\\": {\n                    \\\"summary\\\": \\\"Kubernetes Security Alert: $alert_type\\\",\n                    \\\"severity\\\": \\\"$severity\\\",\n                    \\\"source\\\": \\\"k8s-datamodel\\\",\n                    \\\"custom_details\\\": {\n                        \\\"alert_type\\\": \\\"$alert_type\\\",\n                        \\\"message\\\": \\\"$message\\\",\n                        \\\"timestamp\\\": \\\"$(date)\\\"\n                    }\n                }\n            }\" \\\n            \"https://events.pagerduty.com/v2/enqueue\"\n    fi\n}\n\n# Main alerting function\nsend_security_alert() {\n    local alert_type=\"$1\"\n    local message=\"$2\"\n    local severity=\"${3:-high}\"\n\n    echo \"Sending security alert: $alert_type - $message\"\n\n    send_slack_alert \"$alert_type\" \"$message\" \"$severity\"\n    send_teams_alert \"$alert_type\" \"$message\" \"$severity\"\n\n    # Only send to PagerDuty for critical/high severity alerts\n    if [ \"$severity\" = \"critical\" ] || [ \"$severity\" = \"high\" ]; then\n        send_pagerduty_alert \"$alert_type\" \"$message\" \"$severity\"\n    fi\n}\n\n# Example usage with security monitoring\nif [ \"$1\" = \"test\" ]; then\n    send_security_alert \"TEST_ALERT\" \"This is a test security alert\" \"info\"\n    echo \"Test alerts sent to configured endpoints\"\n    exit 0\nfi\n\n# Store current state and analyze\nk8s-datamodel database store --notes \"Security alerting check - $(date +%Y-%m-%d-%H-%M)\"\nSNAPSHOT_ID=$(k8s-datamodel database list --limit 1 --output json | jq -r '.[0].id')\nk8s-datamodel database export $SNAPSHOT_ID --file alerting-security.json\n\n# Check for critical violations and send alerts\nPRIVILEGED_COUNT=$(jq '[.operators[] | select(.spec.spec.template.spec.containers[0].securityContext.privileged == true)] | length' alerting-security.json)\nif [ $PRIVILEGED_COUNT -gt 0 ]; then\n    PRIVILEGED_LIST=$(jq -r '.operators[] | select(.spec.spec.template.spec.containers[0].securityContext.privileged == true) | .name' alerting-security.json | head -5 | tr '\\n' ', ' | sed 's/,$//')\n    send_security_alert \"PRIVILEGED_CONTAINERS\" \"Found $PRIVILEGED_COUNT privileged containers: $PRIVILEGED_LIST\" \"critical\"\nfi\n\nWILDCARD_COUNT=$(jq '[.csvs[] | select(.spec.spec.install.spec.clusterPermissions[]?.rules[]?.resources[]? == \"*\")] | length' alerting-security.json)\nif [ $WILDCARD_COUNT -gt 0 ]; then\n    WILDCARD_LIST=$(jq -r '.csvs[] | select(.spec.spec.install.spec.clusterPermissions[]?.rules[]?.resources[]? == \"*\") | .display_name' alerting-security.json | head -5 | tr '\\n' ', ' | sed 's/,$//')\n    send_security_alert \"WILDCARD_PERMISSIONS\" \"Found $WILDCARD_COUNT operators with excessive permissions: $WILDCARD_LIST\" \"critical\"\nfi\n\nrm alerting-security.json\necho \"Security alerting check completed\"\nEOF\n\nchmod +x security-alerting-integration.sh\n\n# Usage examples:\n# ./security-alerting-integration.sh test  # Send test alerts\n# ./security-alerting-integration.sh       # Run security check and send real alerts\n</code></pre> <p>This comprehensive security and compliance analysis suite provides:</p> <ol> <li>Security Baseline Management: Establish and validate security baselines</li> <li>RBAC Analysis: Comprehensive permission auditing and change detection</li> <li>Security Context Analysis: Deep container security assessment</li> <li>Compliance Reporting: SOC 2 and PCI DSS compliance automation</li> <li>Vulnerability Assessment: Systematic security violation detection</li> <li>Automated Monitoring: Continuous security monitoring and alerting</li> <li>Integration: Slack, Teams, and PagerDuty alerting integration</li> </ol> <p>These tools enable enterprise-grade security management and compliance reporting using k8s-datamodel's database and analysis capabilities.</p>"},{"location":"examples/security-compliance/#vulnerability-assessment","title":"Vulnerability Assessment","text":"<p>The vulnerability assessment capabilities are integrated throughout the security baseline establishment, RBAC analysis, and container security analysis sections above. These provide comprehensive vulnerability identification including:</p> <ul> <li>Privileged container detection</li> <li>Wildcard permission identification</li> <li>Resource limit violations</li> <li>Host network access risks</li> <li>Root user execution detection</li> </ul> <p>For specific vulnerability scanning workflows, refer to the container security analysis scripts and RBAC audit examples.</p>"},{"location":"examples/security-compliance/#policy-enforcement-monitoring","title":"Policy Enforcement Monitoring","text":"<p>Policy enforcement monitoring is implemented through the continuous security monitoring and alerting integration examples above. Key features include:</p> <ul> <li>Real-time security violation detection</li> <li>Automated policy compliance checking</li> <li>Multi-channel alerting (Slack, Teams, PagerDuty)</li> <li>Historical compliance tracking</li> <li>Security baseline validation</li> </ul> <p>The security monitoring scripts provide comprehensive policy enforcement capabilities with configurable thresholds and automated responses.</p>"},{"location":"examples/security-compliance/#security-drift-detection","title":"Security Drift Detection","text":"<p>Security drift detection is implemented through the security baseline validation and RBAC change detection scripts above. This includes:</p> <ul> <li>Baseline comparison analysis</li> <li>Permission escalation detection</li> <li>Configuration drift identification</li> <li>Security posture degradation alerts</li> <li>Historical trend analysis</li> </ul> <p>The drift detection capabilities leverage k8s-datamodel's database functionality to maintain historical security baselines and detect deviations over time.</p>"},{"location":"usage/cluster/","title":"Cluster Operations","text":"<p>Comprehensive guide for cluster-wide operations and analysis using K8s Inventory CLI.</p>"},{"location":"usage/cluster/#overview","title":"Overview","text":"<p>Cluster operations provide high-level commands to analyze, test, and export complete inventory data from your Kubernetes cluster.</p>"},{"location":"usage/cluster/#available-commands","title":"Available Commands","text":""},{"location":"usage/cluster/#test-connection","title":"Test Connection","text":"<p>Verify connectivity to your Kubernetes cluster:</p> <pre><code>k8s-datamodel cluster test-connection\n</code></pre> <p>This command: - Tests API server connectivity - Validates authentication credentials - Checks basic RBAC permissions - Reports cluster version and status - Identifies connection issues</p>"},{"location":"usage/cluster/#cluster-information","title":"Cluster Information","text":"<p>Get detailed information about your cluster:</p> <pre><code>k8s-datamodel cluster info\n</code></pre> <p>Provides: - Kubernetes version information - API server endpoint details - Node count and status summary - Available API resources - Cluster configuration overview</p>"},{"location":"usage/cluster/#cluster-summary","title":"Cluster Summary","text":"<p>Generate a comprehensive statistical overview:</p> <pre><code>k8s-datamodel cluster summary\n</code></pre> <p>Includes: - CRD Statistics: Total count, groups, scopes - Operator Analysis: Framework breakdown, health status - Resource Utilization: Instance counts, usage patterns - Deployment Patterns: Framework distribution - Health Overview: Cluster-wide health indicators</p>"},{"location":"usage/cluster/#export-complete-inventory","title":"Export Complete Inventory","text":"<p>Export comprehensive cluster inventory data:</p> <pre><code>k8s-datamodel cluster export\n</code></pre>"},{"location":"usage/cluster/#export-options","title":"Export Options","text":"<p>Specify output file: <pre><code>k8s-datamodel cluster export --file cluster-inventory.json\n</code></pre></p> <p>Choose output format: <pre><code>k8s-datamodel cluster export --output json --file inventory.json\nk8s-datamodel cluster export --output yaml --file inventory.yaml\n</code></pre></p> <p>Export to specific directory: <pre><code>k8s-datamodel cluster export --file exports/full-inventory.json\n</code></pre></p>"},{"location":"usage/cluster/#cluster-analysis-workflow","title":"Cluster Analysis Workflow","text":"<pre><code>flowchart TD\n    subgraph \"Initialization\"\n        START([\"\ud83d\ude80 Start\"]) --&gt; AUTH[\"\ud83d\udd13 Authenticate\"]\n        AUTH --&gt; CONNECT[\"\ud83d\udd17 Connect to Cluster\"]\n    end\n\n    CONNECT --&gt; TEST{\"Connection OK?\"}\n    TEST --&gt;|\"\u274c Failed\"| ERROR[\"\u26a0\ufe0f Connection Error\"]\n    TEST --&gt;|\"\u2705 Success\"| INFO[\"\u2139\ufe0f Gather Cluster Info\"]\n\n    subgraph \"Data Collection\"\n        INFO --&gt; PARALLEL_START[\"\ud83d\udd04 Start Parallel Collection\"]\n\n        PARALLEL_START --&gt; CRD_COLLECT[\"\ud83d\udce6 Collect CRDs\"]\n        PARALLEL_START --&gt; OP_COLLECT[\"\ud83e\udd16 Collect Operators\"]\n        PARALLEL_START --&gt; NODE_COLLECT[\"\ud83d\udcbb Collect Nodes\"]\n        PARALLEL_START --&gt; NS_COLLECT[\"\ud83c\udff7\ufe0f Collect Namespaces\"]\n    end\n\n    subgraph \"Analysis Phase\"\n        CRD_COLLECT --&gt; CRD_ANALYZE[\"\ud83d\udd0d Analyze CRDs\"]\n        OP_COLLECT --&gt; OP_ANALYZE[\"\ud83d\udd0d Analyze Operators\"]\n        NODE_COLLECT --&gt; HEALTH_CHECK[\"\ud83d\udc9a Health Assessment\"]\n        NS_COLLECT --&gt; RESOURCE_COUNT[\"\ud83d\udd22 Resource Count\"]\n    end\n\n    subgraph \"Synthesis\"\n        CRD_ANALYZE --&gt; MERGE[\"\ud83d\udd00 Merge Results\"]\n        OP_ANALYZE --&gt; MERGE\n        HEALTH_CHECK --&gt; MERGE\n        RESOURCE_COUNT --&gt; MERGE\n\n        MERGE --&gt; SUMMARY[\"\ud83d\udcca Generate Summary\"]\n        SUMMARY --&gt; RELATIONSHIPS[\"\ud83d\udd17 Map Relationships\"]\n    end\n\n    subgraph \"Output Generation\"\n        RELATIONSHIPS --&gt; FORMAT{\"\ud83c\udfa8 Choose Format\"}\n\n        FORMAT --&gt;|\"\ud83d\udccb Table\"| TABLE_OUT[\"\ud83d\udccb Table Output\"]\n        FORMAT --&gt;|\"\ud83d\udcc4 JSON\"| JSON_OUT[\"\ud83d\udcc4 JSON Export\"]\n        FORMAT --&gt;|\"\ud83d\udcdd YAML\"| YAML_OUT[\"\ud83d\udcdd YAML Export\"]\n        FORMAT --&gt;|\"\ud83c\udf08 Rich\"| RICH_OUT[\"\ud83c\udf08 Rich Display\"]\n    end\n\n    TABLE_OUT --&gt; END([\"\u2705 Complete\"])\n    JSON_OUT --&gt; END\n    YAML_OUT --&gt; END\n    RICH_OUT --&gt; END\n    ERROR --&gt; END\n\n    style START fill:#e3f2fd\n    style END fill:#e8f5e8\n    style ERROR fill:#ffebee\n    style PARALLEL_START fill:#fff3e0</code></pre>"},{"location":"usage/cluster/#export-data-structure","title":"Export Data Structure","text":"<pre><code>graph LR\n    subgraph \"Cluster Export Schema\"\n        ROOT[\"\ud83c\udfd7\ufe0f Cluster Export\"]\n\n        ROOT --&gt; METADATA[\"\ud83d\udcc4 Export Metadata\"]\n        ROOT --&gt; CLUSTER_INFO[\"\u2139\ufe0f Cluster Info\"]\n        ROOT --&gt; CRDS[\"\ud83d\udce6 CRDs Array\"]\n        ROOT --&gt; OPERATORS[\"\ud83e\udd16 Operators Array\"]\n        ROOT --&gt; SUMMARY[\"\ud83d\udcca Summary Stats\"]\n\n        METADATA --&gt; TIMESTAMP[\"\ud83d\udd70\ufe0f Timestamp\"]\n        METADATA --&gt; VERSION[\"\ud83c\udff7\ufe0f Tool Version\"]\n        METADATA --&gt; CONTEXT[\"\ud83d\udd17 K8s Context\"]\n\n        CLUSTER_INFO --&gt; K8S_VERSION[\"\ud83c\udff7\ufe0f K8s Version\"]\n        CLUSTER_INFO --&gt; NODES[\"\ud83d\udcbb Node Count\"]\n        CLUSTER_INFO --&gt; NAMESPACES[\"\ud83c\udff7\ufe0f Namespace Count\"]\n\n        CRDS --&gt; CRD_ITEM[\"\ud83d\udce6 CRD Item\"]\n        CRD_ITEM --&gt; CRD_META[\"\ud83d\udcc4 CRD Metadata\"]\n        CRD_ITEM --&gt; CRD_SPEC[\"\ud83d\udcdd CRD Spec\"]\n        CRD_ITEM --&gt; CRD_INSTANCES[\"\ud83d\udd22 Instance Count\"]\n\n        OPERATORS --&gt; OP_ITEM[\"\ud83e\udd16 Operator Item\"]\n        OP_ITEM --&gt; OP_META[\"\ud83d\udcc4 Operator Metadata\"]\n        OP_ITEM --&gt; OP_HEALTH[\"\ud83d\udc9a Health Status\"]\n        OP_ITEM --&gt; OP_CRDS[\"\ud83d\udd17 Managed CRDs\"]\n\n        SUMMARY --&gt; TOTALS[\"\ud83d\udd22 Resource Totals\"]\n        SUMMARY --&gt; FRAMEWORKS[\"\ud83c\udfd7\ufe0f Framework Stats\"]\n        SUMMARY --&gt; HEALTH_SUMMARY[\"\ud83d\udc9a Health Summary\"]\n    end\n\n    style ROOT fill:#e3f2fd\n    style METADATA fill:#f3e5f5\n    style CLUSTER_INFO fill:#e8f5e8\n    style CRDS fill:#fff3e0\n    style OPERATORS fill:#fce4ec\n    style SUMMARY fill:#f1f8e9</code></pre>"},{"location":"usage/cluster/#understanding-cluster-data","title":"Understanding Cluster Data","text":""},{"location":"usage/cluster/#export-contents","title":"Export Contents","text":"<p>The cluster export includes:</p>"},{"location":"usage/cluster/#crd-information","title":"CRD Information","text":"<ul> <li>Complete CRD definitions and metadata</li> <li>Instance counts and distribution</li> <li>Framework classification</li> <li>Version and compatibility data</li> <li>Categories and capabilities</li> </ul>"},{"location":"usage/cluster/#operator-details","title":"Operator Details","text":"<ul> <li>All detected operators and controllers</li> <li>Health status and replica information</li> <li>Image versions and deployment patterns</li> <li>Managed CRD relationships</li> <li>Resource requirements and constraints</li> </ul>"},{"location":"usage/cluster/#cluster-metadata","title":"Cluster Metadata","text":"<ul> <li>Kubernetes version and build information</li> <li>Node architecture and capacity</li> <li>Available API groups and versions</li> <li>Authentication and authorization details</li> <li>Network and storage capabilities</li> </ul>"},{"location":"usage/cluster/#data-relationships","title":"Data Relationships","text":"<p>The exported data maintains relationships between: - Operators and their managed CRDs - CRDs and their custom resource instances - Namespaces and their contained resources - Framework classifications and deployment patterns</p>"},{"location":"usage/cluster/#output-formats","title":"Output Formats","text":""},{"location":"usage/cluster/#json-format-default","title":"JSON Format (Default)","text":"<pre><code>k8s-datamodel cluster export --output json\n</code></pre> <p>Produces machine-readable JSON with complete structured data: <pre><code>{\n  \"cluster_info\": {...},\n  \"crds\": [...],\n  \"operators\": [...],\n  \"summary\": {...},\n  \"export_metadata\": {...}\n}\n</code></pre></p>"},{"location":"usage/cluster/#yaml-format","title":"YAML Format","text":"<pre><code>k8s-datamodel cluster export --output yaml\n</code></pre> <p>Human-readable YAML format suitable for configuration management and GitOps workflows.</p>"},{"location":"usage/cluster/#use-cases","title":"Use Cases","text":""},{"location":"usage/cluster/#cluster-migration","title":"Cluster Migration","text":""},{"location":"usage/cluster/#pre-migration-assessment","title":"Pre-Migration Assessment","text":"<pre><code># Export complete inventory for migration planning\nk8s-datamodel cluster export --file pre-migration-inventory.json\n\n# Test connectivity to target cluster\nk8s-datamodel cluster test-connection\n\n# Compare cluster versions\nk8s-datamodel cluster info\n</code></pre>"},{"location":"usage/cluster/#migration-validation","title":"Migration Validation","text":"<pre><code># Export post-migration inventory\nk8s-datamodel cluster export --file post-migration-inventory.json\n\n# Compare inventories\ndiff &lt;(jq '.crds | sort_by(.name)' pre-migration-inventory.json) \\\n     &lt;(jq '.crds | sort_by(.name)' post-migration-inventory.json)\n</code></pre>"},{"location":"usage/cluster/#compliance-and-auditing","title":"Compliance and Auditing","text":""},{"location":"usage/cluster/#regular-compliance-exports","title":"Regular Compliance Exports","text":"<pre><code>#!/bin/bash\nDATE=$(date +%Y-%m-%d)\nk8s-datamodel cluster export --file \"compliance/inventory-$DATE.json\"\n</code></pre>"},{"location":"usage/cluster/#audit-trail-generation","title":"Audit Trail Generation","text":"<pre><code># Generate audit summary\nk8s-datamodel cluster summary --output json | \\\n  jq '{\n    audit_date: now | strftime(\"%Y-%m-%d %H:%M:%S\"),\n    crd_count: .crds.total,\n    operator_count: .operators.total,\n    frameworks: .deployment_frameworks\n  }'\n</code></pre>"},{"location":"usage/cluster/#disaster-recovery-planning","title":"Disaster Recovery Planning","text":""},{"location":"usage/cluster/#backup-essential-data","title":"Backup Essential Data","text":"<pre><code># Export cluster inventory for DR documentation\nk8s-datamodel cluster export --file dr-inventory.yaml --output yaml\n\n# Document critical operators\nk8s-datamodel operators list --output yaml &gt; dr-operators.yaml\n</code></pre>"},{"location":"usage/cluster/#recovery-validation","title":"Recovery Validation","text":"<pre><code># Test cluster connectivity after recovery\nk8s-datamodel cluster test-connection\n\n# Validate operator health\nk8s-datamodel cluster summary | grep -A 10 \"Operator Health\"\n</code></pre>"},{"location":"usage/cluster/#security-assessment","title":"Security Assessment","text":""},{"location":"usage/cluster/#security-audit-export","title":"Security Audit Export","text":"<pre><code># Export for security analysis\nk8s-datamodel cluster export --file security-audit.json\n\n# Extract security-relevant information\njq '.operators[] | {\n  name: .name,\n  namespace: .namespace,\n  privileged: .security_context.privileged,\n  cluster_admin: .rbac.cluster_admin\n}' security-audit.json\n</code></pre>"},{"location":"usage/cluster/#privileged-resource-identification","title":"Privileged Resource Identification","text":"<pre><code># Find operators with elevated privileges\nk8s-datamodel operators list --output json | \\\n  jq '.[] | select(.security_context.privileged == true)'\n</code></pre>"},{"location":"usage/cluster/#integration-patterns","title":"Integration Patterns","text":""},{"location":"usage/cluster/#cicd-pipeline-integration","title":"CI/CD Pipeline Integration","text":"<pre><code>#!/bin/bash\n# CI/CD cluster validation script\n\necho \"Testing cluster connectivity...\"\nif ! k8s-datamodel cluster test-connection; then\n  echo \"Cluster connectivity failed\"\n  exit 1\nfi\n\necho \"Exporting cluster inventory...\"\nk8s-datamodel cluster export --file \"artifacts/cluster-inventory-${BUILD_ID}.json\"\n\necho \"Validating critical operators...\"\nFAILED_OPERATORS=$(k8s-datamodel operators list --output json | \\\n  jq -r '.[] | select(.replicas.ready != .replicas.desired) | .name')\n\nif [[ -n \"$FAILED_OPERATORS\" ]]; then\n  echo \"Failed operators detected: $FAILED_OPERATORS\"\n  exit 1\nfi\n\necho \"Cluster validation successful\"\n</code></pre>"},{"location":"usage/cluster/#monitoring-integration","title":"Monitoring Integration","text":"<pre><code># Generate cluster metrics for monitoring\nk8s-datamodel cluster summary --output json | \\\n  jq -r '\n    \"cluster_crd_count \" + (.crds.total | tostring),\n    \"cluster_operator_count \" + (.operators.total | tostring),\n    \"cluster_healthy_operators \" + (.operators.healthy | tostring),\n    \"cluster_failed_operators \" + (.operators.failed | tostring)\n  '\n</code></pre>"},{"location":"usage/cluster/#gitops-workflow","title":"GitOps Workflow","text":"<pre><code># .github/workflows/cluster-inventory.yml\nname: Cluster Inventory Export\non:\n  schedule:\n    - cron: '0 6 * * *'  # Daily at 6 AM\n  workflow_dispatch:\n\njobs:\n  export-inventory:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Setup kubectl\n        uses: azure/setup-kubectl@v3\n\n      - name: Test cluster connection\n        run: k8s-datamodel cluster test-connection\n\n      - name: Export cluster inventory\n        run: |\n          k8s-datamodel cluster export --file \"inventory/$(date +%Y-%m-%d)-inventory.json\"\n\n      - name: Commit inventory\n        run: |\n          git config --local user.email \"action@github.com\"\n          git config --local user.name \"GitHub Action\"\n          git add inventory/\n          git commit -m \"chore: update cluster inventory $(date +%Y-%m-%d)\" || exit 0\n          git push\n</code></pre>"},{"location":"usage/cluster/#advanced-usage","title":"Advanced Usage","text":""},{"location":"usage/cluster/#multi-cluster-management","title":"Multi-Cluster Management","text":"<pre><code># Export from multiple clusters\nfor context in $(kubectl config get-contexts -o name); do\n  echo \"Exporting from context: $context\"\n  KUBECONFIG=$HOME/.kube/config kubectl config use-context $context\n  k8s-datamodel cluster export --file \"exports/$context-inventory.json\"\ndone\n</code></pre>"},{"location":"usage/cluster/#comparative-analysis","title":"Comparative Analysis","text":"<pre><code># Compare two cluster inventories\njq -n --slurpfile a cluster1.json --slurpfile b cluster2.json '\n{\n  cluster1_crds: $a[0].crds | length,\n  cluster2_crds: $b[0].crds | length,\n  common_crds: [$a[0].crds[].name] as $a_names |\n               [$b[0].crds[].name] as $b_names |\n               [$a_names[], $b_names[]] | group_by(.) | map(select(length &gt; 1)) | flatten | unique,\n  unique_to_cluster1: [$a[0].crds[].name] - [$b[0].crds[].name],\n  unique_to_cluster2: [$b[0].crds[].name] - [$a[0].crds[].name]\n}'\n</code></pre>"},{"location":"usage/cluster/#performance-monitoring","title":"Performance Monitoring","text":"<pre><code># Monitor export performance\ntime k8s-datamodel cluster export --file perf-test.json\n\n# Analyze export size and content\nls -lh perf-test.json\njq 'keys' perf-test.json\n</code></pre>"},{"location":"usage/cluster/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/cluster/#connection-issues","title":"Connection Issues","text":"<pre><code># Debug connection problems\nk8s-datamodel cluster test-connection --verbose\n\n# Check kubeconfig\nkubectl config current-context\nkubectl config view --minify\n</code></pre>"},{"location":"usage/cluster/#permission-problems","title":"Permission Problems","text":"<pre><code># Test required permissions\nkubectl auth can-i get customresourcedefinitions\nkubectl auth can-i get deployments --all-namespaces\nkubectl auth can-i get statefulsets --all-namespaces\n</code></pre>"},{"location":"usage/cluster/#large-cluster-performance","title":"Large Cluster Performance","text":"<pre><code># For clusters with many resources, consider filtering\nk8s-datamodel operators list --namespace specific-namespace\nk8s-datamodel crd list --group specific.domain.com\n\n# Monitor memory usage during export\nmemory_before=$(ps -o rss= -p $$)\nk8s-datamodel cluster export --file large-cluster.json\nmemory_after=$(ps -o rss= -p $$)\necho \"Memory used: $((memory_after - memory_before)) KB\"\n</code></pre>"},{"location":"usage/cluster/#export-validation","title":"Export Validation","text":"<pre><code># Validate export integrity\nif ! jq empty large-export.json; then\n  echo \"Export JSON is invalid\"\n  exit 1\nfi\n\n# Check export completeness\nEXPECTED_SECTIONS=(\"cluster_info\" \"crds\" \"operators\" \"summary\")\nfor section in \"${EXPECTED_SECTIONS[@]}\"; do\n  if ! jq -e \".$section\" large-export.json &gt; /dev/null; then\n    echo \"Missing section: $section\"\n  fi\ndone\n</code></pre>"},{"location":"usage/cluster/#best-practices","title":"Best Practices","text":""},{"location":"usage/cluster/#regular-health-checks","title":"Regular Health Checks","text":"<ul> <li>Schedule daily connection tests</li> <li>Monitor cluster summary trends over time</li> <li>Set up alerts for operator health changes</li> <li>Track CRD growth and deprecation patterns</li> </ul>"},{"location":"usage/cluster/#data-management","title":"Data Management","text":"<ul> <li>Implement retention policies for export files</li> <li>Compress large export files for storage</li> <li>Version control important inventory snapshots</li> <li>Archive pre-migration and post-migration exports</li> </ul>"},{"location":"usage/cluster/#security-practices","title":"Security Practices","text":"<ul> <li>Secure export files containing sensitive cluster data</li> <li>Review RBAC permissions regularly</li> <li>Audit operator privilege escalations</li> <li>Monitor for unauthorized CRD installations</li> </ul>"},{"location":"usage/cluster/#related-commands","title":"Related Commands","text":"<ul> <li>CRDs: Detailed CRD analysis and filtering</li> <li>Operators: Comprehensive operator management</li> <li>Output Formats: Format specifications and examples</li> </ul>"},{"location":"usage/crds/","title":"CRD Commands","text":"<p>Comprehensive guide for working with Custom Resource Definitions (CRDs) using K8s Inventory CLI.</p>"},{"location":"usage/crds/#overview","title":"Overview","text":"<p>The CRD commands provide powerful capabilities to discover, analyze, and inventory Custom Resource Definitions in your Kubernetes cluster.</p>"},{"location":"usage/crds/#available-commands","title":"Available Commands","text":""},{"location":"usage/crds/#list-crds","title":"List CRDs","text":"<p>Display all CRDs in your cluster with comprehensive metadata:</p> <pre><code>k8s-datamodel crd list\n</code></pre>"},{"location":"usage/crds/#filtering-options","title":"Filtering Options","text":"<p>Filter CRDs by API group: <pre><code>k8s-datamodel crd list --group networking.k8s.io\nk8s-datamodel crd list --group operators.coreos.com\n</code></pre></p> <p>Filter by resource kind: <pre><code>k8s-datamodel crd list --kind VirtualService\nk8s-datamodel crd list --kind Subscription\n</code></pre></p> <p>Filter by scope (Namespaced/Cluster): <pre><code>k8s-datamodel crd list --scope Namespaced\nk8s-datamodel crd list --scope Cluster\n</code></pre></p>"},{"location":"usage/crds/#get-crd-details","title":"Get CRD Details","text":"<p>Retrieve detailed information about a specific CRD:</p> <pre><code>k8s-datamodel crd get certificaterequests.cert-manager.io\n</code></pre> <p>This command provides: - Complete CRD specification - All available versions - Conversion strategy - Storage version - Categories and short names - Age and creation timestamp</p>"},{"location":"usage/crds/#count-crd-instances","title":"Count CRD Instances","text":"<p>Count how many custom resource instances exist for each CRD:</p> <pre><code>k8s-datamodel crd count\n</code></pre> <p>With filtering: <pre><code>k8s-datamodel crd count --group cert-manager.io\nk8s-datamodel crd count --scope Cluster\n</code></pre></p>"},{"location":"usage/crds/#crd-analysis-process","title":"CRD Analysis Process","text":"<pre><code>flowchart LR\n    subgraph \"Discovery Phase\"\n        API[\"\u26a1 K8s API\"]\n        FETCH[\"\ud83d\udce5 Fetch CRDs\"]\n        FILTER[\"\ud83d\udd0d Apply Filters\"]\n    end\n\n    subgraph \"Analysis Phase\"\n        PARSE[\"\ud83d\udd0d Parse Spec\"]\n        FRAMEWORK[\"\ud83c\udff7\ufe0f Detect Framework\"]\n        CATEGORIZE[\"\ud83d\udcca Categorize\"]\n        COUNT[\"\ud83d\udd22 Count Instances\"]\n    end\n\n    subgraph \"Output Phase\"\n        FORMAT[\"\ud83c\udfa8 Format Results\"]\n        DISPLAY[\"\ud83d\udcbb Display\"]\n        EXPORT[\"\ud83d\udcc1 Export\"]\n    end\n\n    API --&gt; FETCH\n    FETCH --&gt; FILTER\n    FILTER --&gt; PARSE\n    PARSE --&gt; FRAMEWORK\n    FRAMEWORK --&gt; CATEGORIZE\n    CATEGORIZE --&gt; COUNT\n    COUNT --&gt; FORMAT\n    FORMAT --&gt; DISPLAY\n    FORMAT --&gt; EXPORT\n\n    style API fill:#fff3e0\n    style DISPLAY fill:#e8f5e8\n    style EXPORT fill:#e8f5e8</code></pre>"},{"location":"usage/crds/#understanding-crd-information","title":"Understanding CRD Information","text":""},{"location":"usage/crds/#framework-detection","title":"Framework Detection","text":"<p>K8s Inventory CLI automatically detects how CRDs were deployed:</p> <ul> <li>Helm: CRDs installed via Helm charts</li> <li>OLM: CRDs managed by Operator Lifecycle Manager  </li> <li>Manual: CRDs applied directly via kubectl/API</li> </ul>"},{"location":"usage/crds/#crd-categories","title":"CRD Categories","text":"<p>CRDs are automatically categorized based on their metadata: - API extensions - Networking resources - Security policies - Storage classes - Monitoring resources</p>"},{"location":"usage/crds/#instance-analysis","title":"Instance Analysis","text":"<p>The tool can analyze actual custom resource instances: - Count instances per namespace - Identify unused CRDs - Track resource creation patterns - Monitor resource age distribution</p>"},{"location":"usage/crds/#crd-relationship-mapping","title":"CRD Relationship Mapping","text":"<pre><code>erDiagram\n    CRD ||--o{ CUSTOM_RESOURCE : \"defines\"\n    CRD ||--|| OPERATOR : \"managed_by\"\n    CRD {\n        string name\n        string group\n        string kind\n        string scope\n        string framework\n        int instance_count\n    }\n\n    CUSTOM_RESOURCE {\n        string name\n        string namespace\n        string status\n        datetime created\n    }\n\n    OPERATOR {\n        string name\n        string namespace\n        string framework\n        string health_status\n        int replicas\n    }\n\n    NAMESPACE ||--o{ CUSTOM_RESOURCE : \"contains\"\n    NAMESPACE {\n        string name\n        string status\n    }\n\n    FRAMEWORK ||--o{ CRD : \"deploys\"\n    FRAMEWORK {\n        string name\n        string description\n    }</code></pre>"},{"location":"usage/crds/#advanced-filtering","title":"Advanced Filtering","text":""},{"location":"usage/crds/#multiple-filters","title":"Multiple Filters","text":"<p>Combine multiple filters for precise results: <pre><code>k8s-datamodel crd list --group networking.k8s.io --scope Namespaced\n</code></pre></p>"},{"location":"usage/crds/#pattern-matching","title":"Pattern Matching","text":"<p>Use wildcards in group names: <pre><code>k8s-datamodel crd list --group \"*.coreos.com\"\n</code></pre></p>"},{"location":"usage/crds/#output-formats","title":"Output Formats","text":"<p>All CRD commands support multiple output formats:</p>"},{"location":"usage/crds/#table-format-default","title":"Table Format (Default)","text":"<p><pre><code>k8s-datamodel crd list --output table\n</code></pre> Human-readable grid with key information.</p>"},{"location":"usage/crds/#rich-format","title":"Rich Format","text":"<p><pre><code>k8s-datamodel crd list --output rich\n</code></pre> Enhanced terminal output with colors and styling.</p>"},{"location":"usage/crds/#json-format","title":"JSON Format","text":"<p><pre><code>k8s-datamodel crd list --output json\n</code></pre> Machine-readable format perfect for scripting.</p>"},{"location":"usage/crds/#yaml-format","title":"YAML Format","text":"<p><pre><code>k8s-datamodel crd list --output yaml\n</code></pre> Structured format for configuration management.</p>"},{"location":"usage/crds/#use-cases","title":"Use Cases","text":""},{"location":"usage/crds/#cluster-migration-planning","title":"Cluster Migration Planning","text":"<pre><code># Identify all CRDs that need to be migrated\nk8s-datamodel crd list --output yaml &gt; crds-inventory.yaml\n\n# Check which CRDs have active instances\nk8s-datamodel crd count --output json &gt; crd-usage.json\n</code></pre>"},{"location":"usage/crds/#security-auditing","title":"Security Auditing","text":"<pre><code># List all cluster-scoped CRDs (potential security impact)\nk8s-datamodel crd list --scope Cluster\n\n# Find CRDs from specific vendors\nk8s-datamodel crd list --group \"*.example.com\"\n</code></pre>"},{"location":"usage/crds/#operator-management","title":"Operator Management","text":"<pre><code># Find all OLM-managed CRDs\nk8s-datamodel crd list | grep \"OLM\"\n\n# Analyze CRDs by framework\nk8s-datamodel crd list --output json | jq '.[] | select(.framework == \"Helm\")'\n</code></pre>"},{"location":"usage/crds/#cleanup-operations","title":"Cleanup Operations","text":"<pre><code># Find CRDs with zero instances\nk8s-datamodel crd count | grep \"0 instances\"\n\n# Identify old/deprecated CRDs\nk8s-datamodel crd list | sort -k6  # Sort by age\n</code></pre>"},{"location":"usage/crds/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/crds/#permission-issues","title":"Permission Issues","text":"<p>If you encounter permission errors: <pre><code># Test cluster connection\nk8s-datamodel cluster test-connection\n\n# Check your RBAC permissions\nkubectl auth can-i get customresourcedefinitions\n</code></pre></p>"},{"location":"usage/crds/#large-clusters","title":"Large Clusters","text":"<p>For clusters with many CRDs, use filtering to improve performance: <pre><code># Instead of listing all CRDs\nk8s-datamodel crd list --group specific.domain.com\n</code></pre></p>"},{"location":"usage/crds/#output-formatting","title":"Output Formatting","text":"<p>Use <code>--verbose</code> flag for debugging: <pre><code>k8s-datamodel crd list --verbose\n</code></pre></p>"},{"location":"usage/crds/#integration-examples","title":"Integration Examples","text":""},{"location":"usage/crds/#cicd-pipeline-integration","title":"CI/CD Pipeline Integration","text":"<pre><code>#!/bin/bash\n# Export CRD inventory for compliance reporting\nk8s-datamodel crd list --output json &gt; artifacts/crd-inventory.json\n\n# Check for unauthorized CRDs\nUNAUTHORIZED=$(k8s-datamodel crd list --group \"untrusted.com\" --output json)\nif [[ \"$UNAUTHORIZED\" != \"[]\" ]]; then\n  echo \"Unauthorized CRDs detected!\"\n  exit 1\nfi\n</code></pre>"},{"location":"usage/crds/#monitoring-integration","title":"Monitoring Integration","text":"<pre><code># Generate metrics for monitoring systems\nk8s-datamodel crd count --output json | \\\n  jq -r '.[] | \"\\(.name) \\(.instance_count)\"' | \\\n  while read name count; do\n    echo \"crd_instances{name=\\\"$name\\\"} $count\"\n  done\n</code></pre>"},{"location":"usage/crds/#related-commands","title":"Related Commands","text":"<ul> <li>Operators: Find operators managing these CRDs</li> <li>Cluster Operations: Full cluster inventory including CRDs</li> <li>Output Formats: Detailed format specifications</li> </ul>"},{"location":"usage/database/","title":"Database Operations","text":"<p>The k8s-datamodel includes powerful database functionality for persistent storage and historical tracking of Kubernetes cluster inventories. This allows you to store complete snapshots of your cluster state, including the full specifications of all resources, compare changes over time, and maintain a comprehensive historical record of your Kubernetes resources.</p>"},{"location":"usage/database/#overview","title":"Overview","text":"<p>The database functionality provides:</p> <ul> <li>Persistent Storage: Store complete cluster inventories in SQLite database</li> <li>Complete Spec Storage: Store full Kubernetes resource specifications for deep analysis</li> <li>Snapshot Management: Create, list, view, and delete inventory snapshots</li> <li>Historical Tracking: Track changes in CRDs, operators, and OLM resources over time</li> <li>Flexible Storage: Choose what to include in each snapshot (CRDs, operators, OLM CSVs)</li> <li>Multiple Cluster Support: Store inventories from multiple clusters in the same database</li> <li>Spec-level Analysis: Query and analyze stored resource specifications</li> </ul>"},{"location":"usage/database/#database-architecture","title":"Database Architecture","text":""},{"location":"usage/database/#database-schema","title":"Database Schema","text":"<p>The k8s-datamodel database uses SQLite and consists of the following main tables:</p> <pre><code>erDiagram\n    inventory_snapshots {\n        int id PK\n        text timestamp\n        text cluster_context\n        text cluster_info\n        int crd_count\n        int operator_count\n        int csv_count\n        text namespace_filter\n        text notes\n        datetime created_at\n    }\n\n    crds {\n        int id PK\n        int snapshot_id FK\n        text name\n        text group_name\n        text version\n        text kind\n        text plural\n        text singular\n        text scope\n        text creation_timestamp\n        text labels\n        text annotations\n        int instance_count\n        text spec\n    }\n\n    operators {\n        int id PK\n        int snapshot_id FK\n        text name\n        text namespace\n        text operator_type\n        text image\n        text version\n        text creation_timestamp\n        text operator_framework\n        int replicas\n        int ready_replicas\n        text managed_crds\n        text spec\n    }\n\n    csvs {\n        int id PK\n        int snapshot_id FK\n        text name\n        text namespace\n        text display_name\n        text version\n        text phase\n        text description\n        text provider\n        text owned_crds\n        text required_crds\n        text spec\n    }\n\n    inventory_snapshots ||--o{ crds : contains\n    inventory_snapshots ||--o{ operators : contains\n    inventory_snapshots ||--o{ csvs : contains</code></pre>"},{"location":"usage/database/#database-location","title":"Database Location","text":"<p>By default, the database is stored at: - Linux/macOS: <code>~/.k8s-inventory/inventory.db</code> - Windows: <code>%USERPROFILE%\\.k8s-inventory\\inventory.db</code></p> <p>You can specify a custom database location using the <code>--db-path</code> option.</p>"},{"location":"usage/database/#storage-operations","title":"Storage Operations","text":""},{"location":"usage/database/#storing-complete-inventory-snapshots","title":"Storing Complete Inventory Snapshots","text":"<p>The primary way to store data is using the <code>database store</code> command, which creates a complete snapshot of your cluster's inventory:</p> <pre><code># Store complete inventory snapshot\nk8s-datamodel database store\n\n# Store with descriptive notes\nk8s-datamodel database store --notes \"Production cluster before upgrade\"\n\n# Store only specific components\nk8s-datamodel database store --no-crds --notes \"Operators only\"\nk8s-datamodel database store --no-operators --no-olm --notes \"CRDs only\"\nk8s-datamodel database store --no-crds --no-operators --notes \"OLM CSVs only\"\n</code></pre>"},{"location":"usage/database/#storing-from-individual-commands","title":"Storing from Individual Commands","text":"<p>You can also store data while running individual inventory commands:</p> <pre><code># Store CRDs while listing them\nk8s-datamodel crd list --store-db --notes \"CRD inventory snapshot\"\n\n# Store operators while listing them\nk8s-datamodel operators list --store-db --notes \"Operator inventory\"\n\n# Store OLM CSVs while listing them\nk8s-datamodel olm list --store-db --notes \"OLM snapshot\"\n</code></pre>"},{"location":"usage/database/#custom-database-location","title":"Custom Database Location","text":"<p>Use a custom database file:</p> <pre><code># Use specific database file\nk8s-datamodel --db-path /path/to/custom.db database store\n\n# Store with custom location\nk8s-datamodel crd list --store-db --db-path ./cluster-snapshots.db\n</code></pre>"},{"location":"usage/database/#multi-cluster-storage","title":"Multi-Cluster Storage","text":"<p>Store inventories from different clusters:</p> <pre><code># Store from production cluster\nk8s-datamodel --context prod-cluster database store --notes \"Production inventory\"\n\n# Store from development cluster\nk8s-datamodel --context dev-cluster database store --notes \"Development inventory\"\n\n# Store from staging with specific namespace\nk8s-datamodel --context staging --namespace app-namespace database store --notes \"Staging app namespace\"\n</code></pre>"},{"location":"usage/database/#querying-and-viewing-data","title":"Querying and Viewing Data","text":""},{"location":"usage/database/#listing-snapshots","title":"Listing Snapshots","text":"<p>View all stored snapshots:</p> <pre><code># List all snapshots\nk8s-datamodel database list\n\n# List with rich formatting\nk8s-datamodel database list --output rich\n\n# Filter by cluster context\nk8s-datamodel database list --cluster-context prod-cluster\n\n# Limit number of results\nk8s-datamodel database list --limit 10\n\n# JSON output for scripting\nk8s-datamodel database list --output json\n</code></pre> <p>Example output: <pre><code>\u250f\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 ID \u2503 Timestamp           \u2503 Cluster        \u2503 CRDs  \u2503 Operators \u2503 CSVs    \u2503 Notes                                    \u2503\n\u2521\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 1  \u2502 2024-03-15 10:30:15 \u2502 prod-cluster   \u2502 45    \u2502 12        \u2502 8       \u2502 Production cluster before upgrade        \u2502\n\u2502 2  \u2502 2024-03-15 14:45:22 \u2502 prod-cluster   \u2502 47    \u2502 12        \u2502 9       \u2502 Production cluster after upgrade         \u2502\n\u2502 3  \u2502 2024-03-16 09:15:30 \u2502 dev-cluster    \u2502 32    \u2502 8         \u2502 5       \u2502 Development cluster inventory            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"usage/database/#viewing-snapshot-details","title":"Viewing Snapshot Details","text":"<p>Get detailed information about a specific snapshot:</p> <pre><code># Show snapshot details in YAML\nk8s-datamodel database show 1\n\n# Show in JSON format\nk8s-datamodel database show 1 --output json\n</code></pre> <p>Example output: <pre><code>snapshot:\n  id: 1\n  timestamp: '2024-03-15 10:30:15'\n  cluster_context: prod-cluster\n  cluster_info:\n    version: v1.28.3\n    platform: eks\n    nodes: 5\n  crd_count: 45\n  operator_count: 12\n  csv_count: 8\n  notes: Production cluster before upgrade\ncrds:\n  - name: certificates.cert-manager.io\n    group: cert-manager.io\n    version: v1\n    kind: Certificate\n    scope: Namespaced\n    instance_count: 23\n  # ... more CRDs\noperators:\n  - name: cert-manager\n    namespace: cert-manager\n    type: Deployment\n    framework: Helm\n    version: v1.12.0\n    replicas: 1\n    ready_replicas: 1\n  # ... more operators\ncsvs:\n  - name: cert-manager.v1.12.0\n    namespace: operators\n    phase: Succeeded\n    version: 1.12.0\n    description: Certificate management for Kubernetes\n  # ... more CSVs\n</code></pre></p>"},{"location":"usage/database/#exporting-snapshots","title":"Exporting Snapshots","text":"<p>Export snapshots to files for external analysis:</p> <pre><code># Export snapshot to JSON file\nk8s-datamodel database export 1 --file snapshot-1.json\n\n# Export to YAML\nk8s-datamodel database export 1 --output yaml --file snapshot-1.yaml\n\n# Export only specific components\nk8s-datamodel database export 1 --crds-only --file crds-snapshot-1.json\nk8s-datamodel database export 1 --operators-only --file operators-snapshot-1.json\n</code></pre>"},{"location":"usage/database/#database-management","title":"Database Management","text":""},{"location":"usage/database/#database-statistics","title":"Database Statistics","text":"<p>View database statistics and storage information:</p> <pre><code># Show database stats\nk8s-datamodel database stats\n\n# Rich formatted stats\nk8s-datamodel database stats --output rich\n\n# JSON output for monitoring\nk8s-datamodel database stats --output json\n</code></pre> <p>Example output: <pre><code>Database Statistics\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n\n\ud83d\udcca General Statistics:\n  \u2022 Database Path: /Users/user/.k8s-inventory/inventory.db\n  \u2022 Database Size: 2.4 MB\n  \u2022 Total Snapshots: 15\n  \u2022 Date Range: 2024-03-01 to 2024-03-20\n\n\ud83d\udcc8 Content Statistics:\n  \u2022 Total CRDs Stored: 678\n  \u2022 Total Operators Stored: 156\n  \u2022 Total CSVs Stored: 89\n  \u2022 Unique Clusters: 3\n\n\ud83c\udfd7\ufe0f Cluster Breakdown:\n  \u2022 prod-cluster: 8 snapshots\n  \u2022 dev-cluster: 4 snapshots  \n  \u2022 staging-cluster: 3 snapshots\n\n\ud83d\udcbe Storage Breakdown:\n  \u2022 Snapshots: 45%\n  \u2022 CRDs: 35%\n  \u2022 Operators: 15%\n  \u2022 CSVs: 5%\n</code></pre></p>"},{"location":"usage/database/#cleaning-up-old-snapshots","title":"Cleaning Up Old Snapshots","text":"<p>Manage database size by removing old snapshots:</p> <pre><code># Delete specific snapshot\nk8s-datamodel database delete 1\n\n# Delete with confirmation skip\nk8s-datamodel database delete 1 --yes\n\n# Clean up old snapshots (keep most recent N)\nk8s-datamodel database cleanup --keep 10\n\n# Clean up by date\nk8s-datamodel database cleanup --older-than \"30 days\"\n\n# Clean up specific cluster\nk8s-datamodel database cleanup --cluster-context dev-cluster --keep 5\n</code></pre>"},{"location":"usage/database/#database-backup-and-restore","title":"Database Backup and Restore","text":"<pre><code># Backup database\ncp ~/.k8s-inventory/inventory.db ~/backups/inventory-backup-$(date +%Y%m%d).db\n\n# Restore from backup\ncp ~/backups/inventory-backup-20240315.db ~/.k8s-inventory/inventory.db\n\n# Use custom database location for backup testing\nk8s-datamodel --db-path ./test-restore.db database list\n</code></pre>"},{"location":"usage/database/#advanced-usage-patterns","title":"Advanced Usage Patterns","text":""},{"location":"usage/database/#automated-inventory-collection","title":"Automated Inventory Collection","text":"<p>Set up automated snapshot collection using cron or scheduled tasks:</p> <pre><code>#!/bin/bash\n# daily-inventory.sh - Collect daily inventory snapshots\n\n# Production cluster\nk8s-datamodel --context prod-cluster database store --notes \"Daily production snapshot - $(date)\"\n\n# Development cluster  \nk8s-datamodel --context dev-cluster database store --notes \"Daily development snapshot - $(date)\"\n\n# Cleanup old snapshots (keep 30 days)\nk8s-datamodel database cleanup --keep 30\n</code></pre> <p>Add to crontab: <pre><code># Run daily at 2 AM\n0 2 * * * /path/to/daily-inventory.sh\n</code></pre></p>"},{"location":"usage/database/#monitoring-and-alerting","title":"Monitoring and Alerting","text":"<p>Extract metrics for monitoring systems:</p> <pre><code># Get snapshot counts for monitoring\nSNAPSHOT_COUNT=$(k8s-datamodel database stats --output json | jq '.total_snapshots')\n\n# Get latest snapshot info\nLATEST_SNAPSHOT=$(k8s-datamodel database list --limit 1 --output json | jq -r '.[0]')\n\n# Check for recent snapshots (alert if none in 24 hours)\nLATEST_TIME=$(k8s-datamodel database list --limit 1 --output json | jq -r '.[0].timestamp')\n</code></pre>"},{"location":"usage/database/#compliance-and-auditing","title":"Compliance and Auditing","text":"<p>Use database for compliance reporting:</p> <pre><code># Generate compliance report for date range\nk8s-datamodel database list --output json | jq '[.[] | select(.timestamp &gt;= \"2024-03-01\" and .timestamp &lt;= \"2024-03-31\")]' &gt; march-compliance-report.json\n\n# Export security-relevant operators\nk8s-datamodel database show 1 --output json | jq '.operators[] | select(.framework == \"OLM\" and (.managed_crds | contains(\"security\")))' &gt; security-operators.json\n</code></pre>"},{"location":"usage/database/#multi-environment-comparison","title":"Multi-Environment Comparison","text":"<p>Compare inventories across environments:</p> <pre><code># Store snapshots from different environments\nk8s-datamodel --context prod database store --notes \"Production baseline\"\nk8s-datamodel --context staging database store --notes \"Staging baseline\"\nk8s-datamodel --context dev database store --notes \"Development baseline\"\n\n# Export for comparison\nk8s-datamodel database export 1 --file prod-inventory.json\nk8s-datamodel database export 2 --file staging-inventory.json  \nk8s-datamodel database export 3 --file dev-inventory.json\n\n# Use external tools to diff the JSON files\ndiff &lt;(jq -S . prod-inventory.json) &lt;(jq -S . staging-inventory.json)\n</code></pre>"},{"location":"usage/database/#advanced-spec-analysis","title":"Advanced Spec Analysis","text":"<p>With complete resource specifications stored in the database, you can perform deep analysis of your Kubernetes resources:</p>"},{"location":"usage/database/#querying-resource-specifications","title":"Querying Resource Specifications","text":"<pre><code># Export snapshot with full specifications\nk8s-datamodel database export 1 --include-specs --file full-snapshot.json\n\n# Query CRD specifications from exported data\njq '.crds[] | select(.name == \"certificates.cert-manager.io\") | .spec' full-snapshot.json\n\n# Query operator container configurations\njq '.operators[] | {name: .name, spec: .spec.spec.template.spec.containers[0]}' full-snapshot.json\n\n# Extract security contexts from all operators\njq '.operators[] | {name: .name, security_context: .spec.spec.template.spec.containers[0].securityContext}' full-snapshot.json\n</code></pre>"},{"location":"usage/database/#configuration-drift-analysis","title":"Configuration Drift Analysis","text":"<pre><code># Compare operator configurations between snapshots\nk8s-datamodel database export 1 --file snapshot1.json\nk8s-datamodel database export 2 --file snapshot2.json\n\n# Extract and compare specific operator specs\njq '.operators[] | select(.name == \"cert-manager\") | .spec' snapshot1.json &gt; op1.json\njq '.operators[] | select(.name == \"cert-manager\") | .spec' snapshot2.json &gt; op2.json\ndiff op1.json op2.json\n\n# Compare CRD schema changes\njq '.crds[] | select(.name == \"certificates.cert-manager.io\") | .spec.spec.versions[0].schema' snapshot1.json &gt; crd1.json\njq '.crds[] | select(.name == \"certificates.cert-manager.io\") | .spec.spec.versions[0].schema' snapshot2.json &gt; crd2.json\ndiff crd1.json crd2.json\n</code></pre>"},{"location":"usage/database/#security-analysis","title":"Security Analysis","text":"<pre><code># Find operators with privileged security contexts\nk8s-datamodel database export-all --output json | \\\n  jq '.[] | .operators[] | select(.spec.spec.template.spec.containers[0].securityContext.privileged == true)'\n\n# Extract RBAC permissions from CSVs\nk8s-datamodel database export 1 --output json | \\\n  jq '.csvs[] | {name: .name, permissions: .spec.spec.install.spec.permissions}'\n\n# Find operators with host network access\nk8s-datamodel database export 1 --output json | \\\n  jq '.operators[] | select(.spec.spec.template.spec.hostNetwork == true)'\n</code></pre>"},{"location":"usage/database/#resource-requirements-analysis","title":"Resource Requirements Analysis","text":"<pre><code># Analyze resource requests and limits\nk8s-datamodel database export 1 --output json | \\\n  jq '.operators[] | {name: .name, resources: .spec.spec.template.spec.containers[0].resources}'\n\n# Find operators without resource limits\nk8s-datamodel database export 1 --output json | \\\n  jq '.operators[] | select(.spec.spec.template.spec.containers[0].resources.limits == null) | .name'\n\n# Calculate total resource requests across snapshots\nk8s-datamodel database list --output json | \\\n  jq -r '.[] | \"\\(.id) \\(.timestamp)\"' | \\\n  while read id timestamp; do\n    echo \"Snapshot $id ($timestamp):\"\n    k8s-datamodel database export $id --output json | \\\n      jq '[.operators[] | .spec.spec.template.spec.containers[0].resources.requests] | add'\n  done\n</code></pre>"},{"location":"usage/database/#custom-analysis-scripts","title":"Custom Analysis Scripts","text":"<p>Create custom analysis scripts using the stored specifications:</p> <pre><code>#!/bin/bash\n# analyze-operator-images.sh - Analyze operator container images\n\nSNAPSHOT_ID=${1:-\"latest\"}\nif [ \"$SNAPSHOT_ID\" = \"latest\" ]; then\n  SNAPSHOT_ID=$(k8s-datamodel database list --limit 1 --output json | jq -r '.[0].id')\nfi\n\necho \"Analyzing operator images in snapshot $SNAPSHOT_ID\"\nk8s-datamodel database export $SNAPSHOT_ID --output json | \\\n  jq -r '.operators[] | \"\\(.name),\\(.namespace),\\(.spec.spec.template.spec.containers[0].image)\"' | \\\n  while IFS=, read name namespace image; do\n    registry=$(echo $image | cut -d'/' -f1)\n    echo \"Operator: $name (ns: $namespace) - Registry: $registry - Image: $image\"\n  done\n</code></pre> <pre><code>#!/usr/bin/env python3\n# analyze-crd-schemas.py - Analyze CRD schema complexity\n\nimport json\nimport sys\nfrom collections import defaultdict\n\ndef count_schema_properties(schema, depth=0):\n    \"\"\"Count properties in a CRD schema recursively.\"\"\"\n    count = 0\n    if isinstance(schema, dict) and 'properties' in schema:\n        for prop_name, prop_def in schema['properties'].items():\n            count += 1\n            if isinstance(prop_def, dict) and 'properties' in prop_def:\n                count += count_schema_properties(prop_def, depth + 1)\n    return count\n\ndef main():\n    if len(sys.argv) != 2:\n        print(\"Usage: analyze-crd-schemas.py &lt;snapshot-file.json&gt;\")\n        sys.exit(1)\n\n    with open(sys.argv[1]) as f:\n        snapshot = json.load(f)\n\n    complexity = defaultdict(int)\n\n    for crd in snapshot.get('crds', []):\n        if 'spec' in crd and 'spec' in crd['spec']:\n            crd_spec = crd['spec']['spec']\n            if 'versions' in crd_spec:\n                for version in crd_spec['versions']:\n                    if 'schema' in version and 'openAPIV3Schema' in version['schema']:\n                        schema = version['schema']['openAPIV3Schema']\n                        prop_count = count_schema_properties(schema)\n                        complexity[crd['name']] = max(complexity[crd['name']], prop_count)\n\n    print(\"CRD Schema Complexity Analysis:\")\n    print(\"===============================\")\n    for crd_name, count in sorted(complexity.items(), key=lambda x: x[1], reverse=True):\n        print(f\"{crd_name}: {count} properties\")\n\nif __name__ == '__main__':\n    main()\n</code></pre>"},{"location":"usage/database/#integration-examples","title":"Integration Examples","text":""},{"location":"usage/database/#cicd-pipeline-integration","title":"CI/CD Pipeline Integration","text":"<pre><code># .github/workflows/inventory-tracking.yml\nname: Track Cluster Inventory\n\non:\n  schedule:\n    - cron: '0 6 * * *'  # Daily at 6 AM\n  workflow_dispatch:\n\njobs:\n  inventory:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v4\n\n    - name: Setup Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: '3.10'\n\n    - name: Install k8s-datamodel\n      run: pipx install k8s-datamodel\n\n    - name: Configure kubectl\n      run: |\n        echo \"${{ secrets.KUBECONFIG }}\" | base64 -d &gt; kubeconfig\n        export KUBECONFIG=./kubeconfig\n\n    - name: Store inventory snapshot\n      run: |\n        k8s-datamodel database store --notes \"CI/CD automated snapshot - $(date)\"\n\n    - name: Upload database\n      uses: actions/upload-artifact@v4\n      with:\n        name: inventory-database\n        path: ~/.k8s-inventory/inventory.db\n</code></pre>"},{"location":"usage/database/#terraform-integration","title":"Terraform Integration","text":"<pre><code># terraform/inventory-snapshot.tf\nresource \"null_resource\" \"inventory_snapshot\" {\n  triggers = {\n    cluster_version = var.cluster_version\n  }\n\n  provisioner \"local-exec\" {\n    command = &lt;&lt;-EOT\n      k8s-datamodel database store --notes \"Terraform deployment - ${var.environment} - ${timestamp()}\"\n    EOT\n  }\n\n  depends_on = [kubernetes_deployment.applications]\n}\n</code></pre>"},{"location":"usage/database/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/database/#common-issues","title":"Common Issues","text":"<p>Database locked errors: <pre><code># Check for running processes\nps aux | grep k8s-inventory\n\n# Use different database file\nk8s-datamodel --db-path ./temp.db database list\n</code></pre></p> <p>Large database size: <pre><code># Check database size\ndu -h ~/.k8s-inventory/inventory.db\n\n# Clean up old snapshots\nk8s-datamodel database cleanup --keep 10\n\n# Vacuum database to reclaim space\nsqlite3 ~/.k8s-inventory/inventory.db \"VACUUM;\"\n</code></pre></p> <p>Missing snapshots: <pre><code># Verify database integrity\nsqlite3 ~/.k8s-inventory/inventory.db \"PRAGMA integrity_check;\"\n\n# Check database schema\nsqlite3 ~/.k8s-inventory/inventory.db \".schema\"\n</code></pre></p>"},{"location":"usage/database/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Large Clusters: For clusters with hundreds of CRDs/operators, consider using namespace filters</li> <li>Storage Space: Monitor database growth and implement regular cleanup</li> <li>Query Performance: Database includes indexes for common query patterns</li> <li>Concurrent Access: SQLite handles concurrent reads but not concurrent writes</li> </ul>"},{"location":"usage/database/#best-practices","title":"Best Practices","text":"<ol> <li>Regular Snapshots: Set up automated daily/weekly snapshots</li> <li>Meaningful Notes: Always include descriptive notes for snapshots</li> <li>Cleanup Strategy: Implement regular cleanup to manage database size</li> <li>Backup Strategy: Regular database backups for important environments</li> <li>Environment Separation: Consider separate databases for different environments</li> <li>Security: Protect database files containing cluster information</li> </ol> <p> RULE 9aelDXM62tUDmHUQUL8XlE RULE FtUk1rgWdKE6veAClNpAqC RULE mHRxidOov0WLb90jeiS2uG </p>"},{"location":"usage/operators/","title":"Operator Commands","text":"<p>Complete guide for discovering and analyzing Kubernetes operators using K8s Inventory CLI.</p>"},{"location":"usage/operators/#overview","title":"Overview","text":"<p>The operator commands help you identify, classify, and analyze operators running in your Kubernetes cluster, including their managed CRDs and deployment patterns.</p>"},{"location":"usage/operators/#available-commands","title":"Available Commands","text":""},{"location":"usage/operators/#list-operators","title":"List Operators","text":"<p>Display all detected operators in your cluster:</p> <pre><code>k8s-datamodel operators list\n</code></pre>"},{"location":"usage/operators/#filtering-options","title":"Filtering Options","text":"<p>Filter operators by namespace: <pre><code>k8s-datamodel operators list --namespace kube-system\nk8s-datamodel operators list --namespace operators\n</code></pre></p> <p>Filter by deployment framework: <pre><code>k8s-datamodel operators list --framework OLM\nk8s-datamodel operators list --framework Helm  \nk8s-datamodel operators list --framework Manual\n</code></pre></p>"},{"location":"usage/operators/#get-operator-details","title":"Get Operator Details","text":"<p>Retrieve comprehensive information about a specific operator:</p> <pre><code>k8s-datamodel operators get cert-manager --namespace cert-manager\n</code></pre> <p>This provides: - Operator metadata and labels - Container image information and versions - Replica status and health - Resource requirements and limits - Deployment strategy - Related ConfigMaps and Secrets</p>"},{"location":"usage/operators/#managed-crds","title":"Managed CRDs","text":"<p>Discover which CRDs are managed by a specific operator:</p> <pre><code>k8s-datamodel operators managed-crds cert-manager\n</code></pre> <p>This shows: - All CRDs owned by the operator - CRD versions and capabilities - Resource relationships - Instance counts per CRD</p>"},{"location":"usage/operators/#operator-detection-flow","title":"Operator Detection Flow","text":"<pre><code>flowchart TD\n    START([\"\ud83d\udd0d Start Detection\"]) --&gt; SCAN[\"\ud83d\udce1 Scan Workloads\"]\n\n    SCAN --&gt; DEPLOY{\"\ud83d\ude80 Deployments\"}\n    SCAN --&gt; STATEFUL{\"\ud83d\udcca StatefulSets\"}\n\n    DEPLOY --&gt; CHECK_IMAGE[\"\ud83d\uddbc\ufe0f Check Image Name\"]\n    STATEFUL --&gt; CHECK_IMAGE\n\n    CHECK_IMAGE --&gt; PATTERN{\"Operator Pattern?\"}\n    PATTERN --&gt;|\"\u2705 Match\"| CHECK_LABELS[\"\ud83c\udff7\ufe0f Check Labels\"]\n    PATTERN --&gt;|\"\u274c No Match\"| SKIP[\"\u23ed\ufe0f Skip\"]\n\n    CHECK_LABELS --&gt; FRAMEWORK{\"Framework Type?\"}\n\n    FRAMEWORK --&gt;|\"\ud83d\udce6 OLM\"| OLM_DETECT[\"\ud83d\udd0d OLM Detection\"]\n    FRAMEWORK --&gt;|\"\u26f5 Helm\"| HELM_DETECT[\"\ud83d\udd0d Helm Detection\"]\n    FRAMEWORK --&gt;|\"\u270b Manual\"| MANUAL_DETECT[\"\ud83d\udd0d Manual Detection\"]\n\n    subgraph \"OLM Analysis\"\n        OLM_DETECT --&gt; CSV[\"\ud83d\udcdc Check CSV\"]\n        CSV --&gt; SUBSCRIPTION[\"\ud83d\udce6 Check Subscription\"]\n        SUBSCRIPTION --&gt; OLM_RESULT[\"\ud83d\udcca OLM Result\"]\n    end\n\n    subgraph \"Helm Analysis\"\n        HELM_DETECT --&gt; CHART[\"\ud83d\udcc4 Check Chart\"]\n        CHART --&gt; HELM_LABELS[\"\ud83c\udff7\ufe0f Helm Labels\"]\n        HELM_LABELS --&gt; HELM_RESULT[\"\ud83d\udcca Helm Result\"]\n    end\n\n    subgraph \"Manual Analysis\"\n        MANUAL_DETECT --&gt; RBAC[\"\ud83d\udd10 Check RBAC\"]\n        RBAC --&gt; CRD_OWNER[\"\ud83d\udce6 CRD Ownership\"]\n        CRD_OWNER --&gt; MANUAL_RESULT[\"\ud83d\udcca Manual Result\"]\n    end\n\n    OLM_RESULT --&gt; HEALTH[\"\ud83d\udc9a Health Check\"]\n    HELM_RESULT --&gt; HEALTH\n    MANUAL_RESULT --&gt; HEALTH\n\n    HEALTH --&gt; CLASSIFY[\"\ud83d\udcca Classify\"]\n    CLASSIFY --&gt; END([\"\u2705 Detection Complete\"])\n\n    SKIP --&gt; END\n\n    style START fill:#e3f2fd\n    style END fill:#e8f5e8\n    style SKIP fill:#f5f5f5</code></pre>"},{"location":"usage/operators/#operator-detection-logic","title":"Operator Detection Logic","text":""},{"location":"usage/operators/#framework-classification","title":"Framework Classification","text":"<p>K8s Inventory CLI uses sophisticated detection logic:</p>"},{"location":"usage/operators/#olm-operator-lifecycle-manager","title":"OLM (Operator Lifecycle Manager)","text":"<ul> <li>Detects operators managed by OLM</li> <li>Identifies CSV (ClusterServiceVersion) relationships</li> <li>Shows subscription and install plan status</li> <li>Tracks operator versions and upgrades</li> </ul>"},{"location":"usage/operators/#helm-deployed-operators","title":"Helm-deployed Operators","text":"<ul> <li>Identifies operators installed via Helm charts</li> <li>Shows Helm release information</li> <li>Tracks chart versions and repositories</li> <li>Displays Helm-specific annotations</li> </ul>"},{"location":"usage/operators/#manual-deployments","title":"Manual Deployments","text":"<ul> <li>Catches operators deployed directly via kubectl</li> <li>Analyzes deployment patterns and labels</li> <li>Identifies common operator frameworks (Kubebuilder, Operator SDK)</li> <li>Detects custom deployment strategies</li> </ul>"},{"location":"usage/operators/#operator-identification","title":"Operator Identification","text":"<p>Operators are identified through multiple signals: - Container image patterns (<code>*operator*</code>, <code>*controller*</code>) - Common operator ports and health checks - Standard operator labels and annotations - CRD ownership references - RBAC patterns (ServiceAccounts, Roles, ClusterRoles)</p>"},{"location":"usage/operators/#understanding-operator-information","title":"Understanding Operator Information","text":""},{"location":"usage/operators/#health-status","title":"Health Status","text":"<p>Each operator's health is assessed through: - Replica Status: Ready vs Desired replicas - Container Status: Running, Waiting, or Terminated - Health Checks: Liveness and readiness probe status - Resource Conditions: Deployment and pod conditions</p>"},{"location":"usage/operators/#version-detection","title":"Version Detection","text":"<p>K8s Inventory CLI extracts version information from: - Container image tags - Operator metadata labels - OLM CSV specifications - Helm chart annotations</p>"},{"location":"usage/operators/#resource-analysis","title":"Resource Analysis","text":"<p>For each operator, the tool analyzes: - CPU and memory requests/limits - Storage requirements - Network policies and service exposure - Security contexts and privileges</p>"},{"location":"usage/operators/#advanced-filtering-and-queries","title":"Advanced Filtering and Queries","text":""},{"location":"usage/operators/#multi-condition-filtering","title":"Multi-condition Filtering","text":"<pre><code># Find OLM operators in specific namespace\nk8s-datamodel operators list --framework OLM --namespace operators\n\n# Find unhealthy operators (combine with external tools)\nk8s-datamodel operators list --output json | jq '.[] | select(.replicas.ready != .replicas.desired)'\n</code></pre>"},{"location":"usage/operators/#cross-reference-with-crds","title":"Cross-Reference with CRDs","text":"<pre><code># Find operators managing specific CRDs\nk8s-datamodel operators list --output json | \\\n  jq '.[] | select(.managed_crds[] | contains(\"certificates\"))'\n</code></pre>"},{"location":"usage/operators/#output-formats","title":"Output Formats","text":""},{"location":"usage/operators/#table-format-default","title":"Table Format (Default)","text":"<p><pre><code>k8s-datamodel operators list --output table\n</code></pre> Displays essential operator information in a readable grid.</p>"},{"location":"usage/operators/#rich-format","title":"Rich Format","text":"<p><pre><code>k8s-datamodel operators list --output rich\n</code></pre> Enhanced output with color coding for health status and framework types.</p>"},{"location":"usage/operators/#json-format","title":"JSON Format","text":"<p><pre><code>k8s-datamodel operators list --output json\n</code></pre> Complete operator data for programmatic processing.</p>"},{"location":"usage/operators/#yaml-format","title":"YAML Format","text":"<p><pre><code>k8s-datamodel operators list --output yaml\n</code></pre> Structured format suitable for configuration and analysis.</p>"},{"location":"usage/operators/#use-cases","title":"Use Cases","text":""},{"location":"usage/operators/#operator-auditing","title":"Operator Auditing","text":"<pre><code># Get complete operator inventory\nk8s-datamodel operators list --output yaml &gt; operator-inventory.yaml\n\n# Identify operators with elevated privileges\nk8s-datamodel operators list --output json | \\\n  jq '.[] | select(.security_context.privileged == true)'\n</code></pre>"},{"location":"usage/operators/#migration-planning","title":"Migration Planning","text":"<pre><code># List all operators that need to be migrated\nk8s-datamodel operators list --output json &gt; operators-to-migrate.json\n\n# Check operator versions for compatibility\nk8s-datamodel operators list | grep -E \"v[0-9]+\\.[0-9]+\\.[0-9]+\"\n</code></pre>"},{"location":"usage/operators/#security-assessment","title":"Security Assessment","text":"<pre><code># Find operators with cluster-admin permissions\nkubectl get clusterrolebindings -o json | \\\n  jq '.items[] | select(.roleRef.name == \"cluster-admin\") | .subjects[] | select(.kind == \"ServiceAccount\")'\n\n# Cross-reference with operator list\nk8s-datamodel operators list --namespace &lt;namespace&gt;\n</code></pre>"},{"location":"usage/operators/#compliance-reporting","title":"Compliance Reporting","text":"<pre><code># Generate operator compliance report\nk8s-datamodel operators list --output json | \\\n  jq '[.[] | {name, namespace, framework, version: .image_version, health: (.replicas.ready == .replicas.desired)}]'\n</code></pre>"},{"location":"usage/operators/#troubleshooting-operators","title":"Troubleshooting Operators","text":""},{"location":"usage/operators/#health-check-workflow","title":"Health Check Workflow","text":"<ol> <li> <p>List all operators:    <pre><code>k8s-datamodel operators list\n</code></pre></p> </li> <li> <p>Identify unhealthy operators:    <pre><code>k8s-datamodel operators list --output json | jq '.[] | select(.replicas.ready != .replicas.desired)'\n</code></pre></p> </li> <li> <p>Get detailed information:    <pre><code>k8s-datamodel operators get &lt;operator-name&gt; --namespace &lt;namespace&gt;\n</code></pre></p> </li> <li> <p>Check managed CRDs:    <pre><code>k8s-datamodel operators managed-crds &lt;operator-name&gt;\n</code></pre></p> </li> </ol>"},{"location":"usage/operators/#common-issues","title":"Common Issues","text":"<p>Permission Problems: <pre><code># Check if operator service account has required permissions\nkubectl auth can-i get customresourcedefinitions --as=system:serviceaccount:&lt;namespace&gt;:&lt;operator-sa&gt;\n</code></pre></p> <p>Resource Constraints: <pre><code># Check operator resource usage\nk8s-datamodel operators list --output json | jq '.[] | {name, requests: .resources.requests, limits: .resources.limits}'\n</code></pre></p> <p>CRD Conflicts: <pre><code># Find operators managing the same CRDs\nk8s-datamodel operators list --output json | \\\n  jq 'group_by(.managed_crds[]) | map(select(length &gt; 1))'\n</code></pre></p>"},{"location":"usage/operators/#integration-patterns","title":"Integration Patterns","text":""},{"location":"usage/operators/#monitoring-integration","title":"Monitoring Integration","text":"<pre><code># Export operator metrics for monitoring\nk8s-datamodel operators list --output json | \\\n  jq -r '.[] | \"operator_healthy{name=\\\"\\(.name)\\\",namespace=\\\"\\(.namespace)\\\"} \\(if .replicas.ready == .replicas.desired then 1 else 0 end)\"'\n</code></pre>"},{"location":"usage/operators/#cicd-integration","title":"CI/CD Integration","text":"<pre><code>#!/bin/bash\n# Validate operator deployment in CI/CD\nFAILED_OPERATORS=$(k8s-datamodel operators list --output json | jq -r '.[] | select(.replicas.ready != .replicas.desired) | .name')\n\nif [[ -n \"$FAILED_OPERATORS\" ]]; then\n  echo \"Failed operators detected: $FAILED_OPERATORS\"\n  exit 1\nfi\n</code></pre>"},{"location":"usage/operators/#gitops-integration","title":"GitOps Integration","text":"<pre><code># Generate operator state for GitOps comparison\nk8s-datamodel operators list --output yaml | \\\n  yq eval 'sort_by(.name) | .[] | {\"name\": .name, \"namespace\": .namespace, \"image\": .image, \"version\": .image_version}' -\n</code></pre>"},{"location":"usage/operators/#best-practices","title":"Best Practices","text":""},{"location":"usage/operators/#regular-auditing","title":"Regular Auditing","text":"<ul> <li>Schedule periodic operator inventory exports</li> <li>Track operator version changes over time  </li> <li>Monitor for unauthorized operator deployments</li> <li>Validate operator health in monitoring systems</li> </ul>"},{"location":"usage/operators/#security-considerations","title":"Security Considerations","text":"<ul> <li>Review operator RBAC permissions regularly</li> <li>Monitor operators with cluster-wide access</li> <li>Track operator image sources and registries</li> <li>Validate operator security contexts</li> </ul>"},{"location":"usage/operators/#operational-excellence","title":"Operational Excellence","text":"<ul> <li>Document operator dependencies and relationships</li> <li>Maintain operator version compatibility matrices</li> <li>Implement operator upgrade procedures</li> <li>Monitor operator resource consumption patterns</li> </ul>"},{"location":"usage/operators/#related-commands","title":"Related Commands","text":"<ul> <li>CRDs: Analyze CRDs managed by these operators</li> <li>Cluster Operations: Complete cluster analysis including operators</li> <li>Output Formats: Detailed formatting options</li> </ul>"},{"location":"usage/output-formats/","title":"Output Formats","text":"<p>Complete guide to output formats supported by K8s Inventory CLI for integration and automation.</p>"},{"location":"usage/output-formats/#overview","title":"Overview","text":"<p>K8s Inventory CLI supports multiple output formats to accommodate different use cases, from human-readable terminal output to machine-readable formats for automation and integration.</p>"},{"location":"usage/output-formats/#available-formats","title":"Available Formats","text":""},{"location":"usage/output-formats/#table-format-default","title":"Table Format (Default)","text":"<p>Human-readable grid format optimized for terminal viewing:</p> <pre><code>k8s-datamodel crd list --output table\nk8s-datamodel operators list --output table\n</code></pre> <p>Characteristics: - Clean, aligned columns - Truncated data for readability - Color coding for status indicators - Sortable columns - Perfect for interactive terminal use</p> <p>Example Output: <pre><code>NAME                               GROUP                      SCOPE         AGE    INSTANCES\ncertificates.cert-manager.io       cert-manager.io           Namespaced    30d    5\nissuers.cert-manager.io           cert-manager.io           Namespaced    30d    3\nclusterissuers.cert-manager.io    cert-manager.io           Cluster       30d    1\n</code></pre></p>"},{"location":"usage/output-formats/#rich-format","title":"Rich Format","text":"<p>Enhanced terminal output with styling, colors, and visual enhancements:</p> <pre><code>k8s-datamodel crd list --output rich\nk8s-datamodel operators list --output rich\n</code></pre> <p>Features: - Syntax highlighting - Color-coded status indicators - Box-drawing characters for structure - Enhanced typography - Progress indicators - Rich panels and cards</p> <p>Best For: - Interactive terminal sessions - Presentations and demos - Status dashboards - Visual debugging</p>"},{"location":"usage/output-formats/#json-format","title":"JSON Format","text":"<p>Machine-readable JSON format for automation and integration:</p> <pre><code>k8s-datamodel crd list --output json\nk8s-datamodel operators list --output json\nk8s-datamodel cluster export --output json\n</code></pre> <p>Characteristics: - Complete data preservation - Structured, nested objects - Easy to parse programmatically - Supports complex data types - Perfect for APIs and scripting</p> <p>Example Structure: <pre><code>{\n  \"name\": \"certificates.cert-manager.io\",\n  \"group\": \"cert-manager.io\",\n  \"kind\": \"Certificate\",\n  \"scope\": \"Namespaced\",\n  \"versions\": [\"v1\", \"v1beta1\"],\n  \"categories\": [\"cert-manager\"],\n  \"short_names\": [\"cert\", \"certs\"],\n  \"age_days\": 30,\n  \"instance_count\": 5,\n  \"framework\": \"Helm\",\n  \"creation_timestamp\": \"2024-01-15T10:30:00Z\"\n}\n</code></pre></p>"},{"location":"usage/output-formats/#yaml-format","title":"YAML Format","text":"<p>Human and machine-readable YAML format:</p> <pre><code>k8s-datamodel crd list --output yaml\nk8s-datamodel operators list --output yaml\nk8s-datamodel cluster export --output yaml\n</code></pre> <p>Features: - Human-readable structure - Preserves complex data relationships - Easy to edit and version control - Compatible with GitOps workflows - Supports comments and documentation</p> <p>Example Structure: <pre><code>name: certificates.cert-manager.io\ngroup: cert-manager.io\nkind: Certificate\nscope: Namespaced\nversions:\n  - v1\n  - v1beta1\ncategories:\n  - cert-manager\nshort_names:\n  - cert\n  - certs\nage_days: 30\ninstance_count: 5\nframework: Helm\ncreation_timestamp: \"2024-01-15T10:30:00Z\"\n</code></pre></p>"},{"location":"usage/output-formats/#format-selection-guidelines","title":"Format Selection Guidelines","text":""},{"location":"usage/output-formats/#use-table-format-when","title":"Use Table Format When:","text":"<ul> <li>Working interactively in terminal</li> <li>Need quick overview of data</li> <li>Presenting information to humans</li> <li>Terminal space is limited</li> <li>Quick status checks</li> </ul>"},{"location":"usage/output-formats/#use-rich-format-when","title":"Use Rich Format When:","text":"<ul> <li>Creating visual presentations</li> <li>Need enhanced readability</li> <li>Working with status dashboards</li> <li>Demonstrating functionality</li> <li>Color coding is important</li> </ul>"},{"location":"usage/output-formats/#use-json-format-when","title":"Use JSON Format When:","text":"<ul> <li>Building automation scripts</li> <li>Integrating with APIs</li> <li>Processing with jq or similar tools</li> <li>Storing in databases</li> <li>Creating monitoring integrations</li> </ul>"},{"location":"usage/output-formats/#use-yaml-format-when","title":"Use YAML Format When:","text":"<ul> <li>Creating configuration files</li> <li>Working with GitOps workflows</li> <li>Need human-editable output</li> <li>Integrating with Kubernetes manifests</li> <li>Documenting infrastructure</li> </ul>"},{"location":"usage/output-formats/#output-customization","title":"Output Customization","text":""},{"location":"usage/output-formats/#filtering-combined-with-formats","title":"Filtering Combined with Formats","text":"<p>All formats support the same filtering options:</p> <pre><code># JSON output with filtering\nk8s-datamodel crd list --group cert-manager.io --output json\n\n# YAML output with namespace filtering\nk8s-datamodel operators list --namespace kube-system --output yaml\n\n# Rich format with scope filtering\nk8s-datamodel crd list --scope Cluster --output rich\n</code></pre>"},{"location":"usage/output-formats/#file-output","title":"File Output","text":"<p>Save formatted output directly to files:</p> <pre><code># Save JSON export\nk8s-datamodel cluster export --output json --file cluster-inventory.json\n\n# Save YAML export\nk8s-datamodel cluster export --output yaml --file cluster-inventory.yaml\n\n# Save filtered CRD list\nk8s-datamodel crd list --group networking.k8s.io --output json &gt; networking-crds.json\n</code></pre>"},{"location":"usage/output-formats/#integration-examples","title":"Integration Examples","text":""},{"location":"usage/output-formats/#json-processing-with-jq","title":"JSON Processing with jq","text":"<pre><code># Extract specific fields\nk8s-datamodel crd list --output json | jq '.[] | {name, group, instances: .instance_count}'\n\n# Filter and transform\nk8s-datamodel operators list --output json | \\\n  jq '.[] | select(.framework == \"Helm\") | .name'\n\n# Generate summary statistics\nk8s-datamodel cluster export --output json | \\\n  jq '{\n    total_crds: (.crds | length),\n    total_operators: (.operators | length),\n    frameworks: [.operators[].framework] | group_by(.) | map({framework: .[0], count: length})\n  }'\n</code></pre>"},{"location":"usage/output-formats/#yaml-processing-with-yq","title":"YAML Processing with yq","text":"<pre><code># Extract operator information\nk8s-datamodel operators list --output yaml | \\\n  yq eval '.[] | select(.namespace == \"kube-system\")'\n\n# Transform structure\nk8s-datamodel crd list --output yaml | \\\n  yq eval 'map({(.name): {group: .group, scope: .scope}}) | add'\n\n# Merge with existing YAML\nk8s-datamodel cluster export --output yaml | \\\n  yq eval-all '. as $item ireduce ({}; . * $item)' - existing-config.yaml\n</code></pre>"},{"location":"usage/output-formats/#shell-processing","title":"Shell Processing","text":"<pre><code># Table format with shell tools\nk8s-datamodel crd list --output table | grep \"cert-manager\"\nk8s-datamodel operators list --output table | awk '{print $1, $3}' | sort\n\n# Count operations\nCRD_COUNT=$(k8s-datamodel crd list --output json | jq '. | length')\necho \"Total CRDs: $CRD_COUNT\"\n</code></pre>"},{"location":"usage/output-formats/#automation-patterns","title":"Automation Patterns","text":""},{"location":"usage/output-formats/#cicd-integration","title":"CI/CD Integration","text":"<pre><code>#!/bin/bash\n# Export and validate cluster state\n\n# Export current state\nk8s-datamodel cluster export --output json --file current-state.json\n\n# Validate against expected state\nif ! jq -e '.crds | length &gt;= 50' current-state.json; then\n  echo \"ERROR: Expected minimum 50 CRDs\"\n  exit 1\nfi\n\n# Check operator health\nUNHEALTHY=$(k8s-datamodel operators list --output json | \\\n  jq '.[] | select(.replicas.ready != .replicas.desired) | .name' | wc -l)\n\nif [[ $UNHEALTHY -gt 0 ]]; then\n  echo \"ERROR: $UNHEALTHY unhealthy operators detected\"\n  exit 1\nfi\n</code></pre>"},{"location":"usage/output-formats/#monitoring-integration","title":"Monitoring Integration","text":"<pre><code># Generate Prometheus metrics\nk8s-datamodel cluster summary --output json | \\\n  jq -r '\n    \"k8s_inventory_crds_total \" + (.crds.total | tostring),\n    \"k8s_inventory_operators_total \" + (.operators.total | tostring),\n    \"k8s_inventory_operators_healthy \" + (.operators.healthy | tostring)\n  ' &gt; /tmp/metrics.prom\n</code></pre>"},{"location":"usage/output-formats/#configuration-management","title":"Configuration Management","text":"<pre><code># Generate Ansible inventory\nk8s-datamodel operators list --output json | \\\n  jq -r '.[] | \"\\(.name) ansible_host=\\(.namespace) operator_framework=\\(.framework)\"'\n\n# Generate Terraform variables\nk8s-datamodel crd list --output json | \\\n  jq '{crds: [.[] | {name: .name, group: .group, scope: .scope}]}' &gt; terraform-vars.json\n</code></pre>"},{"location":"usage/output-formats/#performance-considerations","title":"Performance Considerations","text":""},{"location":"usage/output-formats/#large-datasets","title":"Large Datasets","text":"<p>For clusters with many resources, consider:</p> <pre><code># Use pagination for large results (if supported)\nk8s-datamodel crd list --output json | jq '. | to_entries | .[0:50] | from_entries'\n\n# Filter early to reduce data transfer\nk8s-datamodel crd list --group specific.domain.com --output json\n\n# Use streaming processing for large exports\nk8s-datamodel cluster export --output json | jq -c '.crds[]' | while read crd; do\n  # Process each CRD individually\n  echo \"$crd\" | jq '.name'\ndone\n</code></pre>"},{"location":"usage/output-formats/#memory-management","title":"Memory Management","text":"<pre><code># For very large exports, consider split processing\nk8s-datamodel cluster export --output json | \\\n  jq -c '{crds: .crds}' &gt; crds-only.json\n\nk8s-datamodel cluster export --output json | \\\n  jq -c '{operators: .operators}' &gt; operators-only.json\n</code></pre>"},{"location":"usage/output-formats/#format-specific-best-practices","title":"Format-Specific Best Practices","text":""},{"location":"usage/output-formats/#json-best-practices","title":"JSON Best Practices","text":"<ul> <li>Use <code>jq -c</code> for compact output in pipelines</li> <li>Always validate JSON integrity with <code>jq empty</code></li> <li>Use meaningful field names when transforming</li> <li>Consider schema validation for critical integrations</li> </ul>"},{"location":"usage/output-formats/#yaml-best-practices","title":"YAML Best Practices","text":"<ul> <li>Use consistent indentation (2 spaces recommended)</li> <li>Add comments for documentation</li> <li>Validate YAML syntax before committing</li> <li>Use anchors and aliases for repeated data</li> </ul>"},{"location":"usage/output-formats/#table-best-practices","title":"Table Best Practices","text":"<ul> <li>Adjust terminal width for optimal display</li> <li>Use filtering to limit column count</li> <li>Consider pagination for large datasets</li> <li>Combine with tools like <code>less -S</code> for horizontal scrolling</li> </ul>"},{"location":"usage/output-formats/#rich-best-practices","title":"Rich Best Practices","text":"<ul> <li>Ensure terminal supports color output</li> <li>Use in interactive sessions, not automation</li> <li>Consider accessibility for color-blind users</li> <li>Test with different terminal themes</li> </ul>"},{"location":"usage/output-formats/#troubleshooting-output-issues","title":"Troubleshooting Output Issues","text":""},{"location":"usage/output-formats/#encoding-problems","title":"Encoding Problems","text":"<pre><code># Force UTF-8 encoding\nexport LC_ALL=C.UTF-8\nk8s-datamodel crd list --output rich\n</code></pre>"},{"location":"usage/output-formats/#terminal-compatibility","title":"Terminal Compatibility","text":"<pre><code># Fallback to table format if rich fails\nk8s-datamodel crd list --output table\n</code></pre>"},{"location":"usage/output-formats/#large-output-handling","title":"Large Output Handling","text":"<pre><code># Use pagination\nk8s-datamodel crd list --output table | less\n\n# Filter to reduce output size\nk8s-datamodel crd list --group cert-manager.io --output table\n</code></pre>"},{"location":"usage/output-formats/#json-parsing-issues","title":"JSON Parsing Issues","text":"<pre><code># Validate JSON output\nk8s-datamodel crd list --output json | jq empty &amp;&amp; echo \"Valid JSON\" || echo \"Invalid JSON\"\n\n# Pretty print for debugging\nk8s-datamodel crd list --output json | jq .\n</code></pre>"},{"location":"usage/output-formats/#related-documentation","title":"Related Documentation","text":"<ul> <li>CRDs: CRD-specific command examples</li> <li>Operators: Operator command examples  </li> <li>Cluster Operations: Cluster-wide export examples</li> </ul>"},{"location":"usage/quick-start/","title":"Quick Start Guide","text":"<p>Get up and running with K8s Inventory CLI in minutes.</p>"},{"location":"usage/quick-start/#installation","title":"Installation","text":""},{"location":"usage/quick-start/#via-pipx-recommended","title":"Via pipx (Recommended)","text":"<pre><code>pipx install k8s-datamodel\n</code></pre>"},{"location":"usage/quick-start/#via-pip","title":"Via pip","text":"<pre><code>pip install k8s-datamodel\n</code></pre>"},{"location":"usage/quick-start/#development-installation","title":"Development Installation","text":"<pre><code>git clone https://github.com/brun-s/k8s-datamodel.git\ncd k8s-datamodel\nuv sync\nuv run k8s-datamodel --help\n</code></pre>"},{"location":"usage/quick-start/#prerequisites","title":"Prerequisites","text":"<ul> <li>Kubernetes cluster access</li> <li>Valid kubeconfig file</li> <li>Python 3.10 or higher</li> </ul>"},{"location":"usage/quick-start/#first-steps","title":"First Steps","text":""},{"location":"usage/quick-start/#1-test-cluster-connection","title":"1. Test Cluster Connection","text":"<pre><code>k8s-datamodel cluster test-connection\n</code></pre>"},{"location":"usage/quick-start/#2-get-cluster-information","title":"2. Get Cluster Information","text":"<pre><code>k8s-datamodel cluster info\n</code></pre>"},{"location":"usage/quick-start/#3-view-cluster-summary","title":"3. View Cluster Summary","text":"<pre><code>k8s-datamodel cluster summary\n</code></pre>"},{"location":"usage/quick-start/#common-commands","title":"Common Commands","text":""},{"location":"usage/quick-start/#list-all-crds","title":"List All CRDs","text":"<pre><code>k8s-datamodel crd list\n</code></pre>"},{"location":"usage/quick-start/#find-operators","title":"Find Operators","text":"<pre><code>k8s-datamodel operators list\n</code></pre>"},{"location":"usage/quick-start/#export-complete-inventory","title":"Export Complete Inventory","text":"<pre><code>k8s-datamodel cluster export --file inventory.json --output json\n</code></pre>"},{"location":"usage/quick-start/#output-formats","title":"Output Formats","text":"<p>K8s Inventory CLI supports multiple output formats:</p> <ul> <li>Table (default): Human-readable grid format</li> <li>Rich: Enhanced terminal output with colors</li> <li>JSON: Machine-readable format</li> <li>YAML: Structured format for both humans and machines</li> </ul> <p>Example with different formats: <pre><code>k8s-datamodel crd list --output table\nk8s-datamodel crd list --output json\nk8s-datamodel crd list --output yaml\nk8s-datamodel crd list --output rich\n</code></pre></p>"},{"location":"usage/quick-start/#next-steps","title":"Next Steps","text":"<ul> <li>Explore CRD Commands for detailed CRD analysis</li> <li>Learn about Operator Detection capabilities  </li> <li>Check Cluster Operations for advanced features</li> <li>Review Output Formats for integration options</li> </ul>"}]}